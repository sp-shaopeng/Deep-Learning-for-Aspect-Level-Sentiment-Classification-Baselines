> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b41ab10b8c8>
>>> learning_rate: 0.001
>>> num_epoch: 100
>>> batch_size: 16
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.3
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 315, 0: 44, 1: 1}, Acc: 0.6416666666666667, Macro-F1: 0.38065016796360074
[Epoch 0] Train Loss=0.8823550939559937 Test Acc=0.6416666666666667 T=1.8900000000000006s
Output Distribution={2: 290, 0: 58, 1: 12}, Acc: 0.6722222222222223, Macro-F1: 0.4796237840261682
[Epoch 1] Train Loss=0.7074709534645081 Test Acc=0.6722222222222223 T=1.6999999999999993s
Output Distribution={2: 251, 0: 83, 1: 26}, Acc: 0.7277777777777777, Macro-F1: 0.5980937714541251
[Epoch 2] Train Loss=0.6013711094856262 Test Acc=0.7277777777777777 T=1.8200000000000003s
Output Distribution={2: 246, 0: 85, 1: 29}, Acc: 0.725, Macro-F1: 0.6016425880248285
[Epoch 3] Train Loss=0.520908534526825 Test Acc=0.725 T=2.0100000000000016s
Output Distribution={2: 245, 0: 73, 1: 42}, Acc: 0.7194444444444444, Macro-F1: 0.6129021019373185
[Epoch 4] Train Loss=0.4596904218196869 Test Acc=0.7194444444444444 T=1.8399999999999999s
Output Distribution={2: 248, 1: 35, 0: 77}, Acc: 0.7194444444444444, Macro-F1: 0.6112229048064721
[Epoch 5] Train Loss=0.4141944944858551 Test Acc=0.7194444444444444 T=1.5200000000000031s
Output Distribution={2: 234, 1: 47, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.6571338147956686
[Epoch 6] Train Loss=0.37754344940185547 Test Acc=0.7388888888888889 T=1.5s
Output Distribution={2: 242, 1: 44, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6426060757439961
[Epoch 7] Train Loss=0.34633907675743103 Test Acc=0.7333333333333333 T=1.8200000000000003s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6636403445930811
[Epoch 8] Train Loss=0.3254634439945221 Test Acc=0.7416666666666667 T=1.5199999999999996s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6611266438852645
[Epoch 9] Train Loss=0.3072502911090851 Test Acc=0.7388888888888889 T=1.7300000000000004s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.660160546524183
[Epoch 10] Train Loss=0.29185980558395386 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 238, 1: 51, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.655647729177141
[Epoch 11] Train Loss=0.27582594752311707 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 238, 1: 54, 0: 68}, Acc: 0.7333333333333333, Macro-F1: 0.6490458752452912
[Epoch 12] Train Loss=0.26653558015823364 Test Acc=0.7333333333333333 T=1.490000000000002s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6616257479893844
[Epoch 13] Train Loss=0.26189371943473816 Test Acc=0.7416666666666667 T=1.4600000000000009s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.658922658922659
[Epoch 14] Train Loss=0.2536349594593048 Test Acc=0.7388888888888889 T=1.4799999999999969s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6617796149900429
[Epoch 15] Train Loss=0.24725781381130219 Test Acc=0.7388888888888889 T=1.4399999999999977s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6585207996722503
[Epoch 16] Train Loss=0.23994649946689606 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6648903320505882
[Epoch 17] Train Loss=0.2357291579246521 Test Acc=0.7444444444444445 T=1.480000000000004s
Output Distribution={2: 232, 1: 53, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6675679519466041
[Epoch 18] Train Loss=0.23915566504001617 Test Acc=0.7472222222222222 T=1.5899999999999963s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6674835938790528
[Epoch 19] Train Loss=0.22516463696956635 Test Acc=0.7472222222222222 T=1.6799999999999997s
Output Distribution={2: 232, 1: 60, 0: 68}, Acc: 0.7444444444444445, Macro-F1: 0.6681122435666609
[Epoch 20] Train Loss=0.22658264636993408 Test Acc=0.7444444444444445 T=1.509999999999998s
Output Distribution={2: 238, 1: 46, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6438542108367086
[Epoch 21] Train Loss=0.22567005455493927 Test Acc=0.7361111111111112 T=1.4799999999999969s
Output Distribution={2: 232, 1: 58, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6628792651010126
[Epoch 22] Train Loss=0.22755955159664154 Test Acc=0.7416666666666667 T=1.4600000000000009s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6474262890727781
[Epoch 23] Train Loss=0.2206919640302658 Test Acc=0.7333333333333333 T=1.4499999999999957s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.663033040984944
[Epoch 24] Train Loss=0.22008860111236572 Test Acc=0.7416666666666667 T=1.4399999999999977s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6631394391265464
[Epoch 25] Train Loss=0.22189007699489594 Test Acc=0.7416666666666667 T=1.4799999999999969s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6569267923971758
[Epoch 26] Train Loss=0.21848781406879425 Test Acc=0.7361111111111112 T=1.4500000000000028s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6670323316964755
[Epoch 27] Train Loss=0.2160942554473877 Test Acc=0.7444444444444445 T=1.490000000000002s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6673994090845531
[Epoch 28] Train Loss=0.21320775151252747 Test Acc=0.7444444444444445 T=1.4399999999999977s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6670098670098671
[Epoch 29] Train Loss=0.2123917043209076 Test Acc=0.7472222222222222 T=1.4799999999999969s
Output Distribution={2: 226, 1: 59, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6711125622266563
[Epoch 30] Train Loss=0.20876748859882355 Test Acc=0.7444444444444445 T=1.4799999999999969s
Output Distribution={2: 229, 1: 56, 0: 75}, Acc: 0.75, Macro-F1: 0.6765440850686751
[Epoch 31] Train Loss=0.2078467309474945 Test Acc=0.75 T=1.4899999999999949s
Output Distribution={2: 237, 1: 47, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.6445544007492336
[Epoch 32] Train Loss=0.213450089097023 Test Acc=0.7333333333333333 T=1.9899999999999949s
Output Distribution={2: 229, 1: 55, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6521411799508199
[Epoch 33] Train Loss=0.20977835357189178 Test Acc=0.7361111111111112 T=1.5300000000000011s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6529436615293548
[Epoch 34] Train Loss=0.21501046419143677 Test Acc=0.7361111111111112 T=1.7800000000000011s
Output Distribution={2: 228, 1: 62, 0: 70}, Acc: 0.7333333333333333, Macro-F1: 0.6552035798277446
[Epoch 35] Train Loss=0.2108253836631775 Test Acc=0.7333333333333333 T=1.5799999999999983s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7333333333333333, Macro-F1: 0.6545519592906963
[Epoch 36] Train Loss=0.21028152108192444 Test Acc=0.7333333333333333 T=1.5300000000000011s
Output Distribution={2: 225, 1: 58, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6604535737820854
[Epoch 37] Train Loss=0.20768803358078003 Test Acc=0.7388888888888889 T=1.460000000000008s
Output Distribution={2: 227, 1: 52, 0: 81}, Acc: 0.7333333333333333, Macro-F1: 0.6499078252256218
[Epoch 38] Train Loss=0.20581106841564178 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 224, 1: 54, 0: 82}, Acc: 0.7361111111111112, Macro-F1: 0.6560710402319682
[Epoch 39] Train Loss=0.2057354897260666 Test Acc=0.7361111111111112 T=1.480000000000004s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6599217011395014
[Epoch 40] Train Loss=0.20475704967975616 Test Acc=0.7388888888888889 T=1.4599999999999937s
Output Distribution={2: 229, 1: 54, 0: 77}, Acc: 0.7333333333333333, Macro-F1: 0.6477777777777778
[Epoch 41] Train Loss=0.20593148469924927 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 230, 1: 50, 0: 80}, Acc: 0.75, Macro-F1: 0.6667676950910514
[Epoch 42] Train Loss=0.20429538190364838 Test Acc=0.75 T=1.4899999999999949s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6666236319489744
[Epoch 43] Train Loss=0.20280411839485168 Test Acc=0.7444444444444445 T=1.5700000000000074s
Output Distribution={2: 228, 1: 56, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6608089777546676
[Epoch 44] Train Loss=0.20472131669521332 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 227, 1: 56, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6590697371844914
[Epoch 45] Train Loss=0.20525099337100983 Test Acc=0.7388888888888889 T=1.519999999999996s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.652272937618455
[Epoch 46] Train Loss=0.20077326893806458 Test Acc=0.7361111111111112 T=1.6099999999999994s
Output Distribution={2: 228, 1: 52, 0: 80}, Acc: 0.7333333333333333, Macro-F1: 0.6477736632550587
[Epoch 47] Train Loss=0.19965530931949615 Test Acc=0.7333333333333333 T=1.509999999999991s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7222222222222222, Macro-F1: 0.6401671239626469
[Epoch 48] Train Loss=0.2057715356349945 Test Acc=0.7222222222222222 T=1.4799999999999898s
Output Distribution={2: 231, 1: 52, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6568521573921303
[Epoch 49] Train Loss=0.2013443410396576 Test Acc=0.7416666666666667 T=1.509999999999991s
Output Distribution={2: 226, 1: 57, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.666647023517215
[Epoch 50] Train Loss=0.20508316159248352 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6656877175821595
[Epoch 51] Train Loss=0.20205743610858917 Test Acc=0.7472222222222222 T=1.480000000000004s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.659802374659289
[Epoch 52] Train Loss=0.20195898413658142 Test Acc=0.7416666666666667 T=1.4500000000000028s
Output Distribution={2: 231, 1: 50, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.657315205927544
[Epoch 53] Train Loss=0.20152609050273895 Test Acc=0.7388888888888889 T=1.4500000000000028s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6597877686475655
[Epoch 54] Train Loss=0.20477260649204254 Test Acc=0.7388888888888889 T=1.480000000000004s
Output Distribution={2: 223, 1: 63, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6642394649039166
[Epoch 55] Train Loss=0.20312918722629547 Test Acc=0.7388888888888889 T=1.4599999999999937s
Output Distribution={2: 231, 1: 47, 0: 82}, Acc: 0.75, Macro-F1: 0.6694547530687981
[Epoch 56] Train Loss=0.20060357451438904 Test Acc=0.75 T=1.480000000000004s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6484965556348278
[Epoch 57] Train Loss=0.20496951043605804 Test Acc=0.7305555555555555 T=1.4599999999999937s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6529235987724117
[Epoch 58] Train Loss=0.20009571313858032 Test Acc=0.7361111111111112 T=1.4799999999999898s
Output Distribution={2: 230, 1: 52, 0: 78}, Acc: 0.7388888888888889, Macro-F1: 0.6576109080920604
[Epoch 59] Train Loss=0.19605164229869843 Test Acc=0.7388888888888889 T=1.4799999999999898s
Output Distribution={2: 224, 1: 60, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6560952692164516
[Epoch 60] Train Loss=0.19913475215435028 Test Acc=0.7361111111111112 T=1.480000000000004s
Output Distribution={2: 238, 1: 45, 0: 77}, Acc: 0.7444444444444445, Macro-F1: 0.6543845806590906
[Epoch 61] Train Loss=0.1956196278333664 Test Acc=0.7444444444444445 T=1.4500000000000028s
Output Distribution={2: 237, 1: 47, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.648891040984717
[Epoch 62] Train Loss=0.20215381681919098 Test Acc=0.7388888888888889 T=1.4599999999999937s
Output Distribution={2: 226, 1: 62, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6597699542287022
[Epoch 63] Train Loss=0.19764448702335358 Test Acc=0.7388888888888889 T=1.4599999999999937s
Output Distribution={2: 225, 1: 61, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6681109127854854
[Epoch 64] Train Loss=0.20197412371635437 Test Acc=0.7444444444444445 T=1.4899999999999949s
Output Distribution={2: 237, 1: 46, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6520426977195536
[Epoch 65] Train Loss=0.1979902684688568 Test Acc=0.7416666666666667 T=1.4799999999999898s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6432243210924048
[Epoch 66] Train Loss=0.19541428983211517 Test Acc=0.7361111111111112 T=1.490000000000009s
Output Distribution={2: 228, 1: 50, 0: 82}, Acc: 0.7472222222222222, Macro-F1: 0.6610125248461336
[Epoch 67] Train Loss=0.19913193583488464 Test Acc=0.7472222222222222 T=1.4599999999999937s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6560064095173054
[Epoch 68] Train Loss=0.19842714071273804 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 234, 1: 56, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6551830682978225
[Epoch 69] Train Loss=0.20314905047416687 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 232, 1: 50, 0: 78}, Acc: 0.7388888888888889, Macro-F1: 0.6508462104488594
[Epoch 70] Train Loss=0.1947290599346161 Test Acc=0.7388888888888889 T=1.4899999999999949s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.75, Macro-F1: 0.6706360521026115
[Epoch 71] Train Loss=0.19544610381126404 Test Acc=0.75 T=1.480000000000004s
Output Distribution={2: 232, 1: 49, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.6538736586162595
[Epoch 72] Train Loss=0.19714997708797455 Test Acc=0.7388888888888889 T=1.480000000000004s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7527777777777778, Macro-F1: 0.6709947843922901
[Epoch 73] Train Loss=0.19581404328346252 Test Acc=0.7527777777777778 T=1.4499999999999886s
Output Distribution={2: 236, 1: 48, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6510204525063461
[Epoch 74] Train Loss=0.19521136581897736 Test Acc=0.7388888888888889 T=1.8400000000000034s
Output Distribution={2: 226, 1: 52, 0: 82}, Acc: 0.7472222222222222, Macro-F1: 0.6677731257407685
[Epoch 75] Train Loss=0.19684569537639618 Test Acc=0.7472222222222222 T=1.5300000000000011s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6553324070565449
[Epoch 76] Train Loss=0.19503115117549896 Test Acc=0.7388888888888889 T=1.5100000000000193s
Output Distribution={2: 227, 1: 53, 0: 80}, Acc: 0.7361111111111112, Macro-F1: 0.6526221599751012
[Epoch 77] Train Loss=0.19491174817085266 Test Acc=0.7361111111111112 T=1.4599999999999795s
Output Distribution={2: 240, 1: 42, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6503067044001667
[Epoch 78] Train Loss=0.19465656578540802 Test Acc=0.7416666666666667 T=1.4800000000000182s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6618167090189887
[Epoch 79] Train Loss=0.1965981125831604 Test Acc=0.7444444444444445 T=1.4699999999999989s
Output Distribution={2: 227, 1: 62, 0: 71}, Acc: 0.7305555555555555, Macro-F1: 0.6529431216931217
[Epoch 80] Train Loss=0.191209614276886 Test Acc=0.7305555555555555 T=1.490000000000009s
Output Distribution={2: 231, 1: 59, 0: 70}, Acc: 0.7333333333333333, Macro-F1: 0.6544236648307444
[Epoch 81] Train Loss=0.19531257450580597 Test Acc=0.7333333333333333 T=1.4799999999999898s
Output Distribution={2: 232, 1: 48, 0: 80}, Acc: 0.7555555555555555, Macro-F1: 0.6773548813816994
[Epoch 82] Train Loss=0.19594191014766693 Test Acc=0.7555555555555555 T=1.4699999999999989s
Output Distribution={2: 239, 1: 50, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.658394413904159
[Epoch 83] Train Loss=0.19589458405971527 Test Acc=0.7444444444444445 T=1.7600000000000193s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6629484464867624
[Epoch 84] Train Loss=0.19536128640174866 Test Acc=0.7444444444444445 T=1.5600000000000023s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.725, Macro-F1: 0.6430521199307694
[Epoch 85] Train Loss=0.19209809601306915 Test Acc=0.725 T=1.490000000000009s
Output Distribution={2: 241, 1: 49, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6470814209944645
[Epoch 86] Train Loss=0.1936689168214798 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6506895685981477
[Epoch 87] Train Loss=0.19590210914611816 Test Acc=0.7305555555555555 T=1.4899999999999807s
Output Distribution={2: 240, 1: 49, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6448472829143393
[Epoch 88] Train Loss=0.19603729248046875 Test Acc=0.7333333333333333 T=1.4799999999999898s
Output Distribution={2: 239, 1: 49, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.654472763618191
[Epoch 89] Train Loss=0.19346968829631805 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 225, 1: 57, 0: 78}, Acc: 0.7361111111111112, Macro-F1: 0.6589741590107374
[Epoch 90] Train Loss=0.19459286332130432 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7277777777777777, Macro-F1: 0.6438313183864216
[Epoch 91] Train Loss=0.1913519650697708 Test Acc=0.7277777777777777 T=1.4799999999999898s
Output Distribution={2: 230, 1: 62, 0: 68}, Acc: 0.7305555555555555, Macro-F1: 0.6520876578446635
[Epoch 92] Train Loss=0.19452011585235596 Test Acc=0.7305555555555555 T=1.4799999999999898s
Output Distribution={2: 234, 1: 48, 0: 78}, Acc: 0.7361111111111112, Macro-F1: 0.6496364872105548
[Epoch 93] Train Loss=0.1896592378616333 Test Acc=0.7361111111111112 T=1.4599999999999795s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6463331463331463
[Epoch 94] Train Loss=0.1939047873020172 Test Acc=0.7333333333333333 T=1.460000000000008s
Output Distribution={2: 231, 1: 59, 0: 70}, Acc: 0.7277777777777777, Macro-F1: 0.6437569981640778
[Epoch 95] Train Loss=0.18957114219665527 Test Acc=0.7277777777777777 T=1.4799999999999898s
Output Distribution={2: 225, 1: 55, 0: 80}, Acc: 0.7361111111111112, Macro-F1: 0.6579761306986074
[Epoch 96] Train Loss=0.19164614379405975 Test Acc=0.7361111111111112 T=1.4799999999999898s
Output Distribution={2: 239, 1: 46, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6490795142969056
[Epoch 97] Train Loss=0.192198246717453 Test Acc=0.7388888888888889 T=1.450000000000017s
Output Distribution={2: 234, 1: 46, 0: 80}, Acc: 0.7472222222222222, Macro-F1: 0.6614929732576791
[Epoch 98] Train Loss=0.1935306042432785 Test Acc=0.7472222222222222 T=1.4699999999999989s
Output Distribution={2: 238, 1: 50, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6504344777502317
[Epoch 99] Train Loss=0.19348636269569397 Test Acc=0.7388888888888889 T=1.460000000000008s
Output Distribution={2: 790, 0: 215, 1: 115}, Acc: 0.6866071428571429, Macro-F1: 0.5369237998638557
accuracy:0.6866071428571429, macro_f1:0.5369237998638557
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b81b0e138c8>
>>> learning_rate: 0.0005
>>> num_epoch: 100
>>> batch_size: 16
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.3
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 353, 0: 7}, Acc: 0.6138888888888889, Macro-F1: 0.2710220673635308
[Epoch 0] Train Loss=0.9371325969696045 Test Acc=0.6138888888888889 T=1.790000000000001s
Output Distribution={2: 334, 0: 24, 1: 2}, Acc: 0.6333333333333333, Macro-F1: 0.3477958249334842
[Epoch 1] Train Loss=0.7972938418388367 Test Acc=0.6333333333333333 T=1.9100000000000001s
Output Distribution={2: 290, 0: 64, 1: 6}, Acc: 0.6638888888888889, Macro-F1: 0.4548649632391258
[Epoch 2] Train Loss=0.7240331768989563 Test Acc=0.6638888888888889 T=1.740000000000002s
Output Distribution={2: 275, 0: 71, 1: 14}, Acc: 0.6944444444444444, Macro-F1: 0.5209080047789726
[Epoch 3] Train Loss=0.6589648723602295 Test Acc=0.6944444444444444 T=2.0s
Output Distribution={2: 271, 0: 65, 1: 24}, Acc: 0.7111111111111111, Macro-F1: 0.5679549114331722
[Epoch 4] Train Loss=0.6016994714736938 Test Acc=0.7111111111111111 T=1.8900000000000006s
Output Distribution={2: 260, 0: 75, 1: 25}, Acc: 0.725, Macro-F1: 0.5934065934065934
[Epoch 5] Train Loss=0.5541451573371887 Test Acc=0.725 T=2.020000000000003s
Output Distribution={2: 246, 0: 80, 1: 34}, Acc: 0.7194444444444444, Macro-F1: 0.6028066787028873
[Epoch 6] Train Loss=0.5131189227104187 Test Acc=0.7194444444444444 T=1.870000000000001s
Output Distribution={2: 250, 0: 76, 1: 34}, Acc: 0.7222222222222222, Macro-F1: 0.6067588119902915
[Epoch 7] Train Loss=0.4771718978881836 Test Acc=0.7222222222222222 T=1.5299999999999976s
Output Distribution={2: 247, 0: 74, 1: 39}, Acc: 0.7277777777777777, Macro-F1: 0.6220594220594221
[Epoch 8] Train Loss=0.45062053203582764 Test Acc=0.7277777777777777 T=1.5199999999999996s
Output Distribution={2: 245, 0: 73, 1: 42}, Acc: 0.7277777777777777, Macro-F1: 0.6282073615348156
[Epoch 9] Train Loss=0.4228709638118744 Test Acc=0.7277777777777777 T=1.879999999999999s
Output Distribution={2: 243, 1: 51, 0: 66}, Acc: 0.7277777777777777, Macro-F1: 0.6386487626874627
[Epoch 10] Train Loss=0.39703771471977234 Test Acc=0.7277777777777777 T=1.5300000000000011s
Output Distribution={2: 245, 1: 47, 0: 68}, Acc: 0.7277777777777777, Macro-F1: 0.6363254676885064
[Epoch 11] Train Loss=0.3750808835029602 Test Acc=0.7277777777777777 T=1.5s
Output Distribution={2: 242, 1: 47, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6466234028711332
[Epoch 12] Train Loss=0.35991740226745605 Test Acc=0.7333333333333333 T=1.4500000000000028s
Output Distribution={2: 239, 1: 46, 0: 75}, Acc: 0.7305555555555555, Macro-F1: 0.6431243355156399
[Epoch 13] Train Loss=0.3459393084049225 Test Acc=0.7305555555555555 T=1.769999999999996s
Output Distribution={2: 237, 1: 47, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6518795378480834
[Epoch 14] Train Loss=0.3323679268360138 Test Acc=0.7361111111111112 T=1.509999999999998s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6537125571476153
[Epoch 15] Train Loss=0.3208145797252655 Test Acc=0.7361111111111112 T=1.7299999999999969s
Output Distribution={2: 235, 1: 48, 0: 77}, Acc: 0.7361111111111112, Macro-F1: 0.6546198830409357
[Epoch 16] Train Loss=0.3066713213920593 Test Acc=0.7361111111111112 T=1.509999999999998s
Output Distribution={2: 234, 1: 49, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6594510803206456
[Epoch 17] Train Loss=0.29789018630981445 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 237, 1: 46, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6595553476121162
[Epoch 18] Train Loss=0.29483482241630554 Test Acc=0.7416666666666667 T=1.7800000000000011s
Output Distribution={2: 238, 1: 51, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6613457348751467
[Epoch 19] Train Loss=0.27801036834716797 Test Acc=0.7416666666666667 T=1.8999999999999986s
Output Distribution={2: 239, 1: 51, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6635485287659201
[Epoch 20] Train Loss=0.2752205729484558 Test Acc=0.7444444444444445 T=1.5200000000000031s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6551649899725972
[Epoch 21] Train Loss=0.2674136459827423 Test Acc=0.7388888888888889 T=1.8200000000000003s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6591643333138357
[Epoch 22] Train Loss=0.2664865255355835 Test Acc=0.7388888888888889 T=1.5399999999999991s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6597310604732329
[Epoch 23] Train Loss=0.2569044530391693 Test Acc=0.7416666666666667 T=1.4499999999999957s
Output Distribution={2: 236, 1: 53, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6538036804802155
[Epoch 24] Train Loss=0.25549644231796265 Test Acc=0.7388888888888889 T=1.4500000000000028s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6539839340364514
[Epoch 25] Train Loss=0.2523074150085449 Test Acc=0.7388888888888889 T=1.470000000000006s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6557880889739297
[Epoch 26] Train Loss=0.24572241306304932 Test Acc=0.7361111111111112 T=1.5600000000000023s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6518009955560483
[Epoch 27] Train Loss=0.24203121662139893 Test Acc=0.7361111111111112 T=1.5399999999999991s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6532845149807354
[Epoch 28] Train Loss=0.23615533113479614 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6508892805885287
[Epoch 29] Train Loss=0.23293396830558777 Test Acc=0.7361111111111112 T=1.4699999999999918s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6600080322098364
[Epoch 30] Train Loss=0.2275056540966034 Test Acc=0.7388888888888889 T=1.4799999999999898s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6476822740843767
[Epoch 31] Train Loss=0.2242906242609024 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7277777777777777, Macro-F1: 0.6380312808884238
[Epoch 32] Train Loss=0.22844298183918 Test Acc=0.7277777777777777 T=1.5699999999999932s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6476822740843767
[Epoch 33] Train Loss=0.22243845462799072 Test Acc=0.7333333333333333 T=1.5300000000000011s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6569416287486297
[Epoch 34] Train Loss=0.22737948596477509 Test Acc=0.7388888888888889 T=1.490000000000009s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6574867724867725
[Epoch 35] Train Loss=0.22246062755584717 Test Acc=0.7361111111111112 T=1.480000000000004s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6568610287316637
[Epoch 36] Train Loss=0.2212582230567932 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6523108340667032
[Epoch 37] Train Loss=0.21578359603881836 Test Acc=0.7333333333333333 T=1.5900000000000034s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7305555555555555, Macro-F1: 0.6468980570976136
[Epoch 38] Train Loss=0.21333903074264526 Test Acc=0.7305555555555555 T=1.5999999999999943s
Output Distribution={2: 228, 1: 54, 0: 78}, Acc: 0.7388888888888889, Macro-F1: 0.6588665680090332
[Epoch 39] Train Loss=0.21223321557044983 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6529750349018641
[Epoch 40] Train Loss=0.2104288637638092 Test Acc=0.7333333333333333 T=1.5s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7305555555555555, Macro-F1: 0.6468980570976136
[Epoch 41] Train Loss=0.2106885313987732 Test Acc=0.7305555555555555 T=1.4500000000000028s
Output Distribution={2: 227, 1: 55, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6635759634706053
[Epoch 42] Train Loss=0.20998835563659668 Test Acc=0.7416666666666667 T=1.5699999999999932s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6568511153663606
[Epoch 43] Train Loss=0.20697623491287231 Test Acc=0.7361111111111112 T=1.6200000000000045s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7305555555555555, Macro-F1: 0.6468980570976136
[Epoch 44] Train Loss=0.20753510296344757 Test Acc=0.7305555555555555 T=1.519999999999996s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6623104623333104
[Epoch 45] Train Loss=0.20796263217926025 Test Acc=0.7388888888888889 T=1.5100000000000051s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6530267206852721
[Epoch 46] Train Loss=0.20387046039104462 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.6503841823043001
[Epoch 47] Train Loss=0.2023579627275467 Test Acc=0.7333333333333333 T=1.4599999999999937s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7277777777777777, Macro-F1: 0.6437740815475083
[Epoch 48] Train Loss=0.20956383645534515 Test Acc=0.7277777777777777 T=1.4599999999999937s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.653021465091787
[Epoch 49] Train Loss=0.20393604040145874 Test Acc=0.7333333333333333 T=1.460000000000008s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607724147914101
[Epoch 50] Train Loss=0.2064741849899292 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6482644339787198
[Epoch 51] Train Loss=0.20242954790592194 Test Acc=0.7333333333333333 T=1.4799999999999898s
Output Distribution={2: 235, 1: 56, 0: 69}, Acc: 0.7416666666666667, Macro-F1: 0.6614455692066308
[Epoch 52] Train Loss=0.20344941318035126 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6573852627067704
[Epoch 53] Train Loss=0.20199331641197205 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6560409813260013
[Epoch 54] Train Loss=0.20616863667964935 Test Acc=0.7361111111111112 T=1.460000000000008s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6749927520475466
[Epoch 55] Train Loss=0.2034502476453781 Test Acc=0.7472222222222222 T=1.5899999999999892s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6618922073906524
[Epoch 56] Train Loss=0.20105676352977753 Test Acc=0.7416666666666667 T=1.8800000000000097s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6628593254514314
[Epoch 57] Train Loss=0.20541517436504364 Test Acc=0.7416666666666667 T=1.5300000000000011s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.664416194464975
[Epoch 58] Train Loss=0.2003929615020752 Test Acc=0.7416666666666667 T=1.4899999999999949s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6643884668078216
[Epoch 59] Train Loss=0.19449010491371155 Test Acc=0.7416666666666667 T=1.5s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6651355367108792
[Epoch 60] Train Loss=0.1983344852924347 Test Acc=0.7416666666666667 T=1.4300000000000068s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6617847430007139
[Epoch 61] Train Loss=0.1942773312330246 Test Acc=0.7472222222222222 T=1.4699999999999989s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.647374730255939
[Epoch 62] Train Loss=0.2010357528924942 Test Acc=0.7361111111111112 T=1.6700000000000017s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6590812314271218
[Epoch 63] Train Loss=0.19817927479743958 Test Acc=0.7361111111111112 T=1.509999999999991s
Output Distribution={2: 228, 1: 61, 0: 71}, Acc: 0.75, Macro-F1: 0.6773136051015153
[Epoch 64] Train Loss=0.2005072981119156 Test Acc=0.75 T=1.6099999999999994s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6440284165848076
[Epoch 65] Train Loss=0.19784867763519287 Test Acc=0.7333333333333333 T=1.8299999999999983s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.658218227637044
[Epoch 66] Train Loss=0.19383449852466583 Test Acc=0.7444444444444445 T=1.5300000000000011s
Output Distribution={2: 228, 1: 53, 0: 79}, Acc: 0.7361111111111112, Macro-F1: 0.6504452208734859
[Epoch 67] Train Loss=0.1981622278690338 Test Acc=0.7361111111111112 T=1.5s
Output Distribution={2: 236, 1: 54, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6588967439076848
[Epoch 68] Train Loss=0.19802097976207733 Test Acc=0.7444444444444445 T=1.5200000000000102s
Output Distribution={2: 235, 1: 58, 0: 67}, Acc: 0.7444444444444445, Macro-F1: 0.6628830139865793
[Epoch 69] Train Loss=0.2034820020198822 Test Acc=0.7444444444444445 T=1.4399999999999977s
Output Distribution={2: 232, 1: 50, 0: 78}, Acc: 0.7388888888888889, Macro-F1: 0.6465707543579204
[Epoch 70] Train Loss=0.19253292679786682 Test Acc=0.7388888888888889 T=1.4599999999999937s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6507928313297441
[Epoch 71] Train Loss=0.1936890184879303 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 230, 1: 51, 0: 79}, Acc: 0.7444444444444445, Macro-F1: 0.6594160724455976
[Epoch 72] Train Loss=0.1961040049791336 Test Acc=0.7444444444444445 T=1.4499999999999886s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7527777777777778, Macro-F1: 0.6728391362537703
[Epoch 73] Train Loss=0.1944352388381958 Test Acc=0.7527777777777778 T=1.4699999999999989s
Output Distribution={2: 230, 1: 52, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6549175837782317
[Epoch 74] Train Loss=0.1944664567708969 Test Acc=0.7416666666666667 T=1.8000000000000114s
Output Distribution={2: 226, 1: 54, 0: 80}, Acc: 0.7416666666666667, Macro-F1: 0.6588944451755347
[Epoch 75] Train Loss=0.19502036273479462 Test Acc=0.7416666666666667 T=1.5199999999999818s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6574875444415517
[Epoch 76] Train Loss=0.1941220462322235 Test Acc=0.7416666666666667 T=1.5200000000000102s
Output Distribution={2: 228, 1: 52, 0: 80}, Acc: 0.7416666666666667, Macro-F1: 0.6563929427587896
[Epoch 77] Train Loss=0.19378462433815002 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 234, 1: 48, 0: 78}, Acc: 0.7361111111111112, Macro-F1: 0.6437368680659026
[Epoch 78] Train Loss=0.1935524344444275 Test Acc=0.7361111111111112 T=1.4799999999999898s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.651471262125015
[Epoch 79] Train Loss=0.1954227089881897 Test Acc=0.7388888888888889 T=1.4399999999999977s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6498236018723824
[Epoch 80] Train Loss=0.18911461532115936 Test Acc=0.7333333333333333 T=1.450000000000017s
Output Distribution={2: 233, 1: 58, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6550723506402444
[Epoch 81] Train Loss=0.1941668838262558 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 227, 1: 54, 0: 79}, Acc: 0.7472222222222222, Macro-F1: 0.6695540935672515
[Epoch 82] Train Loss=0.19457729160785675 Test Acc=0.7472222222222222 T=1.4799999999999898s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6488335194608988
[Epoch 83] Train Loss=0.193643257021904 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6636939066979927
[Epoch 84] Train Loss=0.19367317855358124 Test Acc=0.7444444444444445 T=1.4499999999999886s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6498236018723824
[Epoch 85] Train Loss=0.19022946059703827 Test Acc=0.7333333333333333 T=1.4799999999999898s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.662784437682706
[Epoch 86] Train Loss=0.19146503508090973 Test Acc=0.7472222222222222 T=1.460000000000008s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6666597429018785
[Epoch 87] Train Loss=0.19353212416172028 Test Acc=0.7444444444444445 T=1.4699999999999989s
Output Distribution={2: 238, 1: 49, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6582595979295696
[Epoch 88] Train Loss=0.19507081806659698 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 236, 1: 52, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6560688316599035
[Epoch 89] Train Loss=0.19181720912456512 Test Acc=0.7388888888888889 T=1.4499999999999886s
Output Distribution={2: 225, 1: 57, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.661963695632561
[Epoch 90] Train Loss=0.19474883377552032 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6529562527618206
[Epoch 91] Train Loss=0.18955445289611816 Test Acc=0.7361111111111112 T=1.450000000000017s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6583068783068783
[Epoch 92] Train Loss=0.19435645639896393 Test Acc=0.7388888888888889 T=1.4799999999999898s
Output Distribution={2: 235, 1: 48, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6547368421052632
[Epoch 93] Train Loss=0.18741104006767273 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 231, 1: 52, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6556468843224504
[Epoch 94] Train Loss=0.19165974855422974 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6551992153554866
[Epoch 95] Train Loss=0.18742570281028748 Test Acc=0.7388888888888889 T=1.4199999999999875s
Output Distribution={2: 224, 1: 57, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.6586978087403583
[Epoch 96] Train Loss=0.19197198748588562 Test Acc=0.7388888888888889 T=1.4800000000000182s
Output Distribution={2: 237, 1: 47, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6504842777555738
[Epoch 97] Train Loss=0.19146183133125305 Test Acc=0.7388888888888889 T=1.4599999999999795s
Output Distribution={2: 230, 1: 52, 0: 78}, Acc: 0.7333333333333333, Macro-F1: 0.6504829939777882
[Epoch 98] Train Loss=0.1916166990995407 Test Acc=0.7333333333333333 T=1.5900000000000034s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6528011761366813
[Epoch 99] Train Loss=0.19339816272258759 Test Acc=0.7388888888888889 T=1.5s
Output Distribution={2: 795, 0: 201, 1: 124}, Acc: 0.6991071428571428, Macro-F1: 0.5529020661637704
accuracy:0.6991071428571428, macro_f1:0.5529020661637704
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b9d2b1228c8>
>>> learning_rate: 0.001
>>> num_epoch: 100
>>> batch_size: 16
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.5
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 330, 0: 30}, Acc: 0.6305555555555555, Macro-F1: 0.34306556481595685
[Epoch 0] Train Loss=0.9009724259376526 Test Acc=0.6305555555555555 T=1.709999999999999s
Output Distribution={2: 302, 0: 50, 1: 8}, Acc: 0.6527777777777778, Macro-F1: 0.42942326741235476
[Epoch 1] Train Loss=0.7375503778457642 Test Acc=0.6527777777777778 T=1.8900000000000006s
Output Distribution={2: 261, 0: 77, 1: 22}, Acc: 0.7166666666666667, Macro-F1: 0.5753200050295486
[Epoch 2] Train Loss=0.6424257159233093 Test Acc=0.7166666666666667 T=1.8399999999999999s
Output Distribution={2: 249, 0: 89, 1: 22}, Acc: 0.7194444444444444, Macro-F1: 0.5818547969848207
[Epoch 3] Train Loss=0.5714730620384216 Test Acc=0.7194444444444444 T=1.8500000000000014s
Output Distribution={2: 251, 0: 73, 1: 36}, Acc: 0.725, Macro-F1: 0.6106664784945012
[Epoch 4] Train Loss=0.5147297382354736 Test Acc=0.725 T=1.8199999999999967s
Output Distribution={2: 252, 0: 75, 1: 33}, Acc: 0.725, Macro-F1: 0.609673098045191
[Epoch 5] Train Loss=0.47148510813713074 Test Acc=0.725 T=1.8800000000000026s
Output Distribution={2: 237, 1: 46, 0: 77}, Acc: 0.7305555555555555, Macro-F1: 0.6387346641713455
[Epoch 6] Train Loss=0.4277096390724182 Test Acc=0.7305555555555555 T=1.5299999999999976s
Output Distribution={2: 242, 1: 45, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6469791783558463
[Epoch 7] Train Loss=0.3972998261451721 Test Acc=0.7361111111111112 T=1.870000000000001s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6585501440821134
[Epoch 8] Train Loss=0.3724583089351654 Test Acc=0.7416666666666667 T=1.6400000000000006s
Output Distribution={2: 236, 1: 49, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6623341827223476
[Epoch 9] Train Loss=0.3511607050895691 Test Acc=0.7416666666666667 T=1.7100000000000009s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6516149230412068
[Epoch 10] Train Loss=0.33422693610191345 Test Acc=0.7361111111111112 T=1.5100000000000051s
Output Distribution={2: 237, 1: 51, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6595133142942209
[Epoch 11] Train Loss=0.3135458528995514 Test Acc=0.7416666666666667 T=1.490000000000002s
Output Distribution={2: 240, 1: 50, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6562843868177102
[Epoch 12] Train Loss=0.2961423695087433 Test Acc=0.7388888888888889 T=1.5s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6551649899725972
[Epoch 13] Train Loss=0.2939067780971527 Test Acc=0.7388888888888889 T=1.4600000000000009s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.66228529198454
[Epoch 14] Train Loss=0.2818855345249176 Test Acc=0.7416666666666667 T=1.490000000000002s
Output Distribution={2: 236, 1: 53, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.657947132171614
[Epoch 15] Train Loss=0.2699930667877197 Test Acc=0.7388888888888889 T=1.8100000000000023s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6601909255662283
[Epoch 16] Train Loss=0.267006516456604 Test Acc=0.7416666666666667 T=1.5200000000000031s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.661750608041253
[Epoch 17] Train Loss=0.26177600026130676 Test Acc=0.7416666666666667 T=1.490000000000002s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6586818337255849
[Epoch 18] Train Loss=0.26315072178840637 Test Acc=0.7388888888888889 T=1.4899999999999949s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6664435181676561
[Epoch 19] Train Loss=0.24695150554180145 Test Acc=0.7444444444444445 T=1.490000000000002s
Output Distribution={2: 235, 1: 57, 0: 68}, Acc: 0.7416666666666667, Macro-F1: 0.6621031691839874
[Epoch 20] Train Loss=0.24741970002651215 Test Acc=0.7416666666666667 T=1.7199999999999989s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.656377758497319
[Epoch 21] Train Loss=0.24575357139110565 Test Acc=0.7388888888888889 T=1.509999999999998s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6683933368031253
[Epoch 22] Train Loss=0.24232660233974457 Test Acc=0.7444444444444445 T=1.4799999999999969s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6607457357457358
[Epoch 23] Train Loss=0.23937928676605225 Test Acc=0.7416666666666667 T=1.4499999999999957s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7416666666666667, Macro-F1: 0.6666902963032055
[Epoch 24] Train Loss=0.23888859152793884 Test Acc=0.7416666666666667 T=1.740000000000002s
Output Distribution={2: 235, 1: 55, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6647241647241647
[Epoch 25] Train Loss=0.23779630661010742 Test Acc=0.7416666666666667 T=1.5499999999999972s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553239999900762
[Epoch 26] Train Loss=0.23069927096366882 Test Acc=0.7361111111111112 T=1.8100000000000023s
Output Distribution={2: 231, 1: 51, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6616217626883981
[Epoch 27] Train Loss=0.23048904538154602 Test Acc=0.7416666666666667 T=1.5300000000000011s
Output Distribution={2: 232, 1: 53, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.660494040704403
[Epoch 28] Train Loss=0.22376710176467896 Test Acc=0.7416666666666667 T=1.490000000000002s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6529709881845256
[Epoch 29] Train Loss=0.2252756506204605 Test Acc=0.7361111111111112 T=1.5s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6592467949714474
[Epoch 30] Train Loss=0.21966947615146637 Test Acc=0.7361111111111112 T=1.480000000000004s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6561001313294229
[Epoch 31] Train Loss=0.21838976442813873 Test Acc=0.7361111111111112 T=1.4399999999999977s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6513375930669164
[Epoch 32] Train Loss=0.2257665991783142 Test Acc=0.7333333333333333 T=1.5s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6561008905271286
[Epoch 33] Train Loss=0.22143779695034027 Test Acc=0.7388888888888889 T=1.460000000000008s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6476451210057657
[Epoch 34] Train Loss=0.22642482817173004 Test Acc=0.7305555555555555 T=1.4399999999999977s
Output Distribution={2: 229, 1: 62, 0: 69}, Acc: 0.7277777777777777, Macro-F1: 0.6460951356285864
[Epoch 35] Train Loss=0.22080346941947937 Test Acc=0.7277777777777777 T=1.490000000000009s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7277777777777777, Macro-F1: 0.6445237902766118
[Epoch 36] Train Loss=0.2209072709083557 Test Acc=0.7277777777777777 T=1.4599999999999937s
Output Distribution={2: 226, 1: 58, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6680979528998581
[Epoch 37] Train Loss=0.2140071541070938 Test Acc=0.7444444444444445 T=1.4699999999999989s
Output Distribution={2: 228, 1: 52, 0: 80}, Acc: 0.7333333333333333, Macro-F1: 0.650646180735201
[Epoch 38] Train Loss=0.21031460165977478 Test Acc=0.7333333333333333 T=1.4599999999999937s
Output Distribution={2: 225, 1: 53, 0: 82}, Acc: 0.7388888888888889, Macro-F1: 0.6583415892033075
[Epoch 39] Train Loss=0.21316859126091003 Test Acc=0.7388888888888889 T=1.5s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6511503279725988
[Epoch 40] Train Loss=0.2101099193096161 Test Acc=0.7361111111111112 T=1.4799999999999898s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6507787596385565
[Epoch 41] Train Loss=0.21826748549938202 Test Acc=0.7333333333333333 T=1.4799999999999898s
Output Distribution={2: 232, 1: 49, 0: 79}, Acc: 0.7361111111111112, Macro-F1: 0.6494876937039787
[Epoch 42] Train Loss=0.2133753001689911 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 226, 1: 58, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6680979528998581
[Epoch 43] Train Loss=0.2100316882133484 Test Acc=0.7444444444444445 T=1.480000000000004s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6653782385489703
[Epoch 44] Train Loss=0.21240894496440887 Test Acc=0.7444444444444445 T=1.4799999999999898s
Output Distribution={2: 229, 1: 54, 0: 77}, Acc: 0.7444444444444445, Macro-F1: 0.6637037037037037
[Epoch 45] Train Loss=0.21310563385486603 Test Acc=0.7444444444444445 T=1.460000000000008s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6515558660139743
[Epoch 46] Train Loss=0.20864109694957733 Test Acc=0.7361111111111112 T=1.4899999999999949s
Output Distribution={2: 226, 1: 53, 0: 81}, Acc: 0.7444444444444445, Macro-F1: 0.666178450228983
[Epoch 47] Train Loss=0.20571613311767578 Test Acc=0.7444444444444445 T=1.4799999999999898s
Output Distribution={2: 227, 1: 55, 0: 78}, Acc: 0.7361111111111112, Macro-F1: 0.6565782263592318
[Epoch 48] Train Loss=0.22039954364299774 Test Acc=0.7361111111111112 T=1.4899999999999949s
Output Distribution={2: 229, 1: 52, 0: 79}, Acc: 0.7472222222222222, Macro-F1: 0.6671490402088082
[Epoch 49] Train Loss=0.20029178261756897 Test Acc=0.7472222222222222 T=1.470000000000013s
Output Distribution={2: 231, 1: 52, 0: 77}, Acc: 0.7472222222222222, Macro-F1: 0.6699158375414563
[Epoch 50] Train Loss=0.2058820277452469 Test Acc=0.7472222222222222 T=1.8299999999999983s
Output Distribution={2: 234, 1: 49, 0: 77}, Acc: 0.7444444444444445, Macro-F1: 0.6640080692254605
[Epoch 51] Train Loss=0.20492085814476013 Test Acc=0.7444444444444445 T=1.5400000000000063s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7527777777777778, Macro-F1: 0.67895578803256
[Epoch 52] Train Loss=0.20959104597568512 Test Acc=0.7527777777777778 T=1.5100000000000051s
Output Distribution={2: 231, 1: 51, 0: 78}, Acc: 0.7388888888888889, Macro-F1: 0.6584897463113486
[Epoch 53] Train Loss=0.2084217518568039 Test Acc=0.7388888888888889 T=1.789999999999992s
Output Distribution={2: 224, 1: 62, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6643517987719433
[Epoch 54] Train Loss=0.2110016942024231 Test Acc=0.7388888888888889 T=1.519999999999996s
Output Distribution={2: 223, 1: 62, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6732826576576577
[Epoch 55] Train Loss=0.20975691080093384 Test Acc=0.7444444444444445 T=1.519999999999996s
Output Distribution={2: 229, 1: 51, 0: 80}, Acc: 0.7583333333333333, Macro-F1: 0.6873805932629463
[Epoch 56] Train Loss=0.202813059091568 Test Acc=0.7583333333333333 T=1.5s
Output Distribution={2: 225, 1: 60, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.669632797435488
[Epoch 57] Train Loss=0.20388752222061157 Test Acc=0.7416666666666667 T=1.8700000000000045s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6651732605909333
[Epoch 58] Train Loss=0.20770147442817688 Test Acc=0.7444444444444445 T=1.539999999999992s
Output Distribution={2: 225, 1: 59, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6613382289503517
[Epoch 59] Train Loss=0.19867654144763947 Test Acc=0.7388888888888889 T=1.509999999999991s
Output Distribution={2: 225, 1: 59, 0: 76}, Acc: 0.7472222222222222, Macro-F1: 0.6726406035252454
[Epoch 60] Train Loss=0.203574076294899 Test Acc=0.7472222222222222 T=1.5400000000000063s
Output Distribution={2: 235, 1: 49, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6604313526740692
[Epoch 61] Train Loss=0.20469853281974792 Test Acc=0.7444444444444445 T=1.5300000000000011s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6563361429483386
[Epoch 62] Train Loss=0.2064533680677414 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 225, 1: 63, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6575311190304665
[Epoch 63] Train Loss=0.2022632211446762 Test Acc=0.7361111111111112 T=1.490000000000009s
Output Distribution={2: 226, 1: 63, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.664431697969235
[Epoch 64] Train Loss=0.2068013846874237 Test Acc=0.7416666666666667 T=1.4899999999999949s
Output Distribution={2: 230, 1: 52, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6578543982156114
[Epoch 65] Train Loss=0.20556411147117615 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6466151805803085
[Epoch 66] Train Loss=0.20453301072120667 Test Acc=0.7333333333333333 T=1.480000000000004s
Output Distribution={2: 228, 1: 52, 0: 80}, Acc: 0.7444444444444445, Macro-F1: 0.660750241233735
[Epoch 67] Train Loss=0.20856629312038422 Test Acc=0.7444444444444445 T=1.8199999999999932s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6529213343958897
[Epoch 68] Train Loss=0.20526862144470215 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 235, 1: 57, 0: 68}, Acc: 0.7361111111111112, Macro-F1: 0.6512630607829033
[Epoch 69] Train Loss=0.20596858859062195 Test Acc=0.7361111111111112 T=1.519999999999996s
Output Distribution={2: 230, 1: 50, 0: 80}, Acc: 0.7416666666666667, Macro-F1: 0.656674347492138
[Epoch 70] Train Loss=0.20293565094470978 Test Acc=0.7416666666666667 T=1.5s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6668417862866779
[Epoch 71] Train Loss=0.19954350590705872 Test Acc=0.7444444444444445 T=1.4499999999999886s
Output Distribution={2: 230, 1: 51, 0: 79}, Acc: 0.75, Macro-F1: 0.669500043055884
[Epoch 72] Train Loss=0.2033112496137619 Test Acc=0.75 T=1.4699999999999989s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7527777777777778, Macro-F1: 0.6736424945942355
[Epoch 73] Train Loss=0.20271800458431244 Test Acc=0.7527777777777778 T=1.4399999999999977s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6561008905271286
[Epoch 74] Train Loss=0.19977569580078125 Test Acc=0.7388888888888889 T=1.4799999999999898s
Output Distribution={2: 225, 1: 53, 0: 82}, Acc: 0.7444444444444445, Macro-F1: 0.6654385984105778
[Epoch 75] Train Loss=0.20067206025123596 Test Acc=0.7444444444444445 T=1.4499999999999886s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6534963534963536
[Epoch 76] Train Loss=0.1968826949596405 Test Acc=0.7388888888888889 T=1.460000000000008s
Output Distribution={2: 225, 1: 55, 0: 80}, Acc: 0.7472222222222222, Macro-F1: 0.6668177341062883
[Epoch 77] Train Loss=0.19733236730098724 Test Acc=0.7472222222222222 T=1.5s
Output Distribution={2: 232, 1: 48, 0: 80}, Acc: 0.7388888888888889, Macro-F1: 0.6540010373073749
[Epoch 78] Train Loss=0.19535423815250397 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 228, 1: 59, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6529706399812877
[Epoch 79] Train Loss=0.19974973797798157 Test Acc=0.7361111111111112 T=1.460000000000008s
Output Distribution={2: 227, 1: 61, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6605384456253315
[Epoch 80] Train Loss=0.20082902908325195 Test Acc=0.7388888888888889 T=1.4800000000000182s
Output Distribution={2: 228, 1: 60, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6674143396361352
[Epoch 81] Train Loss=0.19787684082984924 Test Acc=0.7444444444444445 T=1.4700000000000273s
Output Distribution={2: 231, 1: 50, 0: 79}, Acc: 0.75, Macro-F1: 0.6703981497839808
[Epoch 82] Train Loss=0.20058810710906982 Test Acc=0.75 T=1.450000000000017s
Output Distribution={2: 231, 1: 53, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6608499787632581
[Epoch 83] Train Loss=0.19882233440876007 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6616006552795429
[Epoch 84] Train Loss=0.20010694861412048 Test Acc=0.7416666666666667 T=1.490000000000009s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6560817369093231
[Epoch 85] Train Loss=0.19846446812152863 Test Acc=0.7361111111111112 T=1.4300000000000068s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6644953531317168
[Epoch 86] Train Loss=0.19918496906757355 Test Acc=0.7444444444444445 T=1.4699999999999989s
Output Distribution={2: 229, 1: 54, 0: 77}, Acc: 0.7444444444444445, Macro-F1: 0.6655555555555556
[Epoch 87] Train Loss=0.20268088579177856 Test Acc=0.7444444444444445 T=1.490000000000009s
Output Distribution={2: 238, 1: 47, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6482139783371781
[Epoch 88] Train Loss=0.2000379115343094 Test Acc=0.7388888888888889 T=1.4800000000000182s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6508714998647885
[Epoch 89] Train Loss=0.19925238192081451 Test Acc=0.7361111111111112 T=1.450000000000017s
Output Distribution={2: 224, 1: 57, 0: 79}, Acc: 0.7416666666666667, Macro-F1: 0.6641178629409002
[Epoch 90] Train Loss=0.19922089576721191 Test Acc=0.7416666666666667 T=1.4799999999999898s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7305555555555555, Macro-F1: 0.6507931345980126
[Epoch 91] Train Loss=0.19933345913887024 Test Acc=0.7305555555555555 T=1.4799999999999898s
Output Distribution={2: 235, 1: 57, 0: 68}, Acc: 0.7277777777777777, Macro-F1: 0.6429190299741743
[Epoch 92] Train Loss=0.1968110203742981 Test Acc=0.7277777777777777 T=1.460000000000008s
Output Distribution={2: 235, 1: 47, 0: 78}, Acc: 0.7388888888888889, Macro-F1: 0.6519370252586475
[Epoch 93] Train Loss=0.19903752207756042 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 234, 1: 49, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6524138663269099
[Epoch 94] Train Loss=0.19529712200164795 Test Acc=0.7388888888888889 T=1.450000000000017s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.654436189649727
[Epoch 95] Train Loss=0.19504421949386597 Test Acc=0.7388888888888889 T=1.490000000000009s
Output Distribution={2: 225, 1: 54, 0: 81}, Acc: 0.7416666666666667, Macro-F1: 0.6638651084839426
[Epoch 96] Train Loss=0.19859722256660461 Test Acc=0.7416666666666667 T=1.5s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6576111539791927
[Epoch 97] Train Loss=0.19454267621040344 Test Acc=0.7388888888888889 T=1.4800000000000182s
Output Distribution={2: 234, 1: 46, 0: 80}, Acc: 0.75, Macro-F1: 0.664553257200316
[Epoch 98] Train Loss=0.19494426250457764 Test Acc=0.75 T=1.460000000000008s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6536858502578712
[Epoch 99] Train Loss=0.1991601437330246 Test Acc=0.7388888888888889 T=1.5900000000000034s
Output Distribution={2: 792, 0: 211, 1: 117}, Acc: 0.6946428571428571, Macro-F1: 0.5435517801458613
accuracy:0.6946428571428571, macro_f1:0.5435517801458613
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2ba5038018c8>
>>> learning_rate: 0.0005
>>> num_epoch: 100
>>> batch_size: 16
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.5
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 356, 0: 4}, Acc: 0.6111111111111112, Macro-F1: 0.2616909376008163
[Epoch 0] Train Loss=0.9548011422157288 Test Acc=0.6111111111111112 T=1.5999999999999996s
Output Distribution={2: 342, 0: 17, 1: 1}, Acc: 0.625, Macro-F1: 0.31875887976733663
[Epoch 1] Train Loss=0.8165030479431152 Test Acc=0.625 T=1.7299999999999986s
Output Distribution={2: 303, 0: 55, 1: 2}, Acc: 0.65, Macro-F1: 0.4092388863942524
[Epoch 2] Train Loss=0.7522013783454895 Test Acc=0.65 T=1.6499999999999986s
Output Distribution={2: 290, 0: 61, 1: 9}, Acc: 0.6666666666666666, Macro-F1: 0.461390892893653
[Epoch 3] Train Loss=0.6986256837844849 Test Acc=0.6666666666666666 T=1.7300000000000004s
Output Distribution={2: 280, 0: 60, 1: 20}, Acc: 0.6972222222222222, Macro-F1: 0.5380340327679431
[Epoch 4] Train Loss=0.6489890217781067 Test Acc=0.6972222222222222 T=1.8399999999999999s
Output Distribution={2: 272, 0: 69, 1: 19}, Acc: 0.7, Macro-F1: 0.5387995314687313
[Epoch 5] Train Loss=0.6082892417907715 Test Acc=0.7 T=1.7399999999999984s
Output Distribution={2: 254, 0: 79, 1: 27}, Acc: 0.7277777777777777, Macro-F1: 0.5995340501792114
[Epoch 6] Train Loss=0.5659023523330688 Test Acc=0.7277777777777777 T=1.870000000000001s
Output Distribution={2: 254, 0: 77, 1: 29}, Acc: 0.7305555555555555, Macro-F1: 0.6060818713450292
[Epoch 7] Train Loss=0.5326485633850098 Test Acc=0.7305555555555555 T=1.8599999999999994s
Output Distribution={2: 252, 0: 73, 1: 35}, Acc: 0.725, Macro-F1: 0.6114989007661519
[Epoch 8] Train Loss=0.5077528357505798 Test Acc=0.725 T=1.8300000000000018s
Output Distribution={2: 249, 0: 74, 1: 37}, Acc: 0.725, Macro-F1: 0.6173576887892113
[Epoch 9] Train Loss=0.4787723124027252 Test Acc=0.725 T=1.8299999999999983s
Output Distribution={2: 247, 0: 69, 1: 44}, Acc: 0.7333333333333333, Macro-F1: 0.635326905749441
[Epoch 10] Train Loss=0.45432406663894653 Test Acc=0.7333333333333333 T=1.75s
Output Distribution={2: 245, 0: 72, 1: 43}, Acc: 0.7222222222222222, Macro-F1: 0.6189502878202194
[Epoch 11] Train Loss=0.4288947880268097 Test Acc=0.7222222222222222 T=1.8500000000000014s
Output Distribution={2: 246, 1: 42, 0: 72}, Acc: 0.7222222222222222, Macro-F1: 0.6197717740384309
[Epoch 12] Train Loss=0.40846511721611023 Test Acc=0.7222222222222222 T=1.5300000000000011s
Output Distribution={2: 244, 1: 44, 0: 72}, Acc: 0.7222222222222222, Macro-F1: 0.6227840136627679
[Epoch 13] Train Loss=0.3946292996406555 Test Acc=0.7222222222222222 T=1.5200000000000031s
Output Distribution={2: 240, 1: 45, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6425221316761448
[Epoch 14] Train Loss=0.38237181305885315 Test Acc=0.7333333333333333 T=1.5100000000000051s
Output Distribution={2: 241, 1: 45, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6462417890989319
[Epoch 15] Train Loss=0.3641788363456726 Test Acc=0.7333333333333333 T=1.8000000000000043s
Output Distribution={2: 241, 1: 46, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6474653580817965
[Epoch 16] Train Loss=0.3529893457889557 Test Acc=0.7361111111111112 T=1.5600000000000023s
Output Distribution={2: 239, 1: 47, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.650263357876176
[Epoch 17] Train Loss=0.3472456932067871 Test Acc=0.7361111111111112 T=1.7999999999999972s
Output Distribution={2: 240, 1: 46, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6452876522988082
[Epoch 18] Train Loss=0.3408128023147583 Test Acc=0.7333333333333333 T=1.5399999999999991s
Output Distribution={2: 235, 1: 49, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.65435593165386
[Epoch 19] Train Loss=0.32250890135765076 Test Acc=0.7361111111111112 T=1.509999999999998s
Output Distribution={2: 237, 1: 51, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6595133142942209
[Epoch 20] Train Loss=0.31825193762779236 Test Acc=0.7416666666666667 T=1.490000000000002s
Output Distribution={2: 239, 1: 47, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6621474856455344
[Epoch 21] Train Loss=0.31162703037261963 Test Acc=0.7444444444444445 T=1.7800000000000011s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.654690060383187
[Epoch 22] Train Loss=0.30169737339019775 Test Acc=0.7361111111111112 T=1.8100000000000023s
Output Distribution={2: 240, 1: 48, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6534933963927196
[Epoch 23] Train Loss=0.29712235927581787 Test Acc=0.7388888888888889 T=1.5499999999999972s
Output Distribution={2: 238, 1: 49, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.662173813561778
[Epoch 24] Train Loss=0.2967984676361084 Test Acc=0.7444444444444445 T=1.5399999999999991s
Output Distribution={2: 240, 1: 47, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6537750757842906
[Epoch 25] Train Loss=0.2902739942073822 Test Acc=0.7388888888888889 T=1.509999999999998s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6632952484296115
[Epoch 26] Train Loss=0.28112027049064636 Test Acc=0.7416666666666667 T=1.490000000000002s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.655379517448483
[Epoch 27] Train Loss=0.27586114406585693 Test Acc=0.7361111111111112 T=1.490000000000002s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6591643333138357
[Epoch 28] Train Loss=0.2684704661369324 Test Acc=0.7388888888888889 T=1.480000000000004s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.661346010257081
[Epoch 29] Train Loss=0.26621097326278687 Test Acc=0.7416666666666667 T=1.4799999999999969s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6611224336788246
[Epoch 30] Train Loss=0.2581985890865326 Test Acc=0.7416666666666667 T=1.490000000000009s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6516139467489847
[Epoch 31] Train Loss=0.2522541284561157 Test Acc=0.7361111111111112 T=1.5300000000000011s
Output Distribution={2: 238, 1: 50, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6475296121002679
[Epoch 32] Train Loss=0.2596919536590576 Test Acc=0.7333333333333333 T=2.0999999999999943s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6539839340364514
[Epoch 33] Train Loss=0.2507557272911072 Test Acc=0.7388888888888889 T=1.6099999999999994s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6516139467489847
[Epoch 34] Train Loss=0.2553803622722626 Test Acc=0.7361111111111112 T=1.460000000000008s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6594327403961034
[Epoch 35] Train Loss=0.24816325306892395 Test Acc=0.7388888888888889 T=1.470000000000013s
Output Distribution={2: 235, 1: 54, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6555555555555556
[Epoch 36] Train Loss=0.2488008737564087 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6586818337255849
[Epoch 37] Train Loss=0.23711293935775757 Test Acc=0.7388888888888889 T=1.4599999999999937s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7305555555555555, Macro-F1: 0.6430221430221431
[Epoch 38] Train Loss=0.2332930564880371 Test Acc=0.7305555555555555 T=1.4699999999999989s
Output Distribution={2: 231, 1: 53, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6608499787632581
[Epoch 39] Train Loss=0.23544691503047943 Test Acc=0.7416666666666667 T=1.4899999999999949s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607440541906181
[Epoch 40] Train Loss=0.22955018281936646 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.655435962762832
[Epoch 41] Train Loss=0.23702269792556763 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7305555555555555, Macro-F1: 0.6430221430221431
[Epoch 42] Train Loss=0.2300272285938263 Test Acc=0.7305555555555555 T=1.4500000000000028s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6508012672726123
[Epoch 43] Train Loss=0.2251589149236679 Test Acc=0.7333333333333333 T=1.4500000000000028s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6531097814091466
[Epoch 44] Train Loss=0.22787384688854218 Test Acc=0.7333333333333333 T=1.6599999999999966s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7305555555555555, Macro-F1: 0.6477756866744128
[Epoch 45] Train Loss=0.22773686051368713 Test Acc=0.7305555555555555 T=1.5300000000000011s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6523108340667032
[Epoch 46] Train Loss=0.2227822244167328 Test Acc=0.7333333333333333 T=1.5100000000000051s
Output Distribution={2: 229, 1: 54, 0: 77}, Acc: 0.7333333333333333, Macro-F1: 0.6496296296296297
[Epoch 47] Train Loss=0.2201489806175232 Test Acc=0.7333333333333333 T=1.460000000000008s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7305555555555555, Macro-F1: 0.649189833509814
[Epoch 48] Train Loss=0.23441727459430695 Test Acc=0.7305555555555555 T=1.4599999999999937s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6513815005846765
[Epoch 49] Train Loss=0.21411864459514618 Test Acc=0.7333333333333333 T=1.710000000000008s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6488939946839664
[Epoch 50] Train Loss=0.21748574078083038 Test Acc=0.7333333333333333 T=1.769999999999996s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.667447762946208
[Epoch 51] Train Loss=0.2139260470867157 Test Acc=0.7444444444444445 T=1.6099999999999994s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6674785686632377
[Epoch 52] Train Loss=0.2187352478504181 Test Acc=0.7444444444444445 T=1.4699999999999989s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.660639814514785
[Epoch 53] Train Loss=0.21691808104515076 Test Acc=0.7388888888888889 T=1.4799999999999898s
Output Distribution={2: 228, 1: 59, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6659516124111419
[Epoch 54] Train Loss=0.22057895362377167 Test Acc=0.7416666666666667 T=1.6300000000000097s
Output Distribution={2: 227, 1: 59, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6651768707482993
[Epoch 55] Train Loss=0.21957534551620483 Test Acc=0.7416666666666667 T=1.5200000000000102s
Output Distribution={2: 228, 1: 54, 0: 78}, Acc: 0.7444444444444445, Macro-F1: 0.6688371346021164
[Epoch 56] Train Loss=0.21201452612876892 Test Acc=0.7444444444444445 T=1.5100000000000051s
Output Distribution={2: 227, 1: 59, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6651768707482993
[Epoch 57] Train Loss=0.21272455155849457 Test Acc=0.7416666666666667 T=1.4799999999999898s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.660639814514785
[Epoch 58] Train Loss=0.2153668850660324 Test Acc=0.7388888888888889 T=1.4500000000000028s
Output Distribution={2: 227, 1: 57, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6644402481896344
[Epoch 59] Train Loss=0.20471534132957458 Test Acc=0.7416666666666667 T=1.6899999999999977s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6697648108938431
[Epoch 60] Train Loss=0.2094162106513977 Test Acc=0.7444444444444445 T=1.6800000000000068s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6675009395956097
[Epoch 61] Train Loss=0.21020320057868958 Test Acc=0.7444444444444445 T=1.539999999999992s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6660119235332103
[Epoch 62] Train Loss=0.211885005235672 Test Acc=0.7444444444444445 T=1.4899999999999949s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6574867724867725
[Epoch 63] Train Loss=0.2091088891029358 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 228, 1: 59, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6621030600726119
[Epoch 64] Train Loss=0.2105303853750229 Test Acc=0.7416666666666667 T=1.7199999999999989s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6520992170751193
[Epoch 65] Train Loss=0.2111244797706604 Test Acc=0.7361111111111112 T=1.6199999999999903s
Output Distribution={2: 235, 1: 55, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6653385158169848
[Epoch 66] Train Loss=0.2101598083972931 Test Acc=0.7444444444444445 T=1.5s
Output Distribution={2: 227, 1: 56, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6635141816289357
[Epoch 67] Train Loss=0.21393029391765594 Test Acc=0.7416666666666667 T=1.4399999999999977s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7416666666666667, Macro-F1: 0.6621901356631327
[Epoch 68] Train Loss=0.2095639407634735 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 235, 1: 56, 0: 69}, Acc: 0.7444444444444445, Macro-F1: 0.6621379123171587
[Epoch 69] Train Loss=0.2115822434425354 Test Acc=0.7444444444444445 T=1.4599999999999937s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6656448483882113
[Epoch 70] Train Loss=0.20660817623138428 Test Acc=0.7472222222222222 T=1.470000000000013s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7472222222222222, Macro-F1: 0.6650805423532696
[Epoch 71] Train Loss=0.20281831920146942 Test Acc=0.7472222222222222 T=1.8400000000000034s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7472222222222222, Macro-F1: 0.6648486005909481
[Epoch 72] Train Loss=0.20822562277317047 Test Acc=0.7472222222222222 T=1.5199999999999818s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.75, Macro-F1: 0.6664990126714542
[Epoch 73] Train Loss=0.207726389169693 Test Acc=0.75 T=1.4800000000000182s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6633997086693398
[Epoch 74] Train Loss=0.20380574464797974 Test Acc=0.7472222222222222 T=2.210000000000008s
Output Distribution={2: 226, 1: 57, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6597653734926611
[Epoch 75] Train Loss=0.20252160727977753 Test Acc=0.7416666666666667 T=1.5500000000000114s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.666619964532876
[Epoch 76] Train Loss=0.19996687769889832 Test Acc=0.7472222222222222 T=1.509999999999991s
Output Distribution={2: 228, 1: 54, 0: 78}, Acc: 0.7444444444444445, Macro-F1: 0.6618361299986398
[Epoch 77] Train Loss=0.20167823135852814 Test Acc=0.7444444444444445 T=1.4699999999999989s
Output Distribution={2: 230, 1: 52, 0: 78}, Acc: 0.7444444444444445, Macro-F1: 0.6593325948157592
[Epoch 78] Train Loss=0.1996774971485138 Test Acc=0.7444444444444445 T=1.4599999999999795s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6613542023781042
[Epoch 79] Train Loss=0.2028660923242569 Test Acc=0.7416666666666667 T=1.460000000000008s
Output Distribution={2: 229, 1: 61, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6641932345869354
[Epoch 80] Train Loss=0.20321600139141083 Test Acc=0.7416666666666667 T=1.4499999999999886s
Output Distribution={2: 231, 1: 61, 0: 68}, Acc: 0.7444444444444445, Macro-F1: 0.6672727149927197
[Epoch 81] Train Loss=0.20102863013744354 Test Acc=0.7444444444444445 T=1.4499999999999886s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6569416287486297
[Epoch 82] Train Loss=0.20404210686683655 Test Acc=0.7388888888888889 T=1.4800000000000182s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6499039457895343
[Epoch 83] Train Loss=0.20210397243499756 Test Acc=0.7333333333333333 T=1.4399999999999977s
Output Distribution={2: 230, 1: 61, 0: 69}, Acc: 0.7416666666666667, Macro-F1: 0.6649841258209733
[Epoch 84] Train Loss=0.20344696938991547 Test Acc=0.7416666666666667 T=1.4599999999999795s
Output Distribution={2: 232, 1: 60, 0: 68}, Acc: 0.7444444444444445, Macro-F1: 0.6681122435666609
[Epoch 85] Train Loss=0.19988800585269928 Test Acc=0.7444444444444445 T=1.460000000000008s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6651732605909333
[Epoch 86] Train Loss=0.2015487104654312 Test Acc=0.7444444444444445 T=1.4199999999999875s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6635399959441771
[Epoch 87] Train Loss=0.20420345664024353 Test Acc=0.7444444444444445 T=1.4799999999999898s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6558397541156162
[Epoch 88] Train Loss=0.20384125411510468 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6513295057908387
[Epoch 89] Train Loss=0.2010098099708557 Test Acc=0.7361111111111112 T=1.6099999999999852s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7277777777777777, Macro-F1: 0.6431386743886743
[Epoch 90] Train Loss=0.20265206694602966 Test Acc=0.7277777777777777 T=1.509999999999991s
Output Distribution={2: 229, 1: 61, 0: 70}, Acc: 0.7305555555555555, Macro-F1: 0.6469637216093909
[Epoch 91] Train Loss=0.20211036503314972 Test Acc=0.7305555555555555 T=1.5300000000000011s
Output Distribution={2: 236, 1: 56, 0: 68}, Acc: 0.7305555555555555, Macro-F1: 0.6451504163298908
[Epoch 92] Train Loss=0.1997922658920288 Test Acc=0.7305555555555555 T=1.509999999999991s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.642509903317788
[Epoch 93] Train Loss=0.2001301795244217 Test Acc=0.7333333333333333 T=1.4899999999999807s
Output Distribution={2: 233, 1: 51, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6470543443313451
[Epoch 94] Train Loss=0.19623377919197083 Test Acc=0.7361111111111112 T=1.460000000000008s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6452457518933509
[Epoch 95] Train Loss=0.19440904259681702 Test Acc=0.7305555555555555 T=1.450000000000017s
Output Distribution={2: 229, 1: 54, 0: 77}, Acc: 0.7305555555555555, Macro-F1: 0.6451851851851852
[Epoch 96] Train Loss=0.20031167566776276 Test Acc=0.7305555555555555 T=1.4800000000000182s
Output Distribution={2: 231, 1: 53, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.6481705707168536
[Epoch 97] Train Loss=0.19725432991981506 Test Acc=0.7333333333333333 T=1.460000000000008s
Output Distribution={2: 229, 1: 53, 0: 78}, Acc: 0.7361111111111112, Macro-F1: 0.6511577346170255
[Epoch 98] Train Loss=0.1956615000963211 Test Acc=0.7361111111111112 T=1.4599999999999795s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6526187567538029
[Epoch 99] Train Loss=0.20185397565364838 Test Acc=0.7388888888888889 T=1.4499999999999886s
Output Distribution={2: 788, 0: 200, 1: 132}, Acc: 0.7053571428571429, Macro-F1: 0.5662991868185253
accuracy:0.7053571428571429, macro_f1:0.5662991868185253
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2afbdbb728c8>
>>> learning_rate: 0.001
>>> num_epoch: 100
>>> batch_size: 16
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.7
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 343, 0: 17}, Acc: 0.6222222222222222, Macro-F1: 0.3083530338849488
[Epoch 0] Train Loss=0.9315508008003235 Test Acc=0.6222222222222222 T=2.01s
Output Distribution={2: 320, 0: 35, 1: 5}, Acc: 0.6361111111111111, Macro-F1: 0.3758333759201566
[Epoch 1] Train Loss=0.7857024073600769 Test Acc=0.6361111111111111 T=1.9600000000000009s
Output Distribution={2: 276, 0: 70, 1: 14}, Acc: 0.6944444444444444, Macro-F1: 0.5251580579045368
[Epoch 2] Train Loss=0.7117084860801697 Test Acc=0.6944444444444444 T=1.9800000000000004s
Output Distribution={2: 266, 0: 80, 1: 14}, Acc: 0.6972222222222222, Macro-F1: 0.5238141571937924
[Epoch 3] Train Loss=0.648929238319397 Test Acc=0.6972222222222222 T=1.7800000000000011s
Output Distribution={2: 265, 0: 68, 1: 27}, Acc: 0.7194444444444444, Macro-F1: 0.5838085473561718
[Epoch 4] Train Loss=0.5973145365715027 Test Acc=0.7194444444444444 T=1.9400000000000013s
Output Distribution={2: 259, 0: 79, 1: 22}, Acc: 0.7194444444444444, Macro-F1: 0.5785951621477937
[Epoch 5] Train Loss=0.5516290664672852 Test Acc=0.7194444444444444 T=1.9299999999999997s
Output Distribution={2: 245, 0: 79, 1: 36}, Acc: 0.7194444444444444, Macro-F1: 0.6018660005226396
[Epoch 6] Train Loss=0.5100832581520081 Test Acc=0.7194444444444444 T=1.5799999999999983s
Output Distribution={2: 248, 0: 76, 1: 36}, Acc: 0.725, Macro-F1: 0.614791550865229
[Epoch 7] Train Loss=0.483109712600708 Test Acc=0.725 T=1.5599999999999987s
Output Distribution={2: 245, 0: 72, 1: 43}, Acc: 0.725, Macro-F1: 0.6235479889696448
[Epoch 8] Train Loss=0.45689886808395386 Test Acc=0.725 T=1.8000000000000007s
Output Distribution={2: 245, 1: 49, 0: 66}, Acc: 0.7305555555555555, Macro-F1: 0.6418682930125391
[Epoch 9] Train Loss=0.43351900577545166 Test Acc=0.7305555555555555 T=1.5700000000000003s
Output Distribution={2: 244, 1: 52, 0: 64}, Acc: 0.7333333333333333, Macro-F1: 0.6464909538448986
[Epoch 10] Train Loss=0.4099314212799072 Test Acc=0.7333333333333333 T=1.730000000000004s
Output Distribution={2: 244, 1: 51, 0: 65}, Acc: 0.7305555555555555, Macro-F1: 0.64087939487659
[Epoch 11] Train Loss=0.39186978340148926 Test Acc=0.7305555555555555 T=1.7100000000000009s
Output Distribution={2: 244, 1: 50, 0: 66}, Acc: 0.7333333333333333, Macro-F1: 0.6457589879153408
[Epoch 12] Train Loss=0.3733804523944855 Test Acc=0.7333333333333333 T=1.5600000000000023s
Output Distribution={2: 239, 1: 49, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.655672163918041
[Epoch 13] Train Loss=0.3636826276779175 Test Acc=0.7388888888888889 T=1.6599999999999966s
Output Distribution={2: 235, 1: 48, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6605263157894736
[Epoch 14] Train Loss=0.35660916566848755 Test Acc=0.7416666666666667 T=1.7899999999999991s
Output Distribution={2: 238, 1: 46, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.6469017261391258
[Epoch 15] Train Loss=0.34201306104660034 Test Acc=0.7333333333333333 T=1.8100000000000023s
Output Distribution={2: 236, 1: 47, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6570751491601204
[Epoch 16] Train Loss=0.3301466405391693 Test Acc=0.7388888888888889 T=1.5900000000000034s
Output Distribution={2: 236, 1: 48, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6567832968034859
[Epoch 17] Train Loss=0.3296356201171875 Test Acc=0.7388888888888889 T=1.5399999999999991s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6551649899725972
[Epoch 18] Train Loss=0.3187122046947479 Test Acc=0.7388888888888889 T=1.6400000000000006s
Output Distribution={2: 238, 1: 51, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6541952963521591
[Epoch 19] Train Loss=0.2984904646873474 Test Acc=0.7361111111111112 T=1.5899999999999963s
Output Distribution={2: 239, 1: 51, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6564012477055955
[Epoch 20] Train Loss=0.30467689037323 Test Acc=0.7388888888888889 T=1.5600000000000023s
Output Distribution={2: 240, 1: 48, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6607874812070693
[Epoch 21] Train Loss=0.3025912344455719 Test Acc=0.7444444444444445 T=1.5s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6701667530479617
[Epoch 22] Train Loss=0.28778302669525146 Test Acc=0.7472222222222222 T=1.8399999999999963s
Output Distribution={2: 241, 1: 48, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6615212273107011
[Epoch 23] Train Loss=0.28811922669410706 Test Acc=0.7444444444444445 T=1.8500000000000014s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.656377758497319
[Epoch 24] Train Loss=0.2876421809196472 Test Acc=0.7388888888888889 T=1.5899999999999963s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6590069111977899
[Epoch 25] Train Loss=0.28113222122192383 Test Acc=0.7416666666666667 T=1.5799999999999983s
Output Distribution={2: 233, 1: 51, 0: 76}, Acc: 0.75, Macro-F1: 0.6713147959045721
[Epoch 26] Train Loss=0.2630234956741333 Test Acc=0.75 T=1.5399999999999991s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6613054956880623
[Epoch 27] Train Loss=0.268661767244339 Test Acc=0.7416666666666667 T=1.7299999999999969s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6579906270789568
[Epoch 28] Train Loss=0.2658955752849579 Test Acc=0.7388888888888889 T=1.5399999999999991s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6555988838202994
[Epoch 29] Train Loss=0.2672753632068634 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 232, 1: 53, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.65038729530354
[Epoch 30] Train Loss=0.26217785477638245 Test Acc=0.7361111111111112 T=1.5200000000000102s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6637495117134098
[Epoch 31] Train Loss=0.2505495250225067 Test Acc=0.7416666666666667 T=1.539999999999992s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.645915941050979
[Epoch 32] Train Loss=0.25976133346557617 Test Acc=0.7333333333333333 T=1.5400000000000063s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7305555555555555, Macro-F1: 0.6462138453031726
[Epoch 33] Train Loss=0.25334814190864563 Test Acc=0.7305555555555555 T=1.5200000000000102s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553239999900762
[Epoch 34] Train Loss=0.2478921115398407 Test Acc=0.7361111111111112 T=1.5300000000000011s
Output Distribution={2: 228, 1: 62, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6618966941558813
[Epoch 35] Train Loss=0.2527744770050049 Test Acc=0.7388888888888889 T=1.509999999999991s
Output Distribution={2: 233, 1: 58, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6568303287585873
[Epoch 36] Train Loss=0.24813102185726166 Test Acc=0.7361111111111112 T=1.519999999999996s
Output Distribution={2: 232, 1: 58, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6675412697630172
[Epoch 37] Train Loss=0.24498771131038666 Test Acc=0.7444444444444445 T=1.519999999999996s
Output Distribution={2: 230, 1: 53, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6563352732075831
[Epoch 38] Train Loss=0.24033209681510925 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 227, 1: 56, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6635141816289357
[Epoch 39] Train Loss=0.24119041860103607 Test Acc=0.7416666666666667 T=1.7800000000000011s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7305555555555555, Macro-F1: 0.6484032205199776
[Epoch 40] Train Loss=0.2362380027770996 Test Acc=0.7305555555555555 T=1.9300000000000068s
Output Distribution={2: 228, 1: 59, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6500010779916813
[Epoch 41] Train Loss=0.23857147991657257 Test Acc=0.7305555555555555 T=1.6200000000000045s
Output Distribution={2: 229, 1: 55, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6521411799508199
[Epoch 42] Train Loss=0.23682482540607452 Test Acc=0.7361111111111112 T=1.6499999999999915s
Output Distribution={2: 225, 1: 59, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.666671562283685
[Epoch 43] Train Loss=0.2307327687740326 Test Acc=0.7416666666666667 T=1.5600000000000023s
Output Distribution={2: 227, 1: 56, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6590697371844914
[Epoch 44] Train Loss=0.231681227684021 Test Acc=0.7388888888888889 T=1.740000000000009s
Output Distribution={2: 229, 1: 53, 0: 78}, Acc: 0.7361111111111112, Macro-F1: 0.6511577346170255
[Epoch 45] Train Loss=0.2302711308002472 Test Acc=0.7361111111111112 T=1.730000000000004s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6452457518933509
[Epoch 46] Train Loss=0.22692807018756866 Test Acc=0.7305555555555555 T=1.6000000000000085s
Output Distribution={2: 229, 1: 53, 0: 78}, Acc: 0.7333333333333333, Macro-F1: 0.6496762531355441
[Epoch 47] Train Loss=0.22843429446220398 Test Acc=0.7333333333333333 T=1.5499999999999972s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6475982848061729
[Epoch 48] Train Loss=0.23838108777999878 Test Acc=0.7305555555555555 T=1.5400000000000063s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6528596971848243
[Epoch 49] Train Loss=0.21318724751472473 Test Acc=0.7361111111111112 T=1.5300000000000011s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.654436189649727
[Epoch 50] Train Loss=0.2231951504945755 Test Acc=0.7388888888888889 T=1.5200000000000102s
Output Distribution={2: 237, 1: 49, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6531291612904893
[Epoch 51] Train Loss=0.2250988930463791 Test Acc=0.7416666666666667 T=1.5300000000000011s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6689600501447192
[Epoch 52] Train Loss=0.23459377884864807 Test Acc=0.7472222222222222 T=1.5100000000000051s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6633704039908002
[Epoch 53] Train Loss=0.22658675909042358 Test Acc=0.7444444444444445 T=1.5300000000000011s
Output Distribution={2: 227, 1: 63, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.66526270886736
[Epoch 54] Train Loss=0.2245447188615799 Test Acc=0.7416666666666667 T=1.6599999999999966s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6720360869879
[Epoch 55] Train Loss=0.22320382297039032 Test Acc=0.7472222222222222 T=1.7399999999999949s
Output Distribution={2: 230, 1: 53, 0: 77}, Acc: 0.7444444444444445, Macro-F1: 0.6616072593117069
[Epoch 56] Train Loss=0.2218364030122757 Test Acc=0.7444444444444445 T=1.5900000000000034s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6706186489013084
[Epoch 57] Train Loss=0.22235994040966034 Test Acc=0.7472222222222222 T=1.5799999999999983s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6576463839878273
[Epoch 58] Train Loss=0.22110526263713837 Test Acc=0.7388888888888889 T=1.509999999999991s
Output Distribution={2: 228, 1: 55, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6613765924071654
[Epoch 59] Train Loss=0.21421557664871216 Test Acc=0.7416666666666667 T=1.8200000000000074s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.666135802671833
[Epoch 60] Train Loss=0.21800759434700012 Test Acc=0.7444444444444445 T=1.5899999999999892s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6645014697661481
[Epoch 61] Train Loss=0.21436668932437897 Test Acc=0.7444444444444445 T=1.5500000000000114s
Output Distribution={2: 237, 1: 49, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6587326127210584
[Epoch 62] Train Loss=0.2239246815443039 Test Acc=0.7416666666666667 T=1.5300000000000011s
Output Distribution={2: 227, 1: 61, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6492033054057899
[Epoch 63] Train Loss=0.21317261457443237 Test Acc=0.7305555555555555 T=1.5300000000000011s
Output Distribution={2: 229, 1: 62, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6589612676056338
[Epoch 64] Train Loss=0.22330504655838013 Test Acc=0.7388888888888889 T=1.539999999999992s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6513295057908387
[Epoch 65] Train Loss=0.22049547731876373 Test Acc=0.7361111111111112 T=1.5499999999999972s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6533997295065609
[Epoch 66] Train Loss=0.21750393509864807 Test Acc=0.7416666666666667 T=1.5400000000000063s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.659868596675692
[Epoch 67] Train Loss=0.21988952159881592 Test Acc=0.7416666666666667 T=1.519999999999996s
Output Distribution={2: 232, 1: 58, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6621649256769958
[Epoch 68] Train Loss=0.21848931908607483 Test Acc=0.7416666666666667 T=1.8400000000000034s
Output Distribution={2: 234, 1: 58, 0: 68}, Acc: 0.7444444444444445, Macro-F1: 0.6653106597512912
[Epoch 69] Train Loss=0.21416720747947693 Test Acc=0.7444444444444445 T=1.5699999999999932s
Output Distribution={2: 228, 1: 55, 0: 77}, Acc: 0.7472222222222222, Macro-F1: 0.6662406204175794
[Epoch 70] Train Loss=0.21854688227176666 Test Acc=0.7472222222222222 T=1.5300000000000011s
Output Distribution={2: 236, 1: 52, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6589864100698232
[Epoch 71] Train Loss=0.21195781230926514 Test Acc=0.7444444444444445 T=1.5300000000000011s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.659802374659289
[Epoch 72] Train Loss=0.21941450238227844 Test Acc=0.7416666666666667 T=1.5400000000000205s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6528030176453319
[Epoch 73] Train Loss=0.219014510512352 Test Acc=0.7388888888888889 T=1.5400000000000205s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6541325541176208
[Epoch 74] Train Loss=0.21397560834884644 Test Acc=0.7416666666666667 T=1.5299999999999727s
Output Distribution={2: 227, 1: 57, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6506139620959969
[Epoch 75] Train Loss=0.2168387472629547 Test Acc=0.7361111111111112 T=1.5200000000000102s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6448101094742533
[Epoch 76] Train Loss=0.20536571741104126 Test Acc=0.7333333333333333 T=1.5300000000000011s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6473711163289877
[Epoch 77] Train Loss=0.21419782936573029 Test Acc=0.7333333333333333 T=1.5s
Output Distribution={2: 228, 1: 55, 0: 77}, Acc: 0.7333333333333333, Macro-F1: 0.6488725276658057
[Epoch 78] Train Loss=0.2089013159275055 Test Acc=0.7333333333333333 T=1.5199999999999818s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6475681654775731
[Epoch 79] Train Loss=0.20970195531845093 Test Acc=0.7333333333333333 T=1.539999999999992s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6454211060375444
[Epoch 80] Train Loss=0.20997120440006256 Test Acc=0.7305555555555555 T=1.5300000000000011s
Output Distribution={2: 231, 1: 60, 0: 69}, Acc: 0.7333333333333333, Macro-F1: 0.6499511655313724
[Epoch 81] Train Loss=0.21022024750709534 Test Acc=0.7333333333333333 T=1.5300000000000011s
Output Distribution={2: 228, 1: 60, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6560408522009015
[Epoch 82] Train Loss=0.21525366604328156 Test Acc=0.7361111111111112 T=1.549999999999983s
Output Distribution={2: 229, 1: 61, 0: 70}, Acc: 0.7305555555555555, Macro-F1: 0.6469637216093909
[Epoch 83] Train Loss=0.20985911786556244 Test Acc=0.7305555555555555 T=1.4800000000000182s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6454211060375444
[Epoch 84] Train Loss=0.2096395641565323 Test Acc=0.7305555555555555 T=1.5600000000000023s
Output Distribution={2: 229, 1: 62, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6537529342723004
[Epoch 85] Train Loss=0.20862148702144623 Test Acc=0.7361111111111112 T=1.5199999999999818s
Output Distribution={2: 233, 1: 58, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6504829269301565
[Epoch 86] Train Loss=0.20730151236057281 Test Acc=0.7388888888888889 T=1.5500000000000114s
Output Distribution={2: 231, 1: 61, 0: 68}, Acc: 0.7416666666666667, Macro-F1: 0.658248953582365
[Epoch 87] Train Loss=0.2074316293001175 Test Acc=0.7416666666666667 T=1.5500000000000114s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6474744496066804
[Epoch 88] Train Loss=0.2094489485025406 Test Acc=0.7333333333333333 T=1.509999999999991s
Output Distribution={2: 238, 1: 51, 0: 71}, Acc: 0.7277777777777777, Macro-F1: 0.6360329031897659
[Epoch 89] Train Loss=0.2088078260421753 Test Acc=0.7277777777777777 T=1.5400000000000205s
Output Distribution={2: 228, 1: 62, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6576268131460224
[Epoch 90] Train Loss=0.20795410871505737 Test Acc=0.7388888888888889 T=1.5200000000000102s
Output Distribution={2: 230, 1: 61, 0: 69}, Acc: 0.7305555555555555, Macro-F1: 0.6445412586441591
[Epoch 91] Train Loss=0.20933879911899567 Test Acc=0.7305555555555555 T=1.5200000000000102s
Output Distribution={2: 236, 1: 57, 0: 67}, Acc: 0.7333333333333333, Macro-F1: 0.6466504183641398
[Epoch 92] Train Loss=0.20991070568561554 Test Acc=0.7333333333333333 T=1.509999999999991s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7277777777777777, Macro-F1: 0.6363066308111087
[Epoch 93] Train Loss=0.20777559280395508 Test Acc=0.7277777777777777 T=1.5200000000000102s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.646589575201841
[Epoch 94] Train Loss=0.2049942910671234 Test Acc=0.7333333333333333 T=1.5300000000000011s
Output Distribution={2: 238, 1: 54, 0: 68}, Acc: 0.7305555555555555, Macro-F1: 0.6385597737913132
[Epoch 95] Train Loss=0.2100682407617569 Test Acc=0.7305555555555555 T=1.539999999999992s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7277777777777777, Macro-F1: 0.6399756348644303
[Epoch 96] Train Loss=0.20500321686267853 Test Acc=0.7277777777777777 T=1.5300000000000011s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7333333333333333, Macro-F1: 0.6506829249925844
[Epoch 97] Train Loss=0.2131059169769287 Test Acc=0.7333333333333333 T=1.5400000000000205s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.651465464929207
[Epoch 98] Train Loss=0.20360976457595825 Test Acc=0.7333333333333333 T=1.5299999999999727s
Output Distribution={2: 234, 1: 56, 0: 70}, Acc: 0.7277777777777777, Macro-F1: 0.6413237036187857
[Epoch 99] Train Loss=0.20894595980644226 Test Acc=0.7277777777777777 T=1.5100000000000193s
Output Distribution={2: 798, 0: 200, 1: 122}, Acc: 0.7223214285714286, Macro-F1: 0.5855667966625211
accuracy:0.7223214285714286, macro_f1:0.5855667966625211
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2ae1ab4778c8>
>>> learning_rate: 0.0005
>>> num_epoch: 100
>>> batch_size: 16
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.7
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 359, 0: 1}, Acc: 0.6111111111111112, Macro-F1: 0.2528735632183908
[Epoch 0] Train Loss=0.984168291091919 Test Acc=0.6111111111111112 T=1.75s
Output Distribution={2: 353, 0: 7}, Acc: 0.6138888888888889, Macro-F1: 0.2710220673635308
[Epoch 1] Train Loss=0.8513398766517639 Test Acc=0.6138888888888889 T=2.0400000000000027s
Output Distribution={2: 321, 0: 38, 1: 1}, Acc: 0.6333333333333333, Macro-F1: 0.3655789401782683
[Epoch 2] Train Loss=0.8027675151824951 Test Acc=0.6333333333333333 T=1.8800000000000026s
Output Distribution={2: 309, 0: 49, 1: 2}, Acc: 0.6472222222222223, Macro-F1: 0.39851288489413705
[Epoch 3] Train Loss=0.7568209767341614 Test Acc=0.6472222222222223 T=1.8900000000000006s
Output Distribution={2: 302, 0: 50, 1: 8}, Acc: 0.65, Macro-F1: 0.4240032132118127
[Epoch 4] Train Loss=0.716370165348053 Test Acc=0.65 T=2.039999999999999s
Output Distribution={2: 287, 0: 61, 1: 12}, Acc: 0.675, Macro-F1: 0.48299588269032384
[Epoch 5] Train Loss=0.6784042119979858 Test Acc=0.675 T=1.860000000000003s
Output Distribution={2: 274, 0: 68, 1: 18}, Acc: 0.7, Macro-F1: 0.5400253804509124
[Epoch 6] Train Loss=0.642302930355072 Test Acc=0.7 T=1.9399999999999977s
Output Distribution={2: 269, 0: 72, 1: 19}, Acc: 0.7083333333333334, Macro-F1: 0.5542327275737882
[Epoch 7] Train Loss=0.615777850151062 Test Acc=0.7083333333333334 T=1.8499999999999979s
Output Distribution={2: 273, 0: 63, 1: 24}, Acc: 0.7194444444444444, Macro-F1: 0.5803992132165506
[Epoch 8] Train Loss=0.5924022197723389 Test Acc=0.7194444444444444 T=1.6999999999999993s
Output Distribution={2: 261, 0: 71, 1: 28}, Acc: 0.7277777777777777, Macro-F1: 0.6031740776708553
[Epoch 9] Train Loss=0.5654754042625427 Test Acc=0.7277777777777777 T=1.870000000000001s
Output Distribution={2: 255, 0: 72, 1: 33}, Acc: 0.7166666666666667, Macro-F1: 0.5927019641015584
[Epoch 10] Train Loss=0.5398350954055786 Test Acc=0.7166666666666667 T=1.7800000000000011s
Output Distribution={2: 253, 0: 73, 1: 34}, Acc: 0.7194444444444444, Macro-F1: 0.6011294144847119
[Epoch 11] Train Loss=0.5202312469482422 Test Acc=0.7194444444444444 T=1.5399999999999991s
Output Distribution={2: 251, 0: 73, 1: 36}, Acc: 0.725, Macro-F1: 0.6106664784945012
[Epoch 12] Train Loss=0.49928921461105347 Test Acc=0.725 T=1.5100000000000051s
Output Distribution={2: 247, 0: 74, 1: 39}, Acc: 0.725, Macro-F1: 0.6125995697424269
[Epoch 13] Train Loss=0.4847707450389862 Test Acc=0.725 T=1.490000000000002s
Output Distribution={2: 244, 0: 78, 1: 38}, Acc: 0.7277777777777777, Macro-F1: 0.6182849562789746
[Epoch 14] Train Loss=0.4781399369239807 Test Acc=0.7277777777777777 T=1.470000000000006s
Output Distribution={2: 245, 0: 75, 1: 40}, Acc: 0.725, Macro-F1: 0.6191025424971492
[Epoch 15] Train Loss=0.45944520831108093 Test Acc=0.725 T=1.480000000000004s
Output Distribution={2: 244, 0: 75, 1: 41}, Acc: 0.7222222222222222, Macro-F1: 0.6168581001864089
[Epoch 16] Train Loss=0.442657470703125 Test Acc=0.7222222222222222 T=1.6100000000000065s
Output Distribution={2: 244, 0: 73, 1: 43}, Acc: 0.7305555555555555, Macro-F1: 0.6335046394081449
[Epoch 17] Train Loss=0.43961864709854126 Test Acc=0.7305555555555555 T=1.5100000000000051s
Output Distribution={2: 246, 0: 71, 1: 43}, Acc: 0.7277777777777777, Macro-F1: 0.6304108904299462
[Epoch 18] Train Loss=0.423936128616333 Test Acc=0.7277777777777777 T=1.7199999999999989s
Output Distribution={2: 242, 1: 46, 0: 72}, Acc: 0.725, Macro-F1: 0.6302756173594782
[Epoch 19] Train Loss=0.40575504302978516 Test Acc=0.725 T=1.519999999999996s
Output Distribution={2: 243, 1: 50, 0: 67}, Acc: 0.7277777777777777, Macro-F1: 0.6377668308702792
[Epoch 20] Train Loss=0.4040789008140564 Test Acc=0.7277777777777777 T=1.509999999999998s
Output Distribution={2: 242, 1: 46, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6408256994612844
[Epoch 21] Train Loss=0.4008239507675171 Test Acc=0.7305555555555555 T=1.4799999999999969s
Output Distribution={2: 239, 1: 47, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6534339476460073
[Epoch 22] Train Loss=0.3777594268321991 Test Acc=0.7388888888888889 T=1.5s
Output Distribution={2: 244, 1: 46, 0: 70}, Acc: 0.7333333333333333, Macro-F1: 0.6438353760934405
[Epoch 23] Train Loss=0.37566348910331726 Test Acc=0.7333333333333333 T=1.7199999999999989s
Output Distribution={2: 241, 1: 48, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.651793625477836
[Epoch 24] Train Loss=0.373455286026001 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 243, 1: 46, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6504287538770298
[Epoch 25] Train Loss=0.3669598698616028 Test Acc=0.7388888888888889 T=1.5200000000000031s
Output Distribution={2: 239, 1: 48, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6558944512362901
[Epoch 26] Train Loss=0.34791693091392517 Test Acc=0.7388888888888889 T=1.480000000000004s
Output Distribution={2: 241, 1: 48, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6588599022809549
[Epoch 27] Train Loss=0.34692147374153137 Test Acc=0.7416666666666667 T=1.480000000000004s
Output Distribution={2: 236, 1: 49, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6623341827223476
[Epoch 28] Train Loss=0.3425520360469818 Test Acc=0.7416666666666667 T=1.7399999999999949s
Output Distribution={2: 236, 1: 49, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6623341827223476
[Epoch 29] Train Loss=0.3418804705142975 Test Acc=0.7416666666666667 T=1.5300000000000011s
Output Distribution={2: 237, 1: 49, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6527418612530766
[Epoch 30] Train Loss=0.3328946828842163 Test Acc=0.7361111111111112 T=1.5s
Output Distribution={2: 238, 1: 49, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6503580692418587
[Epoch 31] Train Loss=0.3186282515525818 Test Acc=0.7361111111111112 T=1.490000000000009s
Output Distribution={2: 240, 1: 48, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6639390507585191
[Epoch 32] Train Loss=0.32972872257232666 Test Acc=0.7444444444444445 T=1.480000000000004s
Output Distribution={2: 239, 1: 48, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6631916798149832
[Epoch 33] Train Loss=0.3182198703289032 Test Acc=0.7444444444444445 T=1.769999999999996s
Output Distribution={2: 240, 1: 49, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6590550892305113
[Epoch 34] Train Loss=0.31315648555755615 Test Acc=0.7416666666666667 T=1.5700000000000074s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6649907345729269
[Epoch 35] Train Loss=0.3133715093135834 Test Acc=0.7444444444444445 T=1.730000000000004s
Output Distribution={2: 239, 1: 49, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6629185407296352
[Epoch 36] Train Loss=0.308694064617157 Test Acc=0.7444444444444445 T=1.4599999999999937s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6610129431889714
[Epoch 37] Train Loss=0.2973320782184601 Test Acc=0.7416666666666667 T=1.4599999999999937s
Output Distribution={2: 239, 1: 48, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6631916798149832
[Epoch 38] Train Loss=0.2965145707130432 Test Acc=0.7444444444444445 T=1.4500000000000028s
Output Distribution={2: 238, 1: 49, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6607213807367961
[Epoch 39] Train Loss=0.2916780710220337 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.75, Macro-F1: 0.671500001031368
[Epoch 40] Train Loss=0.28728345036506653 Test Acc=0.75 T=1.480000000000004s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.75, Macro-F1: 0.671500001031368
[Epoch 41] Train Loss=0.2883341610431671 Test Acc=0.75 T=1.8299999999999983s
Output Distribution={2: 237, 1: 51, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6652113199922266
[Epoch 42] Train Loss=0.2815396189689636 Test Acc=0.7444444444444445 T=1.519999999999996s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6690349573956181
[Epoch 43] Train Loss=0.2745671272277832 Test Acc=0.7472222222222222 T=1.5300000000000011s
Output Distribution={2: 238, 1: 50, 0: 72}, Acc: 0.7472222222222222, Macro-F1: 0.6676758570605764
[Epoch 44] Train Loss=0.2741468548774719 Test Acc=0.7472222222222222 T=1.4899999999999949s
Output Distribution={2: 238, 1: 49, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.66674002360744
[Epoch 45] Train Loss=0.2731044292449951 Test Acc=0.7472222222222222 T=1.4500000000000028s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6611525701898694
[Epoch 46] Train Loss=0.26717647910118103 Test Acc=0.7444444444444445 T=1.480000000000004s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6565221982977527
[Epoch 47] Train Loss=0.27149641513824463 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6618148650869906
[Epoch 48] Train Loss=0.2770175039768219 Test Acc=0.7416666666666667 T=1.480000000000004s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6596092599315807
[Epoch 49] Train Loss=0.25353455543518066 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 238, 1: 51, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6571001620021227
[Epoch 50] Train Loss=0.262336790561676 Test Acc=0.7416666666666667 T=1.8100000000000023s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6566174227975791
[Epoch 51] Train Loss=0.2611357271671295 Test Acc=0.7416666666666667 T=1.6300000000000097s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.657962036911895
[Epoch 52] Train Loss=0.26424363255500793 Test Acc=0.7388888888888889 T=1.5300000000000011s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6632222783870955
[Epoch 53] Train Loss=0.25847572088241577 Test Acc=0.7444444444444445 T=1.8499999999999943s
Output Distribution={2: 229, 1: 56, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6684950524294786
[Epoch 54] Train Loss=0.2577512264251709 Test Acc=0.7444444444444445 T=1.519999999999996s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6730282077394903
[Epoch 55] Train Loss=0.25572898983955383 Test Acc=0.7472222222222222 T=1.5s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6548910329398134
[Epoch 56] Train Loss=0.2544229030609131 Test Acc=0.7361111111111112 T=1.5s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.657962036911895
[Epoch 57] Train Loss=0.24896103143692017 Test Acc=0.7388888888888889 T=1.4899999999999949s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.655435962762832
[Epoch 58] Train Loss=0.2479468733072281 Test Acc=0.7361111111111112 T=1.460000000000008s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6502325334183742
[Epoch 59] Train Loss=0.23894865810871124 Test Acc=0.7333333333333333 T=1.480000000000004s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.657263015227617
[Epoch 60] Train Loss=0.24534972012043 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.657263015227617
[Epoch 61] Train Loss=0.23900984227657318 Test Acc=0.7388888888888889 T=1.480000000000004s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.655435962762832
[Epoch 62] Train Loss=0.2466101199388504 Test Acc=0.7361111111111112 T=1.5s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6522849053206986
[Epoch 63] Train Loss=0.23883876204490662 Test Acc=0.7333333333333333 T=1.4599999999999937s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6575530012771392
[Epoch 64] Train Loss=0.2464975118637085 Test Acc=0.7361111111111112 T=1.480000000000004s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6499714818885151
[Epoch 65] Train Loss=0.2416900247335434 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6522849053206986
[Epoch 66] Train Loss=0.23999181389808655 Test Acc=0.7333333333333333 T=1.490000000000009s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6545879780092945
[Epoch 67] Train Loss=0.24206866323947906 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553239999900762
[Epoch 68] Train Loss=0.240264892578125 Test Acc=0.7361111111111112 T=1.490000000000009s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6521819031135104
[Epoch 69] Train Loss=0.2362383008003235 Test Acc=0.7361111111111112 T=1.519999999999996s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6629434212709474
[Epoch 70] Train Loss=0.23839734494686127 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6620537544872138
[Epoch 71] Train Loss=0.2315855324268341 Test Acc=0.7444444444444445 T=1.5s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.656701295337659
[Epoch 72] Train Loss=0.23963378369808197 Test Acc=0.7416666666666667 T=1.5s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.651106521818826
[Epoch 73] Train Loss=0.23270048201084137 Test Acc=0.7388888888888889 T=1.4800000000000182s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.651106521818826
[Epoch 74] Train Loss=0.23389238119125366 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 228, 1: 56, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6613035508058028
[Epoch 75] Train Loss=0.23385290801525116 Test Acc=0.7416666666666667 T=1.4699999999999989s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.659797886294072
[Epoch 76] Train Loss=0.2230972945690155 Test Acc=0.7416666666666667 T=1.4499999999999886s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6473687472881671
[Epoch 77] Train Loss=0.22994518280029297 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.656839147664117
[Epoch 78] Train Loss=0.2254990041255951 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6521819031135104
[Epoch 79] Train Loss=0.22512197494506836 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6499039457895343
[Epoch 80] Train Loss=0.2231006771326065 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6475015159256939
[Epoch 81] Train Loss=0.22680029273033142 Test Acc=0.7333333333333333 T=1.5100000000000193s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6545376919341771
[Epoch 82] Train Loss=0.2290465235710144 Test Acc=0.7361111111111112 T=1.6899999999999977s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6568511153663606
[Epoch 83] Train Loss=0.2260439246892929 Test Acc=0.7361111111111112 T=1.6100000000000136s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6522196679438058
[Epoch 84] Train Loss=0.22385181486606598 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6521957671957672
[Epoch 85] Train Loss=0.22099439799785614 Test Acc=0.7333333333333333 T=1.4799999999999898s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6529750349018641
[Epoch 86] Train Loss=0.2197033017873764 Test Acc=0.7333333333333333 T=1.4699999999999989s
Output Distribution={2: 230, 1: 60, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6544485324973129
[Epoch 87] Train Loss=0.22055797278881073 Test Acc=0.7361111111111112 T=1.4399999999999977s
Output Distribution={2: 231, 1: 59, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6598892670751079
[Epoch 88] Train Loss=0.2245451807975769 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.657568560110627
[Epoch 89] Train Loss=0.22186420857906342 Test Acc=0.7388888888888889 T=1.4699999999999989s
Output Distribution={2: 230, 1: 60, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6544485324973129
[Epoch 90] Train Loss=0.22217868268489838 Test Acc=0.7361111111111112 T=1.4699999999999989s
Output Distribution={2: 230, 1: 60, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6544485324973129
[Epoch 91] Train Loss=0.22203244268894196 Test Acc=0.7361111111111112 T=1.4899999999999807s
Output Distribution={2: 237, 1: 54, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6480205834717183
[Epoch 92] Train Loss=0.22306735813617706 Test Acc=0.7361111111111112 T=1.4400000000000261s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7305555555555555, Macro-F1: 0.6420099687323635
[Epoch 93] Train Loss=0.2178114354610443 Test Acc=0.7305555555555555 T=1.4700000000000273s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7277777777777777, Macro-F1: 0.6398213954545726
[Epoch 94] Train Loss=0.21721547842025757 Test Acc=0.7277777777777777 T=1.460000000000008s
Output Distribution={2: 234, 1: 58, 0: 68}, Acc: 0.7333333333333333, Macro-F1: 0.6483646377263398
[Epoch 95] Train Loss=0.21823939681053162 Test Acc=0.7333333333333333 T=1.460000000000008s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6498710792847443
[Epoch 96] Train Loss=0.2173490822315216 Test Acc=0.7333333333333333 T=1.740000000000009s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6553851319839566
[Epoch 97] Train Loss=0.2234940379858017 Test Acc=0.7361111111111112 T=1.8799999999999955s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6522428221551909
[Epoch 98] Train Loss=0.2134980410337448 Test Acc=0.7333333333333333 T=1.5300000000000011s
Output Distribution={2: 234, 1: 56, 0: 70}, Acc: 0.7333333333333333, Macro-F1: 0.6474509097459918
[Epoch 99] Train Loss=0.21851743757724762 Test Acc=0.7333333333333333 T=1.5400000000000205s
Output Distribution={2: 810, 0: 193, 1: 117}, Acc: 0.7330357142857142, Macro-F1: 0.5972174162768417
accuracy:0.7330357142857142, macro_f1:0.5972174162768417
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2ac9fe6728c8>
>>> learning_rate: 0.001
>>> num_epoch: 100
>>> batch_size: 32
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.3
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 346, 0: 14}, Acc: 0.6138888888888889, Macro-F1: 0.2857953739179793
[Epoch 0] Train Loss=0.918972373008728 Test Acc=0.6138888888888889 T=1.1900000000000013s
Output Distribution={2: 313, 0: 40, 1: 7}, Acc: 0.6555555555555556, Macro-F1: 0.422425659282425
[Epoch 1] Train Loss=0.7695943713188171 Test Acc=0.6555555555555556 T=1.5199999999999996s
Output Distribution={2: 266, 0: 77, 1: 17}, Acc: 0.7111111111111111, Macro-F1: 0.5539362652526602
[Epoch 2] Train Loss=0.6739505529403687 Test Acc=0.7111111111111111 T=1.3599999999999994s
Output Distribution={2: 260, 0: 82, 1: 18}, Acc: 0.7138888888888889, Macro-F1: 0.56087697055439
[Epoch 3] Train Loss=0.5957731604576111 Test Acc=0.7138888888888889 T=1.3500000000000014s
Output Distribution={2: 255, 0: 72, 1: 33}, Acc: 0.7222222222222222, Macro-F1: 0.6040336719849905
[Epoch 4] Train Loss=0.5329549908638 Test Acc=0.7222222222222222 T=1.3100000000000023s
Output Distribution={2: 252, 0: 76, 1: 32}, Acc: 0.7194444444444444, Macro-F1: 0.5962409312093809
[Epoch 5] Train Loss=0.4804099500179291 Test Acc=0.7194444444444444 T=1.3999999999999986s
Output Distribution={2: 242, 0: 77, 1: 41}, Acc: 0.7194444444444444, Macro-F1: 0.6123110599750151
[Epoch 6] Train Loss=0.44147151708602905 Test Acc=0.7194444444444444 T=1.0800000000000018s
Output Distribution={2: 246, 0: 74, 1: 40}, Acc: 0.7222222222222222, Macro-F1: 0.6166104651764682
[Epoch 7] Train Loss=0.4033157527446747 Test Acc=0.7222222222222222 T=1.0199999999999996s
Output Distribution={2: 242, 1: 47, 0: 71}, Acc: 0.7277777777777777, Macro-F1: 0.6360940682267543
[Epoch 8] Train Loss=0.38003745675086975 Test Acc=0.7277777777777777 T=1.0199999999999996s
Output Distribution={2: 239, 1: 46, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6490781153824633
[Epoch 9] Train Loss=0.3540187180042267 Test Acc=0.7361111111111112 T=1.3399999999999999s
Output Distribution={2: 239, 1: 50, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6523155089122106
[Epoch 10] Train Loss=0.33328568935394287 Test Acc=0.7388888888888889 T=1.2300000000000004s
Output Distribution={2: 239, 1: 48, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6558944512362901
[Epoch 11] Train Loss=0.3213948905467987 Test Acc=0.7388888888888889 T=1.3200000000000003s
Output Distribution={2: 244, 1: 47, 0: 69}, Acc: 0.7277777777777777, Macro-F1: 0.635587381618349
[Epoch 12] Train Loss=0.3042014241218567 Test Acc=0.7277777777777777 T=1.0899999999999999s
Output Distribution={2: 238, 1: 50, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6486790373876243
[Epoch 13] Train Loss=0.2899670898914337 Test Acc=0.7333333333333333 T=0.9899999999999984s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6643754416151512
[Epoch 14] Train Loss=0.28391334414482117 Test Acc=0.7416666666666667 T=1.009999999999998s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6455889474983626
[Epoch 15] Train Loss=0.2740418314933777 Test Acc=0.7305555555555555 T=1.3200000000000003s
Output Distribution={2: 230, 1: 52, 0: 78}, Acc: 0.75, Macro-F1: 0.6748035507579843
[Epoch 16] Train Loss=0.2589423358440399 Test Acc=0.75 T=1.0799999999999983s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6655329692406137
[Epoch 17] Train Loss=0.25396528840065 Test Acc=0.7444444444444445 T=1.3200000000000003s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.652047805716517
[Epoch 18] Train Loss=0.25147566199302673 Test Acc=0.7388888888888889 T=1.269999999999996s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.75, Macro-F1: 0.6731203707987986
[Epoch 19] Train Loss=0.24624356627464294 Test Acc=0.75 T=1.1300000000000026s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6697566324610071
[Epoch 20] Train Loss=0.2402268797159195 Test Acc=0.7472222222222222 T=1.0499999999999972s
Output Distribution={2: 233, 1: 51, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6584503557273566
[Epoch 21] Train Loss=0.2376127392053604 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6677469504903133
[Epoch 22] Train Loss=0.23673108220100403 Test Acc=0.7472222222222222 T=1.009999999999998s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7472222222222222, Macro-F1: 0.6676965513177442
[Epoch 23] Train Loss=0.23063430190086365 Test Acc=0.7472222222222222 T=1.009999999999998s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6661312418863702
[Epoch 24] Train Loss=0.23220932483673096 Test Acc=0.7416666666666667 T=1.009999999999998s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.663910163910164
[Epoch 25] Train Loss=0.2232496440410614 Test Acc=0.7416666666666667 T=1.0200000000000031s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7472222222222222, Macro-F1: 0.6677205790842153
[Epoch 26] Train Loss=0.22292514145374298 Test Acc=0.7472222222222222 T=1.009999999999998s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6683866699288998
[Epoch 27] Train Loss=0.2176772803068161 Test Acc=0.7472222222222222 T=1.0s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6629484464867624
[Epoch 28] Train Loss=0.2264222949743271 Test Acc=0.7444444444444445 T=0.990000000000002s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6605415569095956
[Epoch 29] Train Loss=0.2154579609632492 Test Acc=0.7444444444444445 T=1.009999999999998s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6706186489013084
[Epoch 30] Train Loss=0.21463847160339355 Test Acc=0.7472222222222222 T=1.009999999999998s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.75, Macro-F1: 0.6729827162358477
[Epoch 31] Train Loss=0.21231646835803986 Test Acc=0.75 T=1.2100000000000009s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6494566637571207
[Epoch 32] Train Loss=0.21692633628845215 Test Acc=0.7388888888888889 T=1.3500000000000014s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6647164725524511
[Epoch 33] Train Loss=0.21003131568431854 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6553696338848791
[Epoch 34] Train Loss=0.209355890750885 Test Acc=0.7333333333333333 T=1.0s
Output Distribution={2: 226, 1: 66, 0: 68}, Acc: 0.7305555555555555, Macro-F1: 0.6559908668290789
[Epoch 35] Train Loss=0.21009321510791779 Test Acc=0.7305555555555555 T=1.019999999999996s
Output Distribution={2: 231, 1: 61, 0: 68}, Acc: 0.7361111111111112, Macro-F1: 0.659073518653324
[Epoch 36] Train Loss=0.2112031877040863 Test Acc=0.7361111111111112 T=1.3799999999999955s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6670098670098671
[Epoch 37] Train Loss=0.21008503437042236 Test Acc=0.7472222222222222 T=1.1600000000000037s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6475982848061729
[Epoch 38] Train Loss=0.2037070244550705 Test Acc=0.7305555555555555 T=1.0500000000000043s
Output Distribution={2: 223, 1: 59, 0: 78}, Acc: 0.7388888888888889, Macro-F1: 0.6627847980430762
[Epoch 39] Train Loss=0.20776744186878204 Test Acc=0.7388888888888889 T=1.0s
Output Distribution={2: 231, 1: 60, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6637530855404469
[Epoch 40] Train Loss=0.20517562329769135 Test Acc=0.7388888888888889 T=1.0200000000000031s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6621164021164021
[Epoch 41] Train Loss=0.20418871939182281 Test Acc=0.7388888888888889 T=1.0200000000000031s
Output Distribution={2: 231, 1: 52, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6568521573921303
[Epoch 42] Train Loss=0.20419418811798096 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 227, 1: 61, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.655940744475906
[Epoch 43] Train Loss=0.20300085842609406 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6496445335147324
[Epoch 44] Train Loss=0.2089966982603073 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 228, 1: 54, 0: 78}, Acc: 0.7472222222222222, Macro-F1: 0.6703219155969196
[Epoch 45] Train Loss=0.20540745556354523 Test Acc=0.7472222222222222 T=1.0100000000000051s
Output Distribution={2: 224, 1: 64, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6650354166045759
[Epoch 46] Train Loss=0.2004735916852951 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 233, 1: 48, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.6503529381456579
[Epoch 47] Train Loss=0.2006954848766327 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 228, 1: 60, 0: 72}, Acc: 0.7277777777777777, Macro-F1: 0.6477802849202896
[Epoch 48] Train Loss=0.20937015116214752 Test Acc=0.7277777777777777 T=0.9900000000000091s
Output Distribution={2: 229, 1: 56, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6690165575411476
[Epoch 49] Train Loss=0.2019084095954895 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6560409813260013
[Epoch 50] Train Loss=0.20145128667354584 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 230, 1: 51, 0: 79}, Acc: 0.7361111111111112, Macro-F1: 0.6478539052351632
[Epoch 51] Train Loss=0.19992445409297943 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 233, 1: 58, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6582987575397914
[Epoch 52] Train Loss=0.19908630847930908 Test Acc=0.7388888888888889 T=1.009999999999991s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7277777777777777, Macro-F1: 0.6388555122223888
[Epoch 53] Train Loss=0.2012498378753662 Test Acc=0.7277777777777777 T=1.019999999999996s
Output Distribution={2: 226, 1: 62, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6567871056082697
[Epoch 54] Train Loss=0.19996654987335205 Test Acc=0.7333333333333333 T=0.9899999999999949s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6583978091778085
[Epoch 55] Train Loss=0.19947831332683563 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 231, 1: 50, 0: 79}, Acc: 0.7333333333333333, Macro-F1: 0.6471821145784816
[Epoch 56] Train Loss=0.20157673954963684 Test Acc=0.7333333333333333 T=1.0100000000000051s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6621164021164021
[Epoch 57] Train Loss=0.19740720093250275 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 226, 1: 62, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6628762310679112
[Epoch 58] Train Loss=0.19969601929187775 Test Acc=0.7388888888888889 T=1.0200000000000102s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.75, Macro-F1: 0.6741177823832943
[Epoch 59] Train Loss=0.19354532659053802 Test Acc=0.75 T=1.0300000000000011s
Output Distribution={2: 229, 1: 56, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6675350760596661
[Epoch 60] Train Loss=0.19896991550922394 Test Acc=0.7444444444444445 T=1.009999999999991s
Output Distribution={2: 232, 1: 51, 0: 77}, Acc: 0.7527777777777778, Macro-F1: 0.6737857776268372
[Epoch 61] Train Loss=0.19809505343437195 Test Acc=0.7527777777777778 T=1.0200000000000102s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6651640651640651
[Epoch 62] Train Loss=0.20024541020393372 Test Acc=0.7472222222222222 T=1.3100000000000023s
Output Distribution={2: 225, 1: 64, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6673421869610211
[Epoch 63] Train Loss=0.20258209109306335 Test Acc=0.7416666666666667 T=1.0999999999999943s
Output Distribution={2: 225, 1: 64, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6673421869610211
[Epoch 64] Train Loss=0.198158398270607 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 232, 1: 50, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6582045621780722
[Epoch 65] Train Loss=0.19428035616874695 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 232, 1: 53, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.661591777096257
[Epoch 66] Train Loss=0.19847950339317322 Test Acc=0.7416666666666667 T=1.1400000000000006s
Output Distribution={2: 225, 1: 55, 0: 80}, Acc: 0.7361111111111112, Macro-F1: 0.6551136005345737
[Epoch 67] Train Loss=0.19233790040016174 Test Acc=0.7361111111111112 T=1.0700000000000074s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6575532284020412
[Epoch 68] Train Loss=0.20169147849082947 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 230, 1: 61, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6544854381569313
[Epoch 69] Train Loss=0.19598688185214996 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 223, 1: 59, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6681181313764095
[Epoch 70] Train Loss=0.19420380890369415 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6603227546966205
[Epoch 71] Train Loss=0.1965475231409073 Test Acc=0.7444444444444445 T=1.0200000000000102s
Output Distribution={2: 224, 1: 56, 0: 80}, Acc: 0.7361111111111112, Macro-F1: 0.6572009192944691
[Epoch 72] Train Loss=0.19384656846523285 Test Acc=0.7361111111111112 T=1.009999999999991s
Output Distribution={2: 227, 1: 61, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6657877894573524
[Epoch 73] Train Loss=0.19501854479312897 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6598760057779564
[Epoch 74] Train Loss=0.19580112397670746 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 223, 1: 59, 0: 78}, Acc: 0.7416666666666667, Macro-F1: 0.6681181313764095
[Epoch 75] Train Loss=0.20044761896133423 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 235, 1: 54, 0: 71}, Acc: 0.7472222222222222, Macro-F1: 0.6645711500974659
[Epoch 76] Train Loss=0.19161710143089294 Test Acc=0.7472222222222222 T=1.0300000000000011s
Output Distribution={2: 225, 1: 57, 0: 78}, Acc: 0.7305555555555555, Macro-F1: 0.6501441369356823
[Epoch 77] Train Loss=0.1938149631023407 Test Acc=0.7305555555555555 T=1.0200000000000102s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.6433881554686924
[Epoch 78] Train Loss=0.18835648894309998 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6506564086210105
[Epoch 79] Train Loss=0.19719165563583374 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 227, 1: 62, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6544312169312169
[Epoch 80] Train Loss=0.19388702511787415 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6605693266652172
[Epoch 81] Train Loss=0.19416700303554535 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 231, 1: 51, 0: 78}, Acc: 0.75, Macro-F1: 0.6673295361099382
[Epoch 82] Train Loss=0.19631701707839966 Test Acc=0.75 T=1.019999999999996s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6536912995446783
[Epoch 83] Train Loss=0.196293443441391 Test Acc=0.7388888888888889 T=1.0s
Output Distribution={2: 230, 1: 61, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6602892901402221
[Epoch 84] Train Loss=0.19292140007019043 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 229, 1: 63, 0: 68}, Acc: 0.7305555555555555, Macro-F1: 0.6513291916359706
[Epoch 85] Train Loss=0.19619998335838318 Test Acc=0.7305555555555555 T=1.009999999999991s
Output Distribution={2: 232, 1: 58, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6628792651010126
[Epoch 86] Train Loss=0.1935461014509201 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7305555555555555, Macro-F1: 0.6483454052722345
[Epoch 87] Train Loss=0.1938965767621994 Test Acc=0.7305555555555555 T=1.0100000000000051s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6680772059823704
[Epoch 88] Train Loss=0.20014984905719757 Test Acc=0.7472222222222222 T=1.0300000000000011s
Output Distribution={2: 238, 1: 47, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.648156746022441
[Epoch 89] Train Loss=0.1950988918542862 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 224, 1: 56, 0: 80}, Acc: 0.7416666666666667, Macro-F1: 0.6641635275096102
[Epoch 90] Train Loss=0.1935710310935974 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 235, 1: 54, 0: 71}, Acc: 0.7472222222222222, Macro-F1: 0.6686647173489279
[Epoch 91] Train Loss=0.19015979766845703 Test Acc=0.7472222222222222 T=1.0100000000000051s
Output Distribution={2: 233, 1: 58, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6589802659450618
[Epoch 92] Train Loss=0.19228430092334747 Test Acc=0.7388888888888889 T=1.0400000000000063s
Output Distribution={2: 236, 1: 52, 0: 72}, Acc: 0.7472222222222222, Macro-F1: 0.6688270558931121
[Epoch 93] Train Loss=0.1875799000263214 Test Acc=0.7472222222222222 T=1.0300000000000011s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6567796042629357
[Epoch 94] Train Loss=0.19180473685264587 Test Acc=0.7388888888888889 T=1.029999999999987s
Output Distribution={2: 229, 1: 62, 0: 69}, Acc: 0.7333333333333333, Macro-F1: 0.6527849504434012
[Epoch 95] Train Loss=0.18843428790569305 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 227, 1: 61, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6651361467747566
[Epoch 96] Train Loss=0.1900675892829895 Test Acc=0.7416666666666667 T=1.039999999999992s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6631163541277756
[Epoch 97] Train Loss=0.19225531816482544 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 227, 1: 57, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.668914521120283
[Epoch 98] Train Loss=0.1936495006084442 Test Acc=0.7444444444444445 T=1.0100000000000051s
Output Distribution={2: 227, 1: 61, 0: 72}, Acc: 0.7472222222222222, Macro-F1: 0.6718735858448728
[Epoch 99] Train Loss=0.19308353960514069 Test Acc=0.7472222222222222 T=1.039999999999992s
Output Distribution={2: 792, 0: 199, 1: 129}, Acc: 0.7071428571428572, Macro-F1: 0.5667065546046226
accuracy:0.7071428571428572, macro_f1:0.5667065546046226
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b3570b0d8c8>
>>> learning_rate: 0.0005
>>> num_epoch: 100
>>> batch_size: 32
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.3
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 359, 0: 1}, Acc: 0.6111111111111112, Macro-F1: 0.2528735632183908
[Epoch 0] Train Loss=0.9769395589828491 Test Acc=0.6111111111111112 T=1.1899999999999995s
Output Distribution={2: 352, 0: 7, 1: 1}, Acc: 0.6166666666666667, Macro-F1: 0.28141621734260636
[Epoch 1] Train Loss=0.8458142280578613 Test Acc=0.6166666666666667 T=1.3499999999999979s
Output Distribution={2: 320, 0: 38, 1: 2}, Acc: 0.6416666666666667, Macro-F1: 0.3829545539885868
[Epoch 2] Train Loss=0.7828003168106079 Test Acc=0.6416666666666667 T=1.4699999999999989s
Output Distribution={2: 305, 0: 52, 1: 3}, Acc: 0.65, Macro-F1: 0.41121110927426024
[Epoch 3] Train Loss=0.7295138239860535 Test Acc=0.65 T=1.4100000000000001s
Output Distribution={2: 296, 0: 52, 1: 12}, Acc: 0.6638888888888889, Macro-F1: 0.4633006331729736
[Epoch 4] Train Loss=0.6819877028465271 Test Acc=0.6638888888888889 T=1.1600000000000001s
Output Distribution={2: 278, 0: 63, 1: 19}, Acc: 0.6944444444444444, Macro-F1: 0.5327046249361468
[Epoch 5] Train Loss=0.6360435485839844 Test Acc=0.6944444444444444 T=1.3900000000000006s
Output Distribution={2: 268, 0: 70, 1: 22}, Acc: 0.7111111111111111, Macro-F1: 0.5609504673921851
[Epoch 6] Train Loss=0.5991212129592896 Test Acc=0.7111111111111111 T=1.370000000000001s
Output Distribution={2: 261, 0: 75, 1: 24}, Acc: 0.7222222222222222, Macro-F1: 0.5868806565902002
[Epoch 7] Train Loss=0.5602248311042786 Test Acc=0.7222222222222222 T=1.3599999999999994s
Output Distribution={2: 261, 0: 72, 1: 27}, Acc: 0.7333333333333333, Macro-F1: 0.6094348979527994
[Epoch 8] Train Loss=0.5310938358306885 Test Acc=0.7333333333333333 T=1.3099999999999987s
Output Distribution={2: 253, 0: 72, 1: 35}, Acc: 0.7305555555555555, Macro-F1: 0.6202084110637166
[Epoch 9] Train Loss=0.5005893707275391 Test Acc=0.7305555555555555 T=1.25s
Output Distribution={2: 251, 0: 71, 1: 38}, Acc: 0.7305555555555555, Macro-F1: 0.6233219856101212
[Epoch 10] Train Loss=0.4751560091972351 Test Acc=0.7305555555555555 T=1.120000000000001s
Output Distribution={2: 251, 0: 70, 1: 39}, Acc: 0.7277777777777777, Macro-F1: 0.621771731093765
[Epoch 11] Train Loss=0.4564066529273987 Test Acc=0.7277777777777777 T=1.0399999999999991s
Output Distribution={2: 249, 0: 70, 1: 41}, Acc: 0.7305555555555555, Macro-F1: 0.6263380551310557
[Epoch 12] Train Loss=0.43467459082603455 Test Acc=0.7305555555555555 T=1.0299999999999976s
Output Distribution={2: 246, 0: 73, 1: 41}, Acc: 0.7222222222222222, Macro-F1: 0.615119913158944
[Epoch 13] Train Loss=0.4137057065963745 Test Acc=0.7222222222222222 T=1.0200000000000031s
Output Distribution={2: 243, 1: 46, 0: 71}, Acc: 0.725, Macro-F1: 0.6278279511038131
[Epoch 14] Train Loss=0.3987813889980316 Test Acc=0.725 T=1.0200000000000031s
Output Distribution={2: 246, 1: 47, 0: 67}, Acc: 0.7222222222222222, Macro-F1: 0.6264235136361873
[Epoch 15] Train Loss=0.3849952220916748 Test Acc=0.7222222222222222 T=1.0100000000000051s
Output Distribution={2: 239, 1: 49, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6440779610194903
[Epoch 16] Train Loss=0.3635551929473877 Test Acc=0.7333333333333333 T=1.0200000000000031s
Output Distribution={2: 238, 1: 51, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6488813474107592
[Epoch 17] Train Loss=0.35467562079429626 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 240, 1: 46, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6452876522988082
[Epoch 18] Train Loss=0.3440650999546051 Test Acc=0.7333333333333333 T=1.3099999999999952s
Output Distribution={2: 240, 1: 47, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6405295341568167
[Epoch 19] Train Loss=0.334320992231369 Test Acc=0.7305555555555555 T=1.1000000000000014s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6479621199150978
[Epoch 20] Train Loss=0.322480171918869 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 238, 1: 47, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6480995137077039
[Epoch 21] Train Loss=0.314434289932251 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 235, 1: 48, 0: 77}, Acc: 0.7361111111111112, Macro-F1: 0.6546198830409357
[Epoch 22] Train Loss=0.3111005425453186 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 236, 1: 47, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6570751491601204
[Epoch 23] Train Loss=0.3013147711753845 Test Acc=0.7388888888888889 T=1.009999999999998s
Output Distribution={2: 238, 1: 47, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6539992187224531
[Epoch 24] Train Loss=0.2972487211227417 Test Acc=0.7361111111111112 T=1.2000000000000028s
Output Distribution={2: 234, 1: 49, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6594510803206456
[Epoch 25] Train Loss=0.285462886095047 Test Acc=0.7388888888888889 T=1.259999999999998s
Output Distribution={2: 236, 1: 49, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6533251737133384
[Epoch 26] Train Loss=0.280358225107193 Test Acc=0.7361111111111112 T=1.0900000000000034s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6537092463518793
[Epoch 27] Train Loss=0.27203553915023804 Test Acc=0.7361111111111112 T=1.0399999999999991s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6537092463518793
[Epoch 28] Train Loss=0.27648502588272095 Test Acc=0.7361111111111112 T=1.009999999999998s
Output Distribution={2: 236, 1: 50, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.65754812199283
[Epoch 29] Train Loss=0.26373037695884705 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6503495601475634
[Epoch 30] Train Loss=0.26060178875923157 Test Acc=0.7333333333333333 T=1.009999999999998s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6520176937932481
[Epoch 31] Train Loss=0.2550819516181946 Test Acc=0.7333333333333333 T=1.009999999999998s
Output Distribution={2: 236, 1: 51, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6587707416519503
[Epoch 32] Train Loss=0.2577378451824188 Test Acc=0.7416666666666667 T=1.009999999999998s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.656377758497319
[Epoch 33] Train Loss=0.2483728975057602 Test Acc=0.7388888888888889 T=1.1999999999999957s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6516149230412068
[Epoch 34] Train Loss=0.24521279335021973 Test Acc=0.7361111111111112 T=1.1200000000000045s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6613775494020998
[Epoch 35] Train Loss=0.24460995197296143 Test Acc=0.7388888888888889 T=1.0400000000000063s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6592382626000016
[Epoch 36] Train Loss=0.24334461987018585 Test Acc=0.7388888888888889 T=1.0200000000000031s
Output Distribution={2: 237, 1: 51, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6420639976730927
[Epoch 37] Train Loss=0.24006015062332153 Test Acc=0.7305555555555555 T=1.0100000000000051s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6476060658393573
[Epoch 38] Train Loss=0.23172767460346222 Test Acc=0.7333333333333333 T=1.0200000000000031s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6676390346448474
[Epoch 39] Train Loss=0.23374441266059875 Test Acc=0.7444444444444445 T=1.0100000000000051s
Output Distribution={2: 236, 1: 54, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6577662672848669
[Epoch 40] Train Loss=0.22904695570468903 Test Acc=0.7388888888888889 T=1.2899999999999991s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.660900443637149
[Epoch 41] Train Loss=0.22785258293151855 Test Acc=0.7388888888888889 T=1.0600000000000023s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6532845149807354
[Epoch 42] Train Loss=0.22526858747005463 Test Acc=0.7361111111111112 T=1.009999999999998s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6586818337255849
[Epoch 43] Train Loss=0.22361576557159424 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6492660526791013
[Epoch 44] Train Loss=0.22675669193267822 Test Acc=0.7333333333333333 T=1.0100000000000051s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6631108648621443
[Epoch 45] Train Loss=0.22126547992229462 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6651198981686787
[Epoch 46] Train Loss=0.21824614703655243 Test Acc=0.7416666666666667 T=1.1200000000000045s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6605751634577774
[Epoch 47] Train Loss=0.21766428649425507 Test Acc=0.7416666666666667 T=1.0600000000000023s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553239999900762
[Epoch 48] Train Loss=0.22426393628120422 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6706709500641233
[Epoch 49] Train Loss=0.21769501268863678 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6660119235332103
[Epoch 50] Train Loss=0.21398821473121643 Test Acc=0.7444444444444445 T=1.2199999999999989s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6549254459436532
[Epoch 51] Train Loss=0.2132597118616104 Test Acc=0.7388888888888889 T=1.0800000000000125s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.663033040984944
[Epoch 52] Train Loss=0.21138104796409607 Test Acc=0.7416666666666667 T=0.9899999999999949s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6561404301671934
[Epoch 53] Train Loss=0.21335440874099731 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6653417553400435
[Epoch 54] Train Loss=0.21104450523853302 Test Acc=0.7416666666666667 T=1.0200000000000102s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6561404301671934
[Epoch 55] Train Loss=0.20828601717948914 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6669415799364984
[Epoch 56] Train Loss=0.21007388830184937 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6653417553400435
[Epoch 57] Train Loss=0.20664450526237488 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6622274594523822
[Epoch 58] Train Loss=0.2095552384853363 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6653417553400435
[Epoch 59] Train Loss=0.20191383361816406 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6615646122037399
[Epoch 60] Train Loss=0.20665718615055084 Test Acc=0.7388888888888889 T=1.0s
Output Distribution={2: 232, 1: 53, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6675679519466041
[Epoch 61] Train Loss=0.20527654886245728 Test Acc=0.7472222222222222 T=1.009999999999991s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6628949045800486
[Epoch 62] Train Loss=0.2056056559085846 Test Acc=0.7416666666666667 T=1.009999999999991s
Output Distribution={2: 226, 1: 60, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6726983112409766
[Epoch 63] Train Loss=0.20745991170406342 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.75, Macro-F1: 0.6781609195402298
[Epoch 64] Train Loss=0.20338654518127441 Test Acc=0.75 T=1.009999999999991s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6534291420762566
[Epoch 65] Train Loss=0.19894473254680634 Test Acc=0.7361111111111112 T=1.1199999999999903s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6530627656804898
[Epoch 66] Train Loss=0.2034841924905777 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 227, 1: 57, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6644402481896344
[Epoch 67] Train Loss=0.19578734040260315 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553079339170931
[Epoch 68] Train Loss=0.20692551136016846 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 229, 1: 61, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6673737577674586
[Epoch 69] Train Loss=0.2009197622537613 Test Acc=0.7416666666666667 T=1.1400000000000006s
Output Distribution={2: 226, 1: 59, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6674368865509805
[Epoch 70] Train Loss=0.1979232132434845 Test Acc=0.7416666666666667 T=1.0600000000000023s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6628949045800486
[Epoch 71] Train Loss=0.20040404796600342 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 227, 1: 56, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6645342180588082
[Epoch 72] Train Loss=0.19733457267284393 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6674074074074076
[Epoch 73] Train Loss=0.19899749755859375 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6576191662412124
[Epoch 74] Train Loss=0.19803272187709808 Test Acc=0.7361111111111112 T=1.009999999999991s
Output Distribution={2: 227, 1: 59, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6697120181405896
[Epoch 75] Train Loss=0.20362940430641174 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 231, 1: 60, 0: 69}, Acc: 0.7444444444444445, Macro-F1: 0.6705190170851395
[Epoch 76] Train Loss=0.19204109907150269 Test Acc=0.7444444444444445 T=1.0100000000000051s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.661461939789466
[Epoch 77] Train Loss=0.19665642082691193 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 234, 1: 52, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6474262890727781
[Epoch 78] Train Loss=0.19084051251411438 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6538913625607173
[Epoch 79] Train Loss=0.2001732587814331 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6590828611316416
[Epoch 80] Train Loss=0.1953348070383072 Test Acc=0.7388888888888889 T=1.0200000000000102s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6613590467430034
[Epoch 81] Train Loss=0.19724887609481812 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6590772877296016
[Epoch 82] Train Loss=0.19934384524822235 Test Acc=0.7416666666666667 T=1.009999999999991s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6552634704287635
[Epoch 83] Train Loss=0.19604933261871338 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 231, 1: 62, 0: 67}, Acc: 0.7388888888888889, Macro-F1: 0.6610527286135693
[Epoch 84] Train Loss=0.19604367017745972 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 231, 1: 62, 0: 67}, Acc: 0.7333333333333333, Macro-F1: 0.6543694690265487
[Epoch 85] Train Loss=0.19672779738903046 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 230, 1: 61, 0: 69}, Acc: 0.7444444444444445, Macro-F1: 0.6696789615017243
[Epoch 86] Train Loss=0.1952478438615799 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6621164021164021
[Epoch 87] Train Loss=0.19446678459644318 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6629484464867624
[Epoch 88] Train Loss=0.2019685059785843 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6536053614413401
[Epoch 89] Train Loss=0.1953846663236618 Test Acc=0.7388888888888889 T=1.0200000000000102s
Output Distribution={2: 227, 1: 57, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6599659752589856
[Epoch 90] Train Loss=0.19494518637657166 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6652179404946139
[Epoch 91] Train Loss=0.19147710502147675 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6667353908290249
[Epoch 92] Train Loss=0.19360236823558807 Test Acc=0.7444444444444445 T=1.0100000000000051s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.663248043771247
[Epoch 93] Train Loss=0.1887252777814865 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6599217011395014
[Epoch 94] Train Loss=0.19192726910114288 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 225, 1: 62, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6605896912177243
[Epoch 95] Train Loss=0.18821460008621216 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 230, 1: 62, 0: 68}, Acc: 0.7388888888888889, Macro-F1: 0.6602523843782925
[Epoch 96] Train Loss=0.1906169056892395 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6647164725524511
[Epoch 97] Train Loss=0.19333507120609283 Test Acc=0.7444444444444445 T=1.009999999999991s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.75, Macro-F1: 0.6766292502179599
[Epoch 98] Train Loss=0.194472074508667 Test Acc=0.75 T=1.0200000000000102s
Output Distribution={2: 226, 1: 60, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6741897355511929
[Epoch 99] Train Loss=0.19465972483158112 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 789, 0: 205, 1: 126}, Acc: 0.70625, Macro-F1: 0.5632902230803025
accuracy:0.70625, macro_f1:0.5632902230803025
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b37808468c8>
>>> learning_rate: 0.001
>>> num_epoch: 100
>>> batch_size: 32
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.5
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 351, 0: 9}, Acc: 0.6111111111111112, Macro-F1: 0.2703394166808801
[Epoch 0] Train Loss=0.9352801442146301 Test Acc=0.6111111111111112 T=1.5899999999999999s
Output Distribution={2: 321, 0: 34, 1: 5}, Acc: 0.6416666666666667, Macro-F1: 0.3836195779359399
[Epoch 1] Train Loss=0.7941117286682129 Test Acc=0.6416666666666667 T=1.3999999999999986s
Output Distribution={2: 280, 0: 69, 1: 11}, Acc: 0.6861111111111111, Macro-F1: 0.5016762402273072
[Epoch 2] Train Loss=0.7128118872642517 Test Acc=0.6861111111111111 T=1.4500000000000028s
Output Distribution={2: 268, 0: 76, 1: 16}, Acc: 0.7055555555555556, Macro-F1: 0.5425910099674143
[Epoch 3] Train Loss=0.6389567255973816 Test Acc=0.7055555555555556 T=1.4100000000000001s
Output Distribution={2: 260, 0: 77, 1: 23}, Acc: 0.7111111111111111, Macro-F1: 0.565665163867411
[Epoch 4] Train Loss=0.5830832719802856 Test Acc=0.7111111111111111 T=1.370000000000001s
Output Distribution={2: 257, 0: 75, 1: 28}, Acc: 0.7277777777777777, Macro-F1: 0.6011658859072729
[Epoch 5] Train Loss=0.5380694270133972 Test Acc=0.7277777777777777 T=1.4400000000000013s
Output Distribution={2: 247, 0: 75, 1: 38}, Acc: 0.7333333333333333, Macro-F1: 0.625086625086625
[Epoch 6] Train Loss=0.49399334192276 Test Acc=0.7333333333333333 T=1.4299999999999997s
Output Distribution={2: 250, 0: 76, 1: 34}, Acc: 0.7222222222222222, Macro-F1: 0.6045664182542736
[Epoch 7] Train Loss=0.45840486884117126 Test Acc=0.7222222222222222 T=1.3499999999999979s
Output Distribution={2: 247, 0: 72, 1: 41}, Acc: 0.725, Macro-F1: 0.6172407366090898
[Epoch 8] Train Loss=0.43091750144958496 Test Acc=0.725 T=1.1600000000000001s
Output Distribution={2: 245, 1: 43, 0: 72}, Acc: 0.725, Macro-F1: 0.6250664957712898
[Epoch 9] Train Loss=0.4070158302783966 Test Acc=0.725 T=1.3300000000000018s
Output Distribution={2: 243, 1: 49, 0: 68}, Acc: 0.725, Macro-F1: 0.6331033065027769
[Epoch 10] Train Loss=0.38400253653526306 Test Acc=0.725 T=1.0599999999999987s
Output Distribution={2: 243, 1: 49, 0: 68}, Acc: 0.7305555555555555, Macro-F1: 0.6392682204996792
[Epoch 11] Train Loss=0.3715475797653198 Test Acc=0.7305555555555555 T=1.0300000000000011s
Output Distribution={2: 243, 1: 46, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6457991242474002
[Epoch 12] Train Loss=0.34884917736053467 Test Acc=0.7361111111111112 T=1.0299999999999976s
Output Distribution={2: 241, 1: 47, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6531915783670437
[Epoch 13] Train Loss=0.33204513788223267 Test Acc=0.7388888888888889 T=1.2000000000000028s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.66228529198454
[Epoch 14] Train Loss=0.3221205174922943 Test Acc=0.7416666666666667 T=1.3499999999999943s
Output Distribution={2: 242, 1: 46, 0: 72}, Acc: 0.7277777777777777, Macro-F1: 0.637582678114815
[Epoch 15] Train Loss=0.3110758364200592 Test Acc=0.7277777777777777 T=1.4200000000000017s
Output Distribution={2: 236, 1: 48, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6640900392248201
[Epoch 16] Train Loss=0.29736241698265076 Test Acc=0.7444444444444445 T=1.1099999999999994s
Output Distribution={2: 233, 1: 51, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6582056597135094
[Epoch 17] Train Loss=0.29171764850616455 Test Acc=0.7388888888888889 T=1.2100000000000009s
Output Distribution={2: 237, 1: 49, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6587326127210584
[Epoch 18] Train Loss=0.28563958406448364 Test Acc=0.7416666666666667 T=1.1300000000000026s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6578397468014127
[Epoch 19] Train Loss=0.27714723348617554 Test Acc=0.7416666666666667 T=1.0500000000000043s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6638204598832377
[Epoch 20] Train Loss=0.271946519613266 Test Acc=0.7444444444444445 T=1.009999999999998s
Output Distribution={2: 235, 1: 49, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6544950914393267
[Epoch 21] Train Loss=0.2652054727077484 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6639688546500278
[Epoch 22] Train Loss=0.25931140780448914 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6663575663575664
[Epoch 23] Train Loss=0.2557038366794586 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6539230985228252
[Epoch 24] Train Loss=0.2572820782661438 Test Acc=0.7361111111111112 T=1.4000000000000057s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.668504002042318
[Epoch 25] Train Loss=0.246302530169487 Test Acc=0.7472222222222222 T=1.0799999999999983s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.660355184658298
[Epoch 26] Train Loss=0.24497874081134796 Test Acc=0.7416666666666667 T=1.009999999999998s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6708878804222485
[Epoch 27] Train Loss=0.23758460581302643 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6655329692406137
[Epoch 28] Train Loss=0.2418491393327713 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6583138428505412
[Epoch 29] Train Loss=0.24024038016796112 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.75, Macro-F1: 0.6759259487629764
[Epoch 30] Train Loss=0.23710860311985016 Test Acc=0.75 T=1.0300000000000011s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7527777777777778, Macro-F1: 0.679124266408227
[Epoch 31] Train Loss=0.22960573434829712 Test Acc=0.7527777777777778 T=1.3599999999999994s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.660796621134494
[Epoch 32] Train Loss=0.230617955327034 Test Acc=0.7444444444444445 T=1.2199999999999989s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6671058729076457
[Epoch 33] Train Loss=0.2294105440378189 Test Acc=0.7472222222222222 T=1.1300000000000026s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6645742422554984
[Epoch 34] Train Loss=0.22334253787994385 Test Acc=0.7416666666666667 T=1.0399999999999991s
Output Distribution={2: 228, 1: 63, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6655784919284182
[Epoch 35] Train Loss=0.220210000872612 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 231, 1: 61, 0: 68}, Acc: 0.7472222222222222, Macro-F1: 0.6725220588247406
[Epoch 36] Train Loss=0.22438396513462067 Test Acc=0.7472222222222222 T=1.0200000000000031s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7583333333333333, Macro-F1: 0.6814570294320351
[Epoch 37] Train Loss=0.22410301864147186 Test Acc=0.7583333333333333 T=1.0200000000000031s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6669149995830573
[Epoch 38] Train Loss=0.22515736520290375 Test Acc=0.7444444444444445 T=1.3500000000000014s
Output Distribution={2: 229, 1: 54, 0: 77}, Acc: 0.7444444444444445, Macro-F1: 0.6696296296296297
[Epoch 39] Train Loss=0.22047561407089233 Test Acc=0.7444444444444445 T=1.1200000000000045s
Output Distribution={2: 236, 1: 54, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6629935102582806
[Epoch 40] Train Loss=0.21926328539848328 Test Acc=0.7444444444444445 T=1.029999999999994s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6651450382791887
[Epoch 41] Train Loss=0.21522551774978638 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7527777777777778, Macro-F1: 0.67895578803256
[Epoch 42] Train Loss=0.2174033522605896 Test Acc=0.7527777777777778 T=1.0100000000000051s
Output Distribution={2: 231, 1: 59, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6552272624131031
[Epoch 43] Train Loss=0.21251040697097778 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6529094033123258
[Epoch 44] Train Loss=0.22128276526927948 Test Acc=0.7361111111111112 T=1.1500000000000057s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7555555555555555, Macro-F1: 0.6851213510618269
[Epoch 45] Train Loss=0.21472427248954773 Test Acc=0.7555555555555555 T=1.1500000000000057s
Output Distribution={2: 227, 1: 64, 0: 69}, Acc: 0.7444444444444445, Macro-F1: 0.670516689882887
[Epoch 46] Train Loss=0.217283695936203 Test Acc=0.7444444444444445 T=1.2600000000000051s
Output Distribution={2: 230, 1: 51, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.6564596792453019
[Epoch 47] Train Loss=0.21051284670829773 Test Acc=0.7388888888888889 T=1.0499999999999972s
Output Distribution={2: 225, 1: 59, 0: 76}, Acc: 0.7444444444444445, Macro-F1: 0.6711458352143337
[Epoch 48] Train Loss=0.2176022231578827 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6712529061319383
[Epoch 49] Train Loss=0.21696144342422485 Test Acc=0.7472222222222222 T=1.0300000000000011s
Output Distribution={2: 229, 1: 56, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6506201283250465
[Epoch 50] Train Loss=0.21317405998706818 Test Acc=0.7333333333333333 T=1.0100000000000051s
Output Distribution={2: 231, 1: 53, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.6496454969705409
[Epoch 51] Train Loss=0.20933318138122559 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 233, 1: 58, 0: 69}, Acc: 0.7305555555555555, Macro-F1: 0.6467591489918146
[Epoch 52] Train Loss=0.20785704255104065 Test Acc=0.7305555555555555 T=1.0400000000000063s
Output Distribution={2: 226, 1: 56, 0: 78}, Acc: 0.7333333333333333, Macro-F1: 0.6513857608405343
[Epoch 53] Train Loss=0.20652428269386292 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 226, 1: 63, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6681082323153497
[Epoch 54] Train Loss=0.20904627442359924 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6536787386055679
[Epoch 55] Train Loss=0.2091081440448761 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 228, 1: 53, 0: 79}, Acc: 0.7416666666666667, Macro-F1: 0.6604334266821251
[Epoch 56] Train Loss=0.2081259936094284 Test Acc=0.7416666666666667 T=1.0200000000000102s
Output Distribution={2: 229, 1: 61, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6574624092734329
[Epoch 57] Train Loss=0.20431780815124512 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 229, 1: 61, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6574624092734329
[Epoch 58] Train Loss=0.2079262137413025 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6669415799364984
[Epoch 59] Train Loss=0.20210395753383636 Test Acc=0.7444444444444445 T=1.2900000000000063s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6622274594523822
[Epoch 60] Train Loss=0.20691250264644623 Test Acc=0.7388888888888889 T=1.039999999999992s
Output Distribution={2: 232, 1: 52, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6530982879423224
[Epoch 61] Train Loss=0.20419269800186157 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6630273649329911
[Epoch 62] Train Loss=0.212136909365654 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 224, 1: 60, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6643624200972816
[Epoch 63] Train Loss=0.20481730997562408 Test Acc=0.7388888888888889 T=1.029999999999987s
Output Distribution={2: 226, 1: 64, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6696651595980455
[Epoch 64] Train Loss=0.20791925489902496 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6613467932758398
[Epoch 65] Train Loss=0.19999797642230988 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.648469388598706
[Epoch 66] Train Loss=0.20239602029323578 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 225, 1: 56, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.6605254129958432
[Epoch 67] Train Loss=0.19819653034210205 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6613966273931888
[Epoch 68] Train Loss=0.2093682736158371 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 229, 1: 63, 0: 68}, Acc: 0.7361111111111112, Macro-F1: 0.6575388055051588
[Epoch 69] Train Loss=0.20464134216308594 Test Acc=0.7361111111111112 T=1.0400000000000063s
Output Distribution={2: 225, 1: 58, 0: 77}, Acc: 0.7361111111111112, Macro-F1: 0.656009129337641
[Epoch 70] Train Loss=0.1992615908384323 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.665266855533606
[Epoch 71] Train Loss=0.20106256008148193 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 224, 1: 57, 0: 79}, Acc: 0.7361111111111112, Macro-F1: 0.6582337706877955
[Epoch 72] Train Loss=0.2060609757900238 Test Acc=0.7361111111111112 T=1.039999999999992s
Output Distribution={2: 226, 1: 59, 0: 75}, Acc: 0.7305555555555555, Macro-F1: 0.6516031198984219
[Epoch 73] Train Loss=0.1994657963514328 Test Acc=0.7305555555555555 T=1.019999999999996s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6561988138390985
[Epoch 74] Train Loss=0.20594239234924316 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 223, 1: 58, 0: 79}, Acc: 0.7388888888888889, Macro-F1: 0.662838984995182
[Epoch 75] Train Loss=0.20462843775749207 Test Acc=0.7388888888888889 T=1.039999999999992s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.662272313644151
[Epoch 76] Train Loss=0.20086385309696198 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 228, 1: 55, 0: 77}, Acc: 0.7305555555555555, Macro-F1: 0.6484529440998362
[Epoch 77] Train Loss=0.20443710684776306 Test Acc=0.7305555555555555 T=1.0500000000000114s
Output Distribution={2: 234, 1: 51, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.648991848991849
[Epoch 78] Train Loss=0.1900567263364792 Test Acc=0.7361111111111112 T=1.039999999999992s
Output Distribution={2: 232, 1: 51, 0: 77}, Acc: 0.7361111111111112, Macro-F1: 0.650557536650252
[Epoch 79] Train Loss=0.20544284582138062 Test Acc=0.7361111111111112 T=1.0400000000000063s
Output Distribution={2: 231, 1: 59, 0: 70}, Acc: 0.7361111111111112, Macro-F1: 0.6552272624131031
[Epoch 80] Train Loss=0.19870194792747498 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6544532315020121
[Epoch 81] Train Loss=0.20050373673439026 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6569416287486297
[Epoch 82] Train Loss=0.1973823457956314 Test Acc=0.7388888888888889 T=1.039999999999992s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6491507028655809
[Epoch 83] Train Loss=0.20226384699344635 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6622189804443055
[Epoch 84] Train Loss=0.19536897540092468 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 228, 1: 62, 0: 70}, Acc: 0.7333333333333333, Macro-F1: 0.6557499084990733
[Epoch 85] Train Loss=0.20062418282032013 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6576759914548087
[Epoch 86] Train Loss=0.19769223034381866 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 228, 1: 61, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6552058103909989
[Epoch 87] Train Loss=0.20135559141635895 Test Acc=0.7333333333333333 T=1.039999999999992s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6666926038429107
[Epoch 88] Train Loss=0.1997460424900055 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 230, 1: 53, 0: 77}, Acc: 0.7361111111111112, Macro-F1: 0.6530486252150528
[Epoch 89] Train Loss=0.2006915658712387 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 225, 1: 54, 0: 81}, Acc: 0.7416666666666667, Macro-F1: 0.66103087246585
[Epoch 90] Train Loss=0.20009209215641022 Test Acc=0.7416666666666667 T=1.1000000000000085s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7472222222222222, Macro-F1: 0.668957031539104
[Epoch 91] Train Loss=0.19803211092948914 Test Acc=0.7472222222222222 T=1.1299999999999955s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.75, Macro-F1: 0.6720968455014562
[Epoch 92] Train Loss=0.19430169463157654 Test Acc=0.75 T=1.0499999999999972s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.667716201971101
[Epoch 93] Train Loss=0.1944189965724945 Test Acc=0.7444444444444445 T=1.2800000000000011s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.75, Macro-F1: 0.6726818893422185
[Epoch 94] Train Loss=0.1969403624534607 Test Acc=0.75 T=1.1800000000000068s
Output Distribution={2: 225, 1: 61, 0: 74}, Acc: 0.75, Macro-F1: 0.6778954040097966
[Epoch 95] Train Loss=0.19208863377571106 Test Acc=0.75 T=1.0499999999999972s
Output Distribution={2: 226, 1: 60, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6703901545704039
[Epoch 96] Train Loss=0.197800412774086 Test Acc=0.7472222222222222 T=1.0200000000000102s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7527777777777778, Macro-F1: 0.6784151026894375
[Epoch 97] Train Loss=0.19743947684764862 Test Acc=0.7527777777777778 T=1.0300000000000011s
Output Distribution={2: 226, 1: 60, 0: 74}, Acc: 0.7527777777777778, Macro-F1: 0.6802163072536994
[Epoch 98] Train Loss=0.19654539227485657 Test Acc=0.7527777777777778 T=1.019999999999996s
Output Distribution={2: 226, 1: 62, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6695759887114608
[Epoch 99] Train Loss=0.20025648176670074 Test Acc=0.7444444444444445 T=1.0200000000000102s
Output Distribution={2: 806, 0: 196, 1: 118}, Acc: 0.7205357142857143, Macro-F1: 0.5769475097523709
accuracy:0.7205357142857143, macro_f1:0.5769475097523709
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b4e173d98c8>
>>> learning_rate: 0.0005
>>> num_epoch: 100
>>> batch_size: 32
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.5
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 359, 0: 1}, Acc: 0.6111111111111112, Macro-F1: 0.2528735632183908
[Epoch 0] Train Loss=0.9930775761604309 Test Acc=0.6111111111111112 T=1.4100000000000001s
Output Distribution={2: 355, 0: 5}, Acc: 0.6111111111111112, Macro-F1: 0.2620192307692308
[Epoch 1] Train Loss=0.862107515335083 Test Acc=0.6111111111111112 T=1.3600000000000012s
Output Distribution={2: 337, 0: 23}, Acc: 0.625, Macro-F1: 0.32056451612903225
[Epoch 2] Train Loss=0.8080812096595764 Test Acc=0.625 T=1.3299999999999983s
Output Distribution={2: 315, 0: 43, 1: 2}, Acc: 0.65, Macro-F1: 0.40273530925494233
[Epoch 3] Train Loss=0.7566854357719421 Test Acc=0.65 T=1.3599999999999994s
Output Distribution={2: 304, 0: 49, 1: 7}, Acc: 0.6555555555555556, Macro-F1: 0.4270828654839434
[Epoch 4] Train Loss=0.7178578972816467 Test Acc=0.6555555555555556 T=1.4299999999999997s
Output Distribution={2: 294, 0: 54, 1: 12}, Acc: 0.6611111111111111, Macro-F1: 0.46102698701123895
[Epoch 5] Train Loss=0.6818298697471619 Test Acc=0.6611111111111111 T=1.4000000000000021s
Output Distribution={2: 277, 0: 65, 1: 18}, Acc: 0.6972222222222222, Macro-F1: 0.5370259505932633
[Epoch 6] Train Loss=0.6446273922920227 Test Acc=0.6972222222222222 T=1.4199999999999982s
Output Distribution={2: 275, 0: 66, 1: 19}, Acc: 0.7, Macro-F1: 0.540567963086836
[Epoch 7] Train Loss=0.6108099818229675 Test Acc=0.7 T=1.3599999999999994s
Output Distribution={2: 275, 0: 63, 1: 22}, Acc: 0.7083333333333334, Macro-F1: 0.5571847507331378
[Epoch 8] Train Loss=0.5805583000183105 Test Acc=0.7083333333333334 T=1.3300000000000018s
Output Distribution={2: 262, 0: 72, 1: 26}, Acc: 0.725, Macro-F1: 0.5939673020632541
[Epoch 9] Train Loss=0.5567408800125122 Test Acc=0.725 T=1.2800000000000011s
Output Distribution={2: 256, 0: 72, 1: 32}, Acc: 0.7194444444444444, Macro-F1: 0.5948895744229884
[Epoch 10] Train Loss=0.5305489301681519 Test Acc=0.7194444444444444 T=1.379999999999999s
Output Distribution={2: 253, 0: 72, 1: 35}, Acc: 0.725, Macro-F1: 0.6090100498482847
[Epoch 11] Train Loss=0.5128674507141113 Test Acc=0.725 T=1.1000000000000014s
Output Distribution={2: 251, 0: 73, 1: 36}, Acc: 0.725, Macro-F1: 0.6106664784945012
[Epoch 12] Train Loss=0.48864439129829407 Test Acc=0.725 T=1.0500000000000007s
Output Distribution={2: 250, 0: 73, 1: 37}, Acc: 0.7222222222222222, Macro-F1: 0.6084487827816618
[Epoch 13] Train Loss=0.46849364042282104 Test Acc=0.7222222222222222 T=1.009999999999998s
Output Distribution={2: 247, 0: 73, 1: 40}, Acc: 0.725, Macro-F1: 0.6173602873008405
[Epoch 14] Train Loss=0.4500996768474579 Test Acc=0.725 T=1.009999999999998s
Output Distribution={2: 250, 0: 73, 1: 37}, Acc: 0.725, Macro-F1: 0.6130149928273237
[Epoch 15] Train Loss=0.43711724877357483 Test Acc=0.725 T=1.0s
Output Distribution={2: 245, 0: 74, 1: 41}, Acc: 0.725, Macro-F1: 0.6189788578381092
[Epoch 16] Train Loss=0.41802117228507996 Test Acc=0.725 T=1.0300000000000011s
Output Distribution={2: 243, 1: 46, 0: 71}, Acc: 0.7277777777777777, Macro-F1: 0.6324575807334428
[Epoch 17] Train Loss=0.41116365790367126 Test Acc=0.7277777777777777 T=1.009999999999998s
Output Distribution={2: 244, 1: 43, 0: 73}, Acc: 0.7222222222222222, Macro-F1: 0.6213885296551401
[Epoch 18] Train Loss=0.39609718322753906 Test Acc=0.7222222222222222 T=1.3500000000000014s
Output Distribution={2: 243, 1: 46, 0: 71}, Acc: 0.725, Macro-F1: 0.6310207991242475
[Epoch 19] Train Loss=0.3845084309577942 Test Acc=0.725 T=1.1000000000000014s
Output Distribution={2: 240, 1: 50, 0: 70}, Acc: 0.7277777777777777, Macro-F1: 0.6354661246201376
[Epoch 20] Train Loss=0.3740156590938568 Test Acc=0.7277777777777777 T=1.0399999999999991s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6525393783244292
[Epoch 21] Train Loss=0.36063966155052185 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6525393783244292
[Epoch 22] Train Loss=0.354739248752594 Test Acc=0.7388888888888889 T=1.1999999999999957s
Output Distribution={2: 240, 1: 46, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6512689312890739
[Epoch 23] Train Loss=0.3490176796913147 Test Acc=0.7388888888888889 T=1.1200000000000045s
Output Distribution={2: 242, 1: 46, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6482179652228807
[Epoch 24] Train Loss=0.3437306582927704 Test Acc=0.7361111111111112 T=1.0500000000000043s
Output Distribution={2: 241, 1: 47, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6531915783670437
[Epoch 25] Train Loss=0.33038529753685 Test Acc=0.7388888888888889 T=1.009999999999998s
Output Distribution={2: 239, 1: 46, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6505259918303397
[Epoch 26] Train Loss=0.32485252618789673 Test Acc=0.7361111111111112 T=1.0200000000000031s
Output Distribution={2: 237, 1: 47, 0: 76}, Acc: 0.7305555555555555, Macro-F1: 0.6459496608417432
[Epoch 27] Train Loss=0.315334290266037 Test Acc=0.7305555555555555 T=1.0s
Output Distribution={2: 236, 1: 48, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6567832968034859
[Epoch 28] Train Loss=0.31401675939559937 Test Acc=0.7388888888888889 T=1.009999999999998s
Output Distribution={2: 237, 1: 46, 0: 77}, Acc: 0.7361111111111112, Macro-F1: 0.6521473625840438
[Epoch 29] Train Loss=0.30993735790252686 Test Acc=0.7361111111111112 T=1.009999999999998s
Output Distribution={2: 234, 1: 49, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6594510803206456
[Epoch 30] Train Loss=0.3038749396800995 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7361111111111112, Macro-F1: 0.654690060383187
[Epoch 31] Train Loss=0.2931845784187317 Test Acc=0.7361111111111112 T=1.009999999999998s
Output Distribution={2: 238, 1: 47, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.655451651547435
[Epoch 32] Train Loss=0.29308706521987915 Test Acc=0.7388888888888889 T=1.009999999999998s
Output Distribution={2: 240, 1: 48, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6534933963927196
[Epoch 33] Train Loss=0.2881573438644409 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6491430363062173
[Epoch 34] Train Loss=0.28240978717803955 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6501053421467169
[Epoch 35] Train Loss=0.2763153612613678 Test Acc=0.7305555555555555 T=1.009999999999998s
Output Distribution={2: 237, 1: 53, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.6601541279167789
[Epoch 36] Train Loss=0.2763306796550751 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 239, 1: 47, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6621474856455344
[Epoch 37] Train Loss=0.27220240235328674 Test Acc=0.7444444444444445 T=1.25s
Output Distribution={2: 237, 1: 51, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6549156131447956
[Epoch 38] Train Loss=0.2738005816936493 Test Acc=0.7388888888888889 T=1.4399999999999977s
Output Distribution={2: 235, 1: 50, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6598840219529875
[Epoch 39] Train Loss=0.26604875922203064 Test Acc=0.7388888888888889 T=1.1000000000000014s
Output Distribution={2: 236, 1: 53, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.657947132171614
[Epoch 40] Train Loss=0.2612690329551697 Test Acc=0.7388888888888889 T=1.0700000000000003s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6618148650869906
[Epoch 41] Train Loss=0.2547350823879242 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6618148650869906
[Epoch 42] Train Loss=0.25560176372528076 Test Acc=0.7416666666666667 T=1.009999999999998s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6618148650869906
[Epoch 43] Train Loss=0.2509039342403412 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6618148650869906
[Epoch 44] Train Loss=0.2571253180503845 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 235, 1: 54, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6570175438596491
[Epoch 45] Train Loss=0.24950502812862396 Test Acc=0.7388888888888889 T=1.009999999999991s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6669415799364984
[Epoch 46] Train Loss=0.25167331099510193 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.75, Macro-F1: 0.675392384926753
[Epoch 47] Train Loss=0.2422902137041092 Test Acc=0.75 T=1.0100000000000051s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6647179924154848
[Epoch 48] Train Loss=0.2502553164958954 Test Acc=0.7416666666666667 T=1.1799999999999926s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6730282077394903
[Epoch 49] Train Loss=0.24735738337039948 Test Acc=0.7472222222222222 T=1.1099999999999994s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.660900443637149
[Epoch 50] Train Loss=0.24092359840869904 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6662720242366261
[Epoch 51] Train Loss=0.237276092171669 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6632922213650113
[Epoch 52] Train Loss=0.23482133448123932 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6600080322098364
[Epoch 53] Train Loss=0.2343742698431015 Test Acc=0.7388888888888889 T=1.009999999999991s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.665252349863978
[Epoch 54] Train Loss=0.23220258951187134 Test Acc=0.7416666666666667 T=0.9899999999999949s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607440541906181
[Epoch 55] Train Loss=0.23306164145469666 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607440541906181
[Epoch 56] Train Loss=0.23033852875232697 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607440541906181
[Epoch 57] Train Loss=0.22559702396392822 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607440541906181
[Epoch 58] Train Loss=0.22983288764953613 Test Acc=0.7388888888888889 T=1.0s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607440541906181
[Epoch 59] Train Loss=0.2221946269273758 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6560815580561986
[Epoch 60] Train Loss=0.22589603066444397 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.660630834945708
[Epoch 61] Train Loss=0.22236011922359467 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6521819031135104
[Epoch 62] Train Loss=0.22863900661468506 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6629434212709474
[Epoch 63] Train Loss=0.22316792607307434 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7444444444444445, Macro-F1: 0.668161966649048
[Epoch 64] Train Loss=0.22425909340381622 Test Acc=0.7444444444444445 T=1.0s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6529389304809974
[Epoch 65] Train Loss=0.21644403040409088 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553239999900762
[Epoch 66] Train Loss=0.2183074951171875 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6652078228481074
[Epoch 67] Train Loss=0.21227943897247314 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553079339170931
[Epoch 68] Train Loss=0.22283130884170532 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6552544908596865
[Epoch 69] Train Loss=0.2196703851222992 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7472222222222222, Macro-F1: 0.6720360869879
[Epoch 70] Train Loss=0.21250216662883759 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6674785686632377
[Epoch 71] Train Loss=0.21288496255874634 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 227, 1: 56, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6590697371844914
[Epoch 72] Train Loss=0.2202269583940506 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 227, 1: 57, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6644402481896344
[Epoch 73] Train Loss=0.21356110274791718 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6652078228481074
[Epoch 74] Train Loss=0.21574245393276215 Test Acc=0.7416666666666667 T=1.0200000000000102s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6697648108938431
[Epoch 75] Train Loss=0.2154829353094101 Test Acc=0.7444444444444445 T=1.009999999999991s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6576759914548087
[Epoch 76] Train Loss=0.20945532619953156 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6569122034753964
[Epoch 77] Train Loss=0.21682240068912506 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7277777777777777, Macro-F1: 0.6428871769458335
[Epoch 78] Train Loss=0.2005072385072708 Test Acc=0.7277777777777777 T=1.0300000000000011s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6569267923971758
[Epoch 79] Train Loss=0.21574223041534424 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7305555555555555, Macro-F1: 0.6476315190256118
[Epoch 80] Train Loss=0.2097417414188385 Test Acc=0.7305555555555555 T=1.019999999999996s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.725, Macro-F1: 0.6383096006731913
[Epoch 81] Train Loss=0.21110929548740387 Test Acc=0.725 T=1.019999999999996s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6484290195358469
[Epoch 82] Train Loss=0.20721201598644257 Test Acc=0.7305555555555555 T=1.019999999999996s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6499714818885151
[Epoch 83] Train Loss=0.2117999792098999 Test Acc=0.7333333333333333 T=1.0200000000000102s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553239999900762
[Epoch 84] Train Loss=0.2063121795654297 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6521957671957672
[Epoch 85] Train Loss=0.20832940936088562 Test Acc=0.7333333333333333 T=1.0s
Output Distribution={2: 229, 1: 60, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6621164021164021
[Epoch 86] Train Loss=0.20661696791648865 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 230, 1: 61, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6582565853888044
[Epoch 87] Train Loss=0.20900215208530426 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6651749619070753
[Epoch 88] Train Loss=0.2084113508462906 Test Acc=0.7416666666666667 T=1.009999999999991s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6599217011395014
[Epoch 89] Train Loss=0.2081056535243988 Test Acc=0.7388888888888889 T=1.009999999999991s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7333333333333333, Macro-F1: 0.6537984831482577
[Epoch 90] Train Loss=0.20619486272335052 Test Acc=0.7333333333333333 T=1.0s
Output Distribution={2: 232, 1: 59, 0: 69}, Acc: 0.7444444444444445, Macro-F1: 0.668161966649048
[Epoch 91] Train Loss=0.20564928650856018 Test Acc=0.7444444444444445 T=1.059999999999988s
Output Distribution={2: 232, 1: 58, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6675412697630172
[Epoch 92] Train Loss=0.20272274315357208 Test Acc=0.7444444444444445 T=1.1199999999999903s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7472222222222222, Macro-F1: 0.6722325418618423
[Epoch 93] Train Loss=0.20121699571609497 Test Acc=0.7472222222222222 T=1.0300000000000011s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.75, Macro-F1: 0.6743310147920907
[Epoch 94] Train Loss=0.20339225232601166 Test Acc=0.75 T=1.0s
Output Distribution={2: 228, 1: 62, 0: 70}, Acc: 0.75, Macro-F1: 0.6773674891366985
[Epoch 95] Train Loss=0.1975466012954712 Test Acc=0.75 T=1.0100000000000051s
Output Distribution={2: 228, 1: 59, 0: 73}, Acc: 0.75, Macro-F1: 0.6765688134972695
[Epoch 96] Train Loss=0.20495377480983734 Test Acc=0.75 T=1.019999999999996s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7555555555555555, Macro-F1: 0.682099205971601
[Epoch 97] Train Loss=0.20465636253356934 Test Acc=0.7555555555555555 T=1.009999999999991s
Output Distribution={2: 227, 1: 59, 0: 74}, Acc: 0.7527777777777778, Macro-F1: 0.6810685941043083
[Epoch 98] Train Loss=0.20403489470481873 Test Acc=0.7527777777777778 T=1.3499999999999943s
Output Distribution={2: 228, 1: 60, 0: 72}, Acc: 0.75, Macro-F1: 0.6766097419349858
[Epoch 99] Train Loss=0.2070690542459488 Test Acc=0.75 T=1.0900000000000034s
Output Distribution={2: 791, 0: 210, 1: 119}, Acc: 0.7044642857142858, Macro-F1: 0.5576902865954193
accuracy:0.7044642857142858, macro_f1:0.5576902865954193
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b7af02ac8c8>
>>> learning_rate: 0.001
>>> num_epoch: 100
>>> batch_size: 32
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.7
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 355, 0: 5}, Acc: 0.6138888888888889, Macro-F1: 0.2705662393162393
[Epoch 0] Train Loss=0.958789587020874 Test Acc=0.6138888888888889 T=1.1799999999999997s
Output Distribution={2: 339, 0: 19, 1: 2}, Acc: 0.6277777777777778, Macro-F1: 0.33472171477286566
[Epoch 1] Train Loss=0.8366950750350952 Test Acc=0.6277777777777778 T=1.240000000000002s
Output Distribution={2: 303, 0: 54, 1: 3}, Acc: 0.6611111111111111, Macro-F1: 0.4273946755659857
[Epoch 2] Train Loss=0.7695524096488953 Test Acc=0.6611111111111111 T=1.360000000000003s
Output Distribution={2: 285, 0: 67, 1: 8}, Acc: 0.675, Macro-F1: 0.4807743372960765
[Epoch 3] Train Loss=0.705180287361145 Test Acc=0.675 T=1.5199999999999996s
Output Distribution={2: 279, 0: 63, 1: 18}, Acc: 0.6972222222222222, Macro-F1: 0.5347040149393091
[Epoch 4] Train Loss=0.6549051403999329 Test Acc=0.6972222222222222 T=1.4499999999999993s
Output Distribution={2: 274, 0: 67, 1: 19}, Acc: 0.7111111111111111, Macro-F1: 0.5586735704382763
[Epoch 5] Train Loss=0.6211413741111755 Test Acc=0.7111111111111111 T=1.2699999999999996s
Output Distribution={2: 254, 0: 79, 1: 27}, Acc: 0.7138888888888889, Macro-F1: 0.580986606300698
[Epoch 6] Train Loss=0.5823038220405579 Test Acc=0.7138888888888889 T=1.4500000000000028s
Output Distribution={2: 256, 0: 76, 1: 28}, Acc: 0.7277777777777777, Macro-F1: 0.6005170191112065
[Epoch 7] Train Loss=0.5508338212966919 Test Acc=0.7277777777777777 T=1.3999999999999986s
Output Distribution={2: 255, 0: 72, 1: 33}, Acc: 0.725, Macro-F1: 0.6054342322090801
[Epoch 8] Train Loss=0.5200130343437195 Test Acc=0.725 T=1.3500000000000014s
Output Distribution={2: 250, 0: 74, 1: 36}, Acc: 0.7194444444444444, Macro-F1: 0.6020352939477277
[Epoch 9] Train Loss=0.49601101875305176 Test Acc=0.7194444444444444 T=1.1099999999999994s
Output Distribution={2: 250, 0: 71, 1: 39}, Acc: 0.725, Macro-F1: 0.6146859097496039
[Epoch 10] Train Loss=0.47457852959632874 Test Acc=0.725 T=1.0399999999999991s
Output Distribution={2: 246, 0: 70, 1: 44}, Acc: 0.7361111111111112, Macro-F1: 0.6392407021957343
[Epoch 11] Train Loss=0.45641911029815674 Test Acc=0.7361111111111112 T=1.0199999999999996s
Output Distribution={2: 247, 0: 72, 1: 41}, Acc: 0.7277777777777777, Macro-F1: 0.6266444659290292
[Epoch 12] Train Loss=0.4356931149959564 Test Acc=0.7277777777777777 T=1.25s
Output Distribution={2: 243, 1: 44, 0: 73}, Acc: 0.7277777777777777, Macro-F1: 0.6312216401139406
[Epoch 13] Train Loss=0.4129165709018707 Test Acc=0.7277777777777777 T=1.2800000000000011s
Output Distribution={2: 241, 1: 47, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6564872756511451
[Epoch 14] Train Loss=0.3976376950740814 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 246, 1: 46, 0: 68}, Acc: 0.7277777777777777, Macro-F1: 0.6360375820715699
[Epoch 15] Train Loss=0.38786810636520386 Test Acc=0.7277777777777777 T=1.4499999999999957s
Output Distribution={2: 241, 1: 48, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.651793625477836
[Epoch 16] Train Loss=0.37319672107696533 Test Acc=0.7388888888888889 T=1.0799999999999983s
Output Distribution={2: 239, 1: 50, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6604572713643179
[Epoch 17] Train Loss=0.3631978929042816 Test Acc=0.7444444444444445 T=1.0599999999999952s
Output Distribution={2: 242, 1: 46, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6542555511815213
[Epoch 18] Train Loss=0.35631227493286133 Test Acc=0.7416666666666667 T=1.3400000000000034s
Output Distribution={2: 241, 1: 47, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6592322809594705
[Epoch 19] Train Loss=0.3479147255420685 Test Acc=0.7444444444444445 T=1.1099999999999994s
Output Distribution={2: 237, 1: 54, 0: 69}, Acc: 0.7333333333333333, Macro-F1: 0.6474256992708313
[Epoch 20] Train Loss=0.33239609003067017 Test Acc=0.7333333333333333 T=1.0399999999999991s
Output Distribution={2: 238, 1: 46, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6543065399164886
[Epoch 21] Train Loss=0.33516648411750793 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 237, 1: 47, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6592348469385242
[Epoch 22] Train Loss=0.32411664724349976 Test Acc=0.7416666666666667 T=1.1700000000000017s
Output Distribution={2: 240, 1: 45, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.6514757707816276
[Epoch 23] Train Loss=0.3164713978767395 Test Acc=0.7388888888888889 T=1.0700000000000003s
Output Distribution={2: 241, 1: 46, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6474653580817965
[Epoch 24] Train Loss=0.313827782869339 Test Acc=0.7361111111111112 T=1.009999999999998s
Output Distribution={2: 239, 1: 48, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6469295633365725
[Epoch 25] Train Loss=0.298446923494339 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 239, 1: 49, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6479260369815093
[Epoch 26] Train Loss=0.29601818323135376 Test Acc=0.7361111111111112 T=1.009999999999998s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6537092463518793
[Epoch 27] Train Loss=0.29757454991340637 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 238, 1: 50, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6573310294743696
[Epoch 28] Train Loss=0.2897760570049286 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 237, 1: 50, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6539839340364514
[Epoch 29] Train Loss=0.29178351163864136 Test Acc=0.7388888888888889 T=1.0400000000000063s
Output Distribution={2: 235, 1: 51, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6625844219829182
[Epoch 30] Train Loss=0.28170493245124817 Test Acc=0.7444444444444445 T=1.0200000000000031s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6516149230412068
[Epoch 31] Train Loss=0.2721567153930664 Test Acc=0.7361111111111112 T=1.0200000000000031s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6516149230412068
[Epoch 32] Train Loss=0.26947295665740967 Test Acc=0.7361111111111112 T=1.029999999999994s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.64944080898956
[Epoch 33] Train Loss=0.27353864908218384 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7333333333333333, Macro-F1: 0.6517446991002284
[Epoch 34] Train Loss=0.2657829523086548 Test Acc=0.7333333333333333 T=1.0200000000000031s
Output Distribution={2: 230, 1: 58, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.665252349863978
[Epoch 35] Train Loss=0.2561517655849457 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6659759900331513
[Epoch 36] Train Loss=0.2635398507118225 Test Acc=0.7444444444444445 T=1.0200000000000031s
Output Distribution={2: 235, 1: 52, 0: 73}, Acc: 0.7472222222222222, Macro-F1: 0.6680556743611991
[Epoch 37] Train Loss=0.2665309011936188 Test Acc=0.7472222222222222 T=1.0399999999999991s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6654280864103784
[Epoch 38] Train Loss=0.2644619643688202 Test Acc=0.7416666666666667 T=1.2099999999999937s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6610255139583426
[Epoch 39] Train Loss=0.25469088554382324 Test Acc=0.7388888888888889 T=1.0200000000000031s
Output Distribution={2: 230, 1: 60, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6635523464791757
[Epoch 40] Train Loss=0.24983903765678406 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6676038035384037
[Epoch 41] Train Loss=0.24506723880767822 Test Acc=0.7416666666666667 T=1.0399999999999991s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6676038035384037
[Epoch 42] Train Loss=0.2477746605873108 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6628863346104725
[Epoch 43] Train Loss=0.2426798939704895 Test Acc=0.7388888888888889 T=1.0200000000000102s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6640204622963245
[Epoch 44] Train Loss=0.24533140659332275 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6676038035384037
[Epoch 45] Train Loss=0.24253153800964355 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 226, 1: 62, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6680845644012446
[Epoch 46] Train Loss=0.2516880929470062 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 230, 1: 54, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6574179344600035
[Epoch 47] Train Loss=0.23480284214019775 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7333333333333333, Macro-F1: 0.6530267206852721
[Epoch 48] Train Loss=0.2386883944272995 Test Acc=0.7333333333333333 T=1.0400000000000063s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6576759914548087
[Epoch 49] Train Loss=0.2423255443572998 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6584467748858142
[Epoch 50] Train Loss=0.23387615382671356 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6529093511852134
[Epoch 51] Train Loss=0.2313203066587448 Test Acc=0.7361111111111112 T=1.039999999999992s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6529093511852134
[Epoch 52] Train Loss=0.2341185212135315 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6576759914548087
[Epoch 53] Train Loss=0.2274680733680725 Test Acc=0.7361111111111112 T=1.0400000000000063s
Output Distribution={2: 227, 1: 60, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6651355367108792
[Epoch 54] Train Loss=0.2314717322587967 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 230, 1: 56, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6523108340667032
[Epoch 55] Train Loss=0.22351893782615662 Test Acc=0.7333333333333333 T=1.0200000000000102s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6646608764181456
[Epoch 56] Train Loss=0.23173727095127106 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6607724147914101
[Epoch 57] Train Loss=0.2313362956047058 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 229, 1: 57, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6569267923971758
[Epoch 58] Train Loss=0.2253747284412384 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 230, 1: 57, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6645742422554984
[Epoch 59] Train Loss=0.22665439546108246 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7416666666666667, Macro-F1: 0.6646608764181456
[Epoch 60] Train Loss=0.22928829491138458 Test Acc=0.7416666666666667 T=1.039999999999992s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7416666666666667, Macro-F1: 0.6623487895373952
[Epoch 61] Train Loss=0.227378711104393 Test Acc=0.7416666666666667 T=1.0200000000000102s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6622440851372526
[Epoch 62] Train Loss=0.22815629839897156 Test Acc=0.7416666666666667 T=1.0300000000000011s
Output Distribution={2: 226, 1: 58, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.662132255658993
[Epoch 63] Train Loss=0.2254692018032074 Test Acc=0.7388888888888889 T=1.0200000000000102s
Output Distribution={2: 228, 1: 59, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6606182790778087
[Epoch 64] Train Loss=0.22380684316158295 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 231, 1: 59, 0: 70}, Acc: 0.7444444444444445, Macro-F1: 0.6660261979907998
[Epoch 65] Train Loss=0.22260482609272003 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 228, 1: 56, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6613035508058028
[Epoch 66] Train Loss=0.21776466071605682 Test Acc=0.7416666666666667 T=1.039999999999992s
Output Distribution={2: 226, 1: 57, 0: 77}, Acc: 0.7361111111111112, Macro-F1: 0.6567825248722287
[Epoch 67] Train Loss=0.21373607218265533 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 231, 1: 58, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6598841204893161
[Epoch 68] Train Loss=0.2342088371515274 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6552911334852863
[Epoch 69] Train Loss=0.22214382886886597 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.657524027483705
[Epoch 70] Train Loss=0.2196776121854782 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 232, 1: 53, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6649985452089074
[Epoch 71] Train Loss=0.21660299599170685 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 227, 1: 57, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.6521120445504551
[Epoch 72] Train Loss=0.22443442046642303 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 227, 1: 58, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.657524027483705
[Epoch 73] Train Loss=0.21240857243537903 Test Acc=0.7361111111111112 T=1.009999999999991s
Output Distribution={2: 228, 1: 58, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.6597986178210539
[Epoch 74] Train Loss=0.22304777801036835 Test Acc=0.7388888888888889 T=1.0400000000000063s
Output Distribution={2: 226, 1: 57, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.661226969316673
[Epoch 75] Train Loss=0.22031864523887634 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6637157554830951
[Epoch 76] Train Loss=0.22073087096214294 Test Acc=0.7444444444444445 T=1.0400000000000063s
Output Distribution={2: 227, 1: 56, 0: 77}, Acc: 0.7416666666666667, Macro-F1: 0.6645342180588082
[Epoch 77] Train Loss=0.2203483134508133 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 233, 1: 52, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6511956965552127
[Epoch 78] Train Loss=0.20235024392604828 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 229, 1: 55, 0: 76}, Acc: 0.7333333333333333, Macro-F1: 0.6506596984693385
[Epoch 79] Train Loss=0.22337810695171356 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.654356081628809
[Epoch 80] Train Loss=0.21430930495262146 Test Acc=0.7388888888888889 T=1.039999999999992s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7388888888888889, Macro-F1: 0.655160913125515
[Epoch 81] Train Loss=0.21994730830192566 Test Acc=0.7388888888888889 T=1.0400000000000063s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7277777777777777, Macro-F1: 0.6398236998993858
[Epoch 82] Train Loss=0.2146582156419754 Test Acc=0.7277777777777777 T=1.0400000000000063s
Output Distribution={2: 229, 1: 56, 0: 75}, Acc: 0.7277777777777777, Macro-F1: 0.6416111193160373
[Epoch 83] Train Loss=0.2217894047498703 Test Acc=0.7277777777777777 T=1.0100000000000051s
Output Distribution={2: 230, 1: 59, 0: 71}, Acc: 0.7333333333333333, Macro-F1: 0.6498236018723824
[Epoch 84] Train Loss=0.20754586160182953 Test Acc=0.7333333333333333 T=1.019999999999996s
Output Distribution={2: 225, 1: 62, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6627265828163074
[Epoch 85] Train Loss=0.21435348689556122 Test Acc=0.7388888888888889 T=1.0400000000000063s
Output Distribution={2: 228, 1: 62, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6618966941558813
[Epoch 86] Train Loss=0.21250678598880768 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 229, 1: 62, 0: 69}, Acc: 0.7388888888888889, Macro-F1: 0.6626881194574857
[Epoch 87] Train Loss=0.21073468029499054 Test Acc=0.7388888888888889 T=1.0200000000000102s
Output Distribution={2: 227, 1: 62, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6703869047619048
[Epoch 88] Train Loss=0.20702262222766876 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6611265925712542
[Epoch 89] Train Loss=0.2136935442686081 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 223, 1: 60, 0: 77}, Acc: 0.7444444444444445, Macro-F1: 0.6695638495638496
[Epoch 90] Train Loss=0.210151806473732 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 234, 1: 57, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6504783128623733
[Epoch 91] Train Loss=0.21268627047538757 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6528011761366813
[Epoch 92] Train Loss=0.2128971517086029 Test Acc=0.7388888888888889 T=1.0200000000000102s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6558957158365009
[Epoch 93] Train Loss=0.20379219949245453 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 230, 1: 55, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6633679638114228
[Epoch 94] Train Loss=0.21014970541000366 Test Acc=0.7444444444444445 T=1.0100000000000051s
Output Distribution={2: 228, 1: 57, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.6672618351416766
[Epoch 95] Train Loss=0.20397867262363434 Test Acc=0.7472222222222222 T=1.0300000000000011s
Output Distribution={2: 231, 1: 60, 0: 69}, Acc: 0.7361111111111112, Macro-F1: 0.6520222613953139
[Epoch 96] Train Loss=0.2093842476606369 Test Acc=0.7361111111111112 T=1.0300000000000011s
Output Distribution={2: 229, 1: 58, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6674650169391662
[Epoch 97] Train Loss=0.21750479936599731 Test Acc=0.7444444444444445 T=1.0300000000000011s
Output Distribution={2: 226, 1: 59, 0: 75}, Acc: 0.7472222222222222, Macro-F1: 0.67426164419453
[Epoch 98] Train Loss=0.20905333757400513 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 225, 1: 62, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6718590029076316
[Epoch 99] Train Loss=0.2113117128610611 Test Acc=0.7444444444444445 T=1.029999999999987s
Output Distribution={2: 814, 0: 196, 1: 110}, Acc: 0.7258928571428571, Macro-F1: 0.58277318709585
accuracy:0.7258928571428571, macro_f1:0.58277318709585
> training arguments:
>>> model_name: ContextAvg
>>> dataset: restaurants14
>>> optimizer: Adam
>>> initializer: <function xavier_uniform_ at 0x2b9e0b0948c8>
>>> learning_rate: 0.0005
>>> num_epoch: 100
>>> batch_size: 32
>>> gpu: 0
>>> embed_dim: 300
>>> hidden_dim: 300
>>> max_seq_len: -1
>>> polarities_dim: 3
>>> kernel_num: 100
>>> kernel_sizes: [3, 4, 5]
>>> hops: 3
>>> seed: 111
>>> batch_normalizations: False
>>> softmax: False
>>> dev: 0.1
>>> dropout: 0.7
>>> model_class: <class 'models.ContextAvg.ContextAvg'>
>>> inputs_cols: ['text_raw_indices']
>>> device: cuda
preparing restaurants14 dataset...
loading embedding_matrix: /gpfs/home/lianghe/zhoujie/data/code/data/store/300_restaurants14_embedding_matrix.dat
n_trainable_params: 903, n_nontrainable_params: 2622000
Output Distribution={2: 359, 0: 1}, Acc: 0.6111111111111112, Macro-F1: 0.2528735632183908
[Epoch 0] Train Loss=1.0182873010635376 Test Acc=0.6111111111111112 T=1.25s
Output Distribution={2: 358, 0: 2}, Acc: 0.6083333333333333, Macro-F1: 0.25215889464594127
[Epoch 1] Train Loss=0.8945005536079407 Test Acc=0.6083333333333333 T=1.6199999999999992s
Output Distribution={2: 348, 0: 12}, Acc: 0.6194444444444445, Macro-F1: 0.2946345497777318
[Epoch 2] Train Loss=0.8465723991394043 Test Acc=0.6194444444444445 T=1.129999999999999s
Output Distribution={2: 333, 0: 27}, Acc: 0.6277777777777778, Macro-F1: 0.332057761732852
[Epoch 3] Train Loss=0.8005300760269165 Test Acc=0.6277777777777778 T=1.3599999999999994s
Output Distribution={2: 320, 0: 39, 1: 1}, Acc: 0.6416666666666667, Macro-F1: 0.37833771464830585
[Epoch 4] Train Loss=0.7664672136306763 Test Acc=0.6416666666666667 T=1.4000000000000021s
Output Distribution={2: 311, 0: 47, 1: 2}, Acc: 0.65, Macro-F1: 0.4006855373728439
[Epoch 5] Train Loss=0.7435294985771179 Test Acc=0.65 T=1.3599999999999994s
Output Distribution={2: 298, 0: 54, 1: 8}, Acc: 0.6555555555555556, Macro-F1: 0.4369252507707744
[Epoch 6] Train Loss=0.7129082679748535 Test Acc=0.6555555555555556 T=1.3900000000000006s
Output Distribution={2: 291, 0: 56, 1: 13}, Acc: 0.675, Macro-F1: 0.48501550080953787
[Epoch 7] Train Loss=0.6867722868919373 Test Acc=0.675 T=1.3599999999999994s
Output Distribution={2: 290, 0: 55, 1: 15}, Acc: 0.6777777777777778, Macro-F1: 0.49601035450540776
[Epoch 8] Train Loss=0.6580114364624023 Test Acc=0.6777777777777778 T=1.3500000000000014s
Output Distribution={2: 280, 0: 61, 1: 19}, Acc: 0.6972222222222222, Macro-F1: 0.5352831942202806
[Epoch 9] Train Loss=0.6387346386909485 Test Acc=0.6972222222222222 T=1.370000000000001s
Output Distribution={2: 274, 0: 64, 1: 22}, Acc: 0.7083333333333334, Macro-F1: 0.5600469414338027
[Epoch 10] Train Loss=0.6153207421302795 Test Acc=0.7083333333333334 T=1.1900000000000013s
Output Distribution={2: 276, 0: 62, 1: 22}, Acc: 0.7111111111111111, Macro-F1: 0.5628004841619866
[Epoch 11] Train Loss=0.599510133266449 Test Acc=0.7111111111111111 T=1.2799999999999976s
Output Distribution={2: 266, 0: 69, 1: 25}, Acc: 0.7305555555555555, Macro-F1: 0.5969653544920341
[Epoch 12] Train Loss=0.5757982134819031 Test Acc=0.7305555555555555 T=1.3399999999999963s
Output Distribution={2: 258, 0: 75, 1: 27}, Acc: 0.7222222222222222, Macro-F1: 0.5903537047721841
[Epoch 13] Train Loss=0.5575934052467346 Test Acc=0.7222222222222222 T=1.4100000000000037s
Output Distribution={2: 255, 0: 74, 1: 31}, Acc: 0.7222222222222222, Macro-F1: 0.5989749851830767
[Epoch 14] Train Loss=0.5347974300384521 Test Acc=0.7222222222222222 T=1.0699999999999932s
Output Distribution={2: 260, 0: 72, 1: 28}, Acc: 0.725, Macro-F1: 0.5986320989989369
[Epoch 15] Train Loss=0.5252154469490051 Test Acc=0.725 T=1.0499999999999972s
Output Distribution={2: 252, 0: 74, 1: 34}, Acc: 0.725, Macro-F1: 0.6095459579180509
[Epoch 16] Train Loss=0.5088960528373718 Test Acc=0.725 T=1.0200000000000031s
Output Distribution={2: 252, 0: 73, 1: 35}, Acc: 0.7277777777777777, Macro-F1: 0.6160651108118139
[Epoch 17] Train Loss=0.49835672974586487 Test Acc=0.7277777777777777 T=1.009999999999998s
Output Distribution={2: 252, 0: 75, 1: 33}, Acc: 0.7222222222222222, Macro-F1: 0.6029390913111844
[Epoch 18] Train Loss=0.4850142300128937 Test Acc=0.7222222222222222 T=1.0s
Output Distribution={2: 250, 0: 75, 1: 35}, Acc: 0.7222222222222222, Macro-F1: 0.6066423994783708
[Epoch 19] Train Loss=0.4779267907142639 Test Acc=0.7222222222222222 T=1.009999999999998s
Output Distribution={2: 248, 0: 72, 1: 40}, Acc: 0.7277777777777777, Macro-F1: 0.6226538096764065
[Epoch 20] Train Loss=0.45720332860946655 Test Acc=0.7277777777777777 T=1.009999999999998s
Output Distribution={2: 249, 0: 72, 1: 39}, Acc: 0.7305555555555555, Macro-F1: 0.6249170247702897
[Epoch 21] Train Loss=0.4552340805530548 Test Acc=0.7305555555555555 T=1.009999999999998s
Output Distribution={2: 245, 0: 76, 1: 39}, Acc: 0.725, Macro-F1: 0.6173954391311881
[Epoch 22] Train Loss=0.44420239329338074 Test Acc=0.725 T=1.019999999999996s
Output Distribution={2: 247, 0: 74, 1: 39}, Acc: 0.7277777777777777, Macro-F1: 0.620245363102506
[Epoch 23] Train Loss=0.4369979798793793 Test Acc=0.7277777777777777 T=1.009999999999998s
Output Distribution={2: 245, 0: 74, 1: 41}, Acc: 0.725, Macro-F1: 0.6220833900658789
[Epoch 24] Train Loss=0.4280787408351898 Test Acc=0.725 T=1.0300000000000011s
Output Distribution={2: 242, 1: 45, 0: 73}, Acc: 0.7194444444444444, Macro-F1: 0.6183888554372888
[Epoch 25] Train Loss=0.4101477265357971 Test Acc=0.7194444444444444 T=1.0100000000000051s
Output Distribution={2: 245, 1: 48, 0: 67}, Acc: 0.725, Macro-F1: 0.6303276072871736
[Epoch 26] Train Loss=0.4050232768058777 Test Acc=0.725 T=1.0200000000000031s
Output Distribution={2: 244, 1: 46, 0: 70}, Acc: 0.7222222222222222, Macro-F1: 0.6271252940607779
[Epoch 27] Train Loss=0.4032241702079773 Test Acc=0.7222222222222222 T=1.009999999999998s
Output Distribution={2: 241, 1: 47, 0: 72}, Acc: 0.7305555555555555, Macro-F1: 0.6399491668945437
[Epoch 28] Train Loss=0.39354562759399414 Test Acc=0.7305555555555555 T=1.0s
Output Distribution={2: 239, 1: 46, 0: 75}, Acc: 0.7361111111111112, Macro-F1: 0.6476302389345868
[Epoch 29] Train Loss=0.3900741636753082 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 240, 1: 49, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6506443843636148
[Epoch 30] Train Loss=0.37919238209724426 Test Acc=0.7361111111111112 T=1.3900000000000006s
Output Distribution={2: 239, 1: 50, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6497487367427398
[Epoch 31] Train Loss=0.36481714248657227 Test Acc=0.7361111111111112 T=1.1499999999999986s
Output Distribution={2: 243, 1: 48, 0: 69}, Acc: 0.7333333333333333, Macro-F1: 0.6440725924411157
[Epoch 32] Train Loss=0.36793652176856995 Test Acc=0.7333333333333333 T=1.0799999999999983s
Output Distribution={2: 242, 1: 46, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6482179652228807
[Epoch 33] Train Loss=0.3639458417892456 Test Acc=0.7361111111111112 T=1.0200000000000031s
Output Distribution={2: 241, 1: 46, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6474653580817965
[Epoch 34] Train Loss=0.3594639301300049 Test Acc=0.7361111111111112 T=1.009999999999998s
Output Distribution={2: 238, 1: 48, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.649317036756223
[Epoch 35] Train Loss=0.3457980155944824 Test Acc=0.7361111111111112 T=1.0200000000000031s
Output Distribution={2: 241, 1: 48, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6483823194349511
[Epoch 36] Train Loss=0.3462502956390381 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 241, 1: 46, 0: 73}, Acc: 0.7444444444444445, Macro-F1: 0.6594269505228411
[Epoch 37] Train Loss=0.3454477787017822 Test Acc=0.7444444444444445 T=1.009999999999998s
Output Distribution={2: 240, 1: 46, 0: 74}, Acc: 0.7444444444444445, Macro-F1: 0.6586674438394303
[Epoch 38] Train Loss=0.3449224829673767 Test Acc=0.7444444444444445 T=1.3399999999999963s
Output Distribution={2: 236, 1: 47, 0: 77}, Acc: 0.7333333333333333, Macro-F1: 0.6497166549404112
[Epoch 39] Train Loss=0.33322563767433167 Test Acc=0.7333333333333333 T=1.0899999999999963s
Output Distribution={2: 239, 1: 48, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6546127080655779
[Epoch 40] Train Loss=0.3252965211868286 Test Acc=0.7388888888888889 T=1.0600000000000023s
Output Distribution={2: 236, 1: 48, 0: 76}, Acc: 0.7388888888888889, Macro-F1: 0.6567832968034859
[Epoch 41] Train Loss=0.31956443190574646 Test Acc=0.7388888888888889 T=1.0200000000000031s
Output Distribution={2: 236, 1: 47, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6570751491601204
[Epoch 42] Train Loss=0.3178015947341919 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 236, 1: 47, 0: 77}, Acc: 0.7388888888888889, Macro-F1: 0.6570751491601204
[Epoch 43] Train Loss=0.3146432638168335 Test Acc=0.7388888888888889 T=1.009999999999991s
Output Distribution={2: 237, 1: 47, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6592348469385242
[Epoch 44] Train Loss=0.3122211992740631 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 237, 1: 48, 0: 75}, Acc: 0.7416666666666667, Macro-F1: 0.6589607304385515
[Epoch 45] Train Loss=0.3097313344478607 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6574183270958898
[Epoch 46] Train Loss=0.31604233384132385 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6649114597506173
[Epoch 47] Train Loss=0.29717007279396057 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 234, 1: 53, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6596092599315807
[Epoch 48] Train Loss=0.3031381666660309 Test Acc=0.7388888888888889 T=1.009999999999991s
Output Distribution={2: 234, 1: 50, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6649114597506173
[Epoch 49] Train Loss=0.3032251000404358 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 239, 1: 50, 0: 71}, Acc: 0.7472222222222222, Macro-F1: 0.6684393914154034
[Epoch 50] Train Loss=0.29270675778388977 Test Acc=0.7472222222222222 T=1.019999999999996s
Output Distribution={2: 240, 1: 49, 0: 71}, Acc: 0.7444444444444445, Macro-F1: 0.6636847188601409
[Epoch 51] Train Loss=0.28963127732276917 Test Acc=0.7444444444444445 T=1.230000000000004s
Output Distribution={2: 240, 1: 50, 0: 70}, Acc: 0.7472222222222222, Macro-F1: 0.6660088982252196
[Epoch 52] Train Loss=0.2878170311450958 Test Acc=0.7472222222222222 T=1.1300000000000097s
Output Distribution={2: 237, 1: 53, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6586985238410874
[Epoch 53] Train Loss=0.2862373888492584 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.660352876782897
[Epoch 54] Train Loss=0.2844550311565399 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 237, 1: 53, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6586985238410874
[Epoch 55] Train Loss=0.27892637252807617 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6542758712379761
[Epoch 56] Train Loss=0.2797184884548187 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 237, 1: 52, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6542758712379761
[Epoch 57] Train Loss=0.2824127972126007 Test Acc=0.7361111111111112 T=1.0200000000000102s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6594255173834616
[Epoch 58] Train Loss=0.271259069442749 Test Acc=0.7361111111111112 T=1.0900000000000034s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6638678922296312
[Epoch 59] Train Loss=0.274748831987381 Test Acc=0.7416666666666667 T=1.0900000000000034s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6618148650869906
[Epoch 60] Train Loss=0.2748192548751831 Test Acc=0.7416666666666667 T=1.009999999999991s
Output Distribution={2: 235, 1: 53, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6618148650869906
[Epoch 61] Train Loss=0.27025893330574036 Test Acc=0.7416666666666667 T=1.019999999999996s
Output Distribution={2: 235, 1: 54, 0: 71}, Acc: 0.7416666666666667, Macro-F1: 0.6616471734892787
[Epoch 62] Train Loss=0.2688199281692505 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6618205510191687
[Epoch 63] Train Loss=0.26993992924690247 Test Acc=0.7388888888888889 T=1.009999999999991s
Output Distribution={2: 233, 1: 55, 0: 72}, Acc: 0.7416666666666667, Macro-F1: 0.6640304415455286
[Epoch 64] Train Loss=0.2639557421207428 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7388888888888889, Macro-F1: 0.6590875070514052
[Epoch 65] Train Loss=0.26205646991729736 Test Acc=0.7388888888888889 T=1.1599999999999966s
Output Distribution={2: 232, 1: 57, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.656871982627111
[Epoch 66] Train Loss=0.2614782154560089 Test Acc=0.7361111111111112 T=1.0699999999999932s
Output Distribution={2: 231, 1: 56, 0: 73}, Acc: 0.7305555555555555, Macro-F1: 0.6493948264634826
[Epoch 67] Train Loss=0.25331178307533264 Test Acc=0.7305555555555555 T=1.0s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6548250599974739
[Epoch 68] Train Loss=0.26978135108947754 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 234, 1: 54, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6548250599974739
[Epoch 69] Train Loss=0.2612078785896301 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 231, 1: 53, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6608499787632581
[Epoch 70] Train Loss=0.25489646196365356 Test Acc=0.7416666666666667 T=1.0s
Output Distribution={2: 231, 1: 54, 0: 75}, Acc: 0.7444444444444445, Macro-F1: 0.6662720242366261
[Epoch 71] Train Loss=0.25179117918014526 Test Acc=0.7444444444444445 T=1.019999999999996s
Output Distribution={2: 229, 1: 55, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6631604636973764
[Epoch 72] Train Loss=0.2576674222946167 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 229, 1: 55, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6631604636973764
[Epoch 73] Train Loss=0.24911652505397797 Test Acc=0.7416666666666667 T=0.9900000000000091s
Output Distribution={2: 229, 1: 55, 0: 76}, Acc: 0.7416666666666667, Macro-F1: 0.6631604636973764
[Epoch 74] Train Loss=0.2542465925216675 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6555905816335651
[Epoch 75] Train Loss=0.2517395317554474 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6531262781700293
[Epoch 76] Train Loss=0.25261932611465454 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6555905816335651
[Epoch 77] Train Loss=0.25223585963249207 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6532845149807354
[Epoch 78] Train Loss=0.2303200364112854 Test Acc=0.7361111111111112 T=1.0100000000000051s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7388888888888889, Macro-F1: 0.657962036911895
[Epoch 79] Train Loss=0.25323328375816345 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6531262781700293
[Epoch 80] Train Loss=0.2438364028930664 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 233, 1: 53, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6476822740843767
[Epoch 81] Train Loss=0.2492271512746811 Test Acc=0.7333333333333333 T=1.0300000000000011s
Output Distribution={2: 233, 1: 54, 0: 73}, Acc: 0.7361111111111112, Macro-F1: 0.6531262781700293
[Epoch 82] Train Loss=0.24185018241405487 Test Acc=0.7361111111111112 T=1.009999999999991s
Output Distribution={2: 231, 1: 55, 0: 74}, Acc: 0.7333333333333333, Macro-F1: 0.6500809397602869
[Epoch 83] Train Loss=0.2497575283050537 Test Acc=0.7333333333333333 T=1.029999999999987s
Output Distribution={2: 232, 1: 54, 0: 74}, Acc: 0.7361111111111112, Macro-F1: 0.6524064813563395
[Epoch 84] Train Loss=0.2356119155883789 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6577825794917331
[Epoch 85] Train Loss=0.23986057937145233 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 232, 1: 55, 0: 73}, Acc: 0.7388888888888889, Macro-F1: 0.6577825794917331
[Epoch 86] Train Loss=0.23534077405929565 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6575530012771392
[Epoch 87] Train Loss=0.23729713261127472 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6576463839878273
[Epoch 88] Train Loss=0.23021861910820007 Test Acc=0.7388888888888889 T=1.019999999999996s
Output Distribution={2: 232, 1: 56, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6576463839878273
[Epoch 89] Train Loss=0.23686255514621735 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6575530012771392
[Epoch 90] Train Loss=0.23189730942249298 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 231, 1: 57, 0: 72}, Acc: 0.7361111111111112, Macro-F1: 0.6553239999900762
[Epoch 91] Train Loss=0.23371271789073944 Test Acc=0.7361111111111112 T=1.0s
Output Distribution={2: 233, 1: 57, 0: 70}, Acc: 0.7416666666666667, Macro-F1: 0.659797886294072
[Epoch 92] Train Loss=0.2339756190776825 Test Acc=0.7416666666666667 T=1.0100000000000051s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6544073592622015
[Epoch 93] Train Loss=0.22547569870948792 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 234, 1: 55, 0: 71}, Acc: 0.7361111111111112, Macro-F1: 0.6497264519991793
[Epoch 94] Train Loss=0.23180460929870605 Test Acc=0.7361111111111112 T=1.019999999999996s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6544073592622015
[Epoch 95] Train Loss=0.2235727161169052 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 233, 1: 56, 0: 71}, Acc: 0.7388888888888889, Macro-F1: 0.6544073592622015
[Epoch 96] Train Loss=0.22893297672271729 Test Acc=0.7388888888888889 T=1.0100000000000051s
Output Distribution={2: 231, 1: 60, 0: 69}, Acc: 0.7444444444444445, Macro-F1: 0.6672991076580757
[Epoch 97] Train Loss=0.23853068053722382 Test Acc=0.7444444444444445 T=1.009999999999991s
Output Distribution={2: 227, 1: 61, 0: 72}, Acc: 0.7444444444444445, Macro-F1: 0.6703854906067775
[Epoch 98] Train Loss=0.23001845180988312 Test Acc=0.7444444444444445 T=1.0s
Output Distribution={2: 229, 1: 59, 0: 72}, Acc: 0.7388888888888889, Macro-F1: 0.6621507024265645
[Epoch 99] Train Loss=0.23213958740234375 Test Acc=0.7388888888888889 T=1.0300000000000011s
Output Distribution={2: 815, 0: 193, 1: 112}, Acc: 0.7348214285714286, Macro-F1: 0.5957754424467852
accuracy:0.7348214285714286, macro_f1:0.5957754424467852
